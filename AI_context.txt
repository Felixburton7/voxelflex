Working Directory: /home/s_felix/voxelflex

Full File Structure of Project:
.
├── AI_context.sh
├── AI_context.txt
├── dump_snapshot.pickle
├── main.py
├── README.md
├── requirements.txt
├── setup.py
└── src
    ├── inspect_hdf5.py
    ├── voxelflex
    │   ├── cli
    │   │   ├── cli.py
    │   │   ├── commands
    │   │   │   ├── evaluate.py
    │   │   │   ├── __init__.py
    │   │   │   ├── predict.py
    │   │   │   ├── __pycache__
    │   │   │   │   ├── evaluate.cpython-310.pyc
    │   │   │   │   ├── __init__.cpython-310.pyc
    │   │   │   │   ├── predict.cpython-310.pyc
    │   │   │   │   ├── train.cpython-310.pyc
    │   │   │   │   └── visualize.cpython-310.pyc
    │   │   │   ├── train.py
    │   │   │   └── visualize.py
    │   │   ├── __init__.py
    │   │   └── __pycache__
    │   │       ├── cli.cpython-310.pyc
    │   │       └── __init__.cpython-310.pyc
    │   ├── config
    │   │   ├── config.py
    │   │   ├── default_config.yaml
    │   │   ├── __init__.py
    │   │   └── __pycache__
    │   │       ├── config.cpython-310.pyc
    │   │       └── __init__.cpython-310.pyc
    │   ├── data
    │   │   ├── data_loader.py
    │   │   ├── __init__.py
    │   │   ├── __pycache__
    │   │   │   ├── data_loader.cpython-310.pyc
    │   │   │   ├── __init__.cpython-310.pyc
    │   │   │   └── validators.cpython-310.pyc
    │   │   └── validators.py
    │   ├── __init__.py
    │   ├── models
    │   │   ├── cnn_models.py
    │   │   ├── __init__.py
    │   │   └── __pycache__
    │   │       ├── cnn_models.cpython-310.pyc
    │   │       └── __init__.cpython-310.pyc
    │   ├── __pycache__
    │   │   └── __init__.cpython-310.pyc
    │   └── utils
    │       ├── file_utils.py
    │       ├── __init__.py
    │       ├── logging_utils.py
    │       ├── __pycache__
    │       │   ├── file_utils.cpython-310.pyc
    │       │   ├── __init__.cpython-310.pyc
    │       │   ├── logging_utils.cpython-310.pyc
    │       │   └── system_utils.cpython-310.pyc
    │       └── system_utils.py
    └── voxelflex.egg-info
        ├── dependency_links.txt
        ├── entry_points.txt
        ├── PKG-INFO
        ├── requires.txt
        ├── SOURCES.txt
        └── top_level.txt

16 directories, 53 files

---------------------------------------------------------
Contents of Relevant Files (Ignoring Binary Files):
---------------------------------------------------------
===== FILE: src/voxelflex/config/default_config.yaml =====
# Default configuration for Voxelflex - Medium Settings
input:
  data_dir: /home/s_felix/voxelflex_inputs                    # Base directory for all data files
  voxel_file: /home/s_felix/voxelflex_inputs/voxelized_output/voxel_320.hdf5 # Full path to the voxel data
  rmsf_dir: /home/s_felix/voxelflex_inputs/replicas  # Full path to RMSF data directory
  temperature: 320                          # Temperature identifier: 320, 348, 379, 413, 450, or "average"
  domain_ids: []                            # List of domain IDs to process
  use_metadata: true                        # Flag to include metadata in processing
  max_domains: null                          # Limit to 500 domains for faster training can set to null

output:
  base_dir: outputs/                        # Base output directory
  log_file: voxelflex.log                   # Filename for logging output

model:
  architecture: multipath_rmsf_net          # Choose from: voxelflex_cnn, dilated_resnet3d, multipath_rmsf_net
  input_channels: 5                         # Number of channels: 5 (C, N, O, CA, CB) or 4 if CA/CB are missing
  channel_growth_rate: 1.5                  # Growth rate for channels in the model
  num_residual_blocks: 3                    # Reduced from 4 to 3 for medium settings
  dropout_rate: 0.3                         # Reduced dropout for better convergence
  base_filters: 32                          # Base number of filters for convolutional layers

training:
  batch_size: 256                           # Reduced from 512 to 256 for medium settings
  num_epochs: 20                            # Reduced from 50 to 20 for medium settings
  learning_rate: 0.0005                     # Learning rate for optimizer
  weight_decay: 1e-4                        # Weight decay for regularization
  train_split: 0.7                          # Proportion of data for training
  val_split: 0.15                           # Proportion of data for validation
  test_split: 0.15                          # Proportion of data for testing
  seed: 42                                  # Random seed for reproducibility
  safe_mode: false                          # Enable safe mode for dataset handling (single-threaded)
  memory_efficient: true                    # Use memory-efficient dataset mode
  resume_checkpoint: null                   # Path to checkpoint to resume training from (null = start fresh)
  gradient_clipping:
    enabled: true
    max_norm: 1.0
  warmup:
    enabled: true
    epochs: 1
  domain_streaming:
    enabled: true                           # Enable domain streaming
    initial_domains_per_batch: 100          # Reduced from 200 to 100 for medium settings
    memory_reserve_percent: 25.0            # Increased to 25% to keep more memory free
    dynamic_batch_sizing: true              # Adjust batch size based on memory
  # Mixed precision settings
  mixed_precision:
    enabled: true                           # Enable mixed precision training
    dtype: "bfloat16"                       # Options: "float16", "bfloat16"
  scheduler:                                # Learning rate scheduler configuration
    type: cosine_annealing                  # Scheduler type: reduce_on_plateau, step, or cosine_annealing
    patience: 5                             # Reduced from 10 to 5 for medium settings
    factor: 0.1                             # Factor for scheduler
    mode: min
    T_max: 5                                # Reduced from 10 to 5 for medium settings
    eta_min: 1e-6

prediction:
  domains_per_batch: 150                     # Reduced from 100 to 75 for medium settings
  batch_size: 256                            # Batch size for prediction
  use_training_domains: true                # Use domains from training

logging:
  level: INFO                               # Overall logging level
  console_level: INFO                       # Logging level for console output
  file_level: DEBUG                         # Logging level for file output
  show_progress_bars: true                  # Display progress bars during processing

visualization:
  plot_loss: true                           # Plot training loss over epochs
  plot_predictions: true                    # Plot predicted vs. actual RMSF values
  plot_residue_type_analysis: true          # Analyze prediction errors across residue types
  plot_error_distribution: true             # Visualize overall error distribution
  plot_amino_acid_performance: true         # Generate histogram of prediction errors across amino acids
  save_format: png                          # Format for saving visualizations
  dpi: 300                                  # DPI for saved figures
  plot_correlation: true                    # Plot correlation between predictions and ground truth
  max_scatter_points: 1000                  # Maximum scatter points in plots

system_utilization:
  detect_cores: true                        # Detect available CPU cores
  adjust_for_gpu: true                      # Adjust resources based on GPU availability
  num_workers: 16                           # Reduced from 24 to 16 for medium settings
  memory_ceiling_percent: 80.0              # Reduced from 80.0 to 75.0 for medium settings
  out_of_core_mode: true                    # Use out-of-core processing for large domains
  memory_thresholds:
    warning: 70.0                           # Reduced from 75.0 to 70.0 for earlier warnings
    critical: 80.0                          # Reduced from 85.0 to 80.0 for more headroom
    emergency: 90.0                         # Emergency threshold (percent)
  gpu_memory_fraction: 0.85                 # Reduced from 0.95 to 0.85 to leave more GPU memory free
===== FILE: src/voxelflex/config/config.py =====
"""
Configuration module for Voxelflex.

This module handles loading and validating YAML configuration files.
"""

import os
import logging
from pathlib import Path
from typing import Dict, Any, Optional

import yaml

def load_config(config_path: str) -> Dict[str, Any]:
    """
    Load configuration from YAML file.
    
    Args:
        config_path: Path to configuration file
        
    Returns:
        Configuration dictionary
    """
    # Expand user path if necessary
    config_path = os.path.expanduser(config_path)
    
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Configuration file not found: {config_path}")
    
    # Load configuration from YAML file
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # Validate configuration
    validate_config(config)
    
    # Expand paths in configuration
    config = expand_paths(config)
    
    return config


def validate_config(config: Dict[str, Any]) -> None:
    """
    Validate configuration dictionary.
    
    Args:
        config: Configuration dictionary to validate
        
    Raises:
        ValueError: If configuration is invalid
    """
    # Check for required sections
    required_sections = ['input', 'output', 'model', 'training']
    missing_sections = [section for section in required_sections if section not in config]
    
    if missing_sections:
        raise ValueError(f"Missing required configuration sections: {missing_sections}")
    
    # Validate input section
    if 'voxel_file' not in config['input']:
        raise ValueError("Missing required input parameter: voxel_file")
    
    if 'rmsf_dir' not in config['input']:
        raise ValueError("Missing required input parameter: rmsf_dir")
    
    # Validate output section
    if 'base_dir' not in config['output']:
        raise ValueError("Missing required output parameter: base_dir")
    
    # Validate model section
    if 'architecture' not in config['model']:
        raise ValueError("Missing required model parameter: architecture")
    
    valid_architectures = ['voxelflex_cnn', 'dilated_resnet3d', 'multipath_rmsf_net']
    if config['model']['architecture'] not in valid_architectures:
        raise ValueError(f"Invalid model architecture: {config['model']['architecture']}. "
                         f"Must be one of: {valid_architectures}")
    
    #Validate system memory and utilization
    if 'system_utilization' in config:
        if 'memory_ceiling_percent' in config['system_utilization']:
            memory_ceiling = config['system_utilization']['memory_ceiling_percent']
            if not isinstance(memory_ceiling, (int, float)) or memory_ceiling <= 0 or memory_ceiling > 100:
                raise ValueError(f"Invalid memory_ceiling_percent: {memory_ceiling}. Must be between 0 and 100.")
            
    # Validate training section
    if 'batch_size' not in config['training']:
        raise ValueError("Missing required training parameter: batch_size")
    
    if 'num_epochs' not in config['training']:
        raise ValueError("Missing required training parameter: num_epochs")


def expand_paths(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    Expand relative paths in configuration.
    
    Args:
        config: Configuration dictionary
        
    Returns:
        Configuration with expanded paths
    """
    # Expand paths in input section
    if 'data_dir' in config['input']:
        config['input']['data_dir'] = os.path.expanduser(config['input']['data_dir'])
    
    config['input']['voxel_file'] = os.path.expanduser(config['input']['voxel_file'])
    config['input']['rmsf_dir'] = os.path.expanduser(config['input']['rmsf_dir'])
    
    # Expand output base directory
    config['output']['base_dir'] = os.path.expanduser(config['output']['base_dir'])
    
    return config


def get_default_config() -> Dict[str, Any]:
    """
    Get default configuration.
    
    Returns:
        Default configuration dictionary
    """
    # Get the path to the default configuration file
    default_config_path = os.path.join(
        os.path.dirname(__file__), 
        'default_config.yaml'
    )
    
    # Load default configuration
    with open(default_config_path, 'r') as f:
        default_config = yaml.safe_load(f)
    
    return default_config
===== FILE: src/voxelflex/cli/commands/visualize.py =====
"""
Revised visualization command for Voxelflex with improved visualizations.

This module handles creating visualizations for model performance and analysis.
"""

import os
import time
import json
from typing import Dict, Any, List, Optional, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.figure import Figure
from matplotlib.colors import LinearSegmentedColormap
from sklearn.metrics import r2_score
from scipy.stats import gaussian_kde

from voxelflex.utils.logging_utils import get_logger
from voxelflex.utils.file_utils import ensure_dir, load_json

logger = get_logger(__name__)

def create_loss_curve(
    train_history: Dict[str, List[float]],
    output_dir: str,
    save_format: str = 'png',
    dpi: int = 300
) -> str:
    """
    Create a plot of training and validation loss curves.
    
    Args:
        train_history: Dictionary containing training and validation losses
        output_dir: Directory to save the plot
        save_format: Format to save the plot (png, jpg, etc.)
        dpi: DPI for the saved plot
        
    Returns:
        Path to the saved plot
    """
    logger.info("Creating loss curve plot")
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    epochs = range(1, len(train_history['train_loss']) + 1)
    ax.plot(epochs, train_history['train_loss'], 'b-', label='Training Loss', linewidth=2.5)
    ax.plot(epochs, train_history['val_loss'], 'r-', label='Validation Loss', linewidth=2.5)
    
    ax.set_title('Training and Validation Loss', fontsize=16, fontweight='bold')
    ax.set_xlabel('Epochs', fontsize=14)
    ax.set_ylabel('Loss', fontsize=14)
    ax.legend(fontsize=12)
    ax.grid(True, linestyle='--', alpha=0.7)
    
    # Add min/max annotations
    min_val_loss = min(train_history['val_loss'])
    min_val_epoch = train_history['val_loss'].index(min_val_loss) + 1
    
    ax.annotate(f'Min val loss: {min_val_loss:.4f}',
                xy=(min_val_epoch, min_val_loss),
                xytext=(min_val_epoch, min_val_loss * 1.2),
                arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8),
                fontsize=12,
                bbox=dict(boxstyle="round,pad=0.3", fc="yellow", alpha=0.3))
    
    # Save plot
    ensure_dir(output_dir)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    plot_path = os.path.join(output_dir, f"loss_curve_{timestamp}.{save_format}")
    
    fig.savefig(plot_path, dpi=dpi, bbox_inches='tight')
    plt.close(fig)
    
    logger.info(f"Loss curve plot saved to {plot_path}")
    return plot_path


def create_prediction_scatter(
    predictions_df: pd.DataFrame,
    output_dir: str,
    save_format: str = 'png',
    dpi: int = 300,
    max_points: int = 1000
) -> str:
    """
    Create a simplified scatter plot of predicted vs. validation RMSF values with R².
    
    Args:
        predictions_df: DataFrame containing predictions and actual values
        output_dir: Directory to save the plot
        save_format: Format to save the plot (png, jpg, etc.)
        dpi: DPI for the saved plot
        max_points: Maximum number of points to plot (to avoid overcrowding)
        
    Returns:
        Path to the saved plot
    """
    logger.info("Creating prediction scatter plot with R²")
    
    # Extract predictions and actual values
    y_true = predictions_df['actual_rmsf'].values
    y_pred = predictions_df['predicted_rmsf'].values
    
    # Calculate metrics
    r2 = r2_score(y_true, y_pred)
    mse = np.mean((y_pred - y_true)**2)
    rmse = np.sqrt(mse)
    mae = np.mean(np.abs(y_pred - y_true))
    
    # Sample points if there are too many
    if len(y_true) > max_points:
        logger.info(f"Sampling {max_points} points for scatter plot (out of {len(y_true)} total)")
        indices = np.random.choice(len(y_true), max_points, replace=False)
        y_true_plot = y_true[indices]
        y_pred_plot = y_pred[indices]
    else:
        y_true_plot = y_true
        y_pred_plot = y_pred
    
    # Create plot
    fig, ax = plt.subplots(figsize=(10, 8))
    
    # Create a simple scatter plot with alpha for overlap visibility
    scatter = ax.scatter(y_true_plot, y_pred_plot, c='steelblue', s=30, alpha=0.6, edgecolor='none')
    
    # Add perfect prediction line
    max_val = max(np.max(y_true), np.max(y_pred))
    min_val = min(np.min(y_true), np.min(y_pred))
    margin = (max_val - min_val) * 0.1
    ax.plot([min_val - margin, max_val + margin], [min_val - margin, max_val + margin], 'r--', linewidth=2.0, label='Perfect Prediction')
    
    # Add metrics as text box
    metrics_text = (
        f'R²: {r2:.4f}\n'
        f'RMSE: {rmse:.4f}\n'
        f'MAE: {mae:.4f}\n'
        f'Samples: {len(y_true)}'
    )
    props = dict(boxstyle='round', facecolor='white', alpha=0.8)
    ax.text(0.05, 0.95, metrics_text, transform=ax.transAxes, fontsize=12,
            verticalalignment='top', bbox=props)
    
    ax.set_title('Predicted vs. Validation RMSF Values', fontsize=16, fontweight='bold')
    ax.set_xlabel('Validation RMSF', fontsize=14)
    ax.set_ylabel('Predicted RMSF', fontsize=14)
    ax.grid(True, linestyle='--', alpha=0.7)
    ax.legend(loc='lower right', fontsize=12)
    
    # Make plot square
    ax.set_aspect('equal')
    ax.set_xlim(min_val - margin, max_val + margin)
    ax.set_ylim(min_val - margin, max_val + margin)
    
    # Save plot
    ensure_dir(output_dir)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    plot_path = os.path.join(output_dir, f"prediction_scatter_{timestamp}.{save_format}")
    
    fig.savefig(plot_path, dpi=dpi, bbox_inches='tight')
    plt.close(fig)
    
    logger.info(f"Prediction scatter plot saved to {plot_path}")
    return plot_path


def create_error_distribution(
    predictions_df: pd.DataFrame,
    output_dir: str,
    save_format: str = 'png',
    dpi: int = 300
) -> str:
    """
    Create a histogram of prediction errors.
    
    Args:
        predictions_df: DataFrame containing predictions and actual values
        output_dir: Directory to save the plot
        save_format: Format to save the plot (png, jpg, etc.)
        dpi: DPI for the saved plot
        
    Returns:
        Path to the saved plot
    """
    logger.info("Creating error distribution plot")
    
    # Calculate errors
    predictions_df['error'] = predictions_df['predicted_rmsf'] - predictions_df['actual_rmsf']
    
    # Create plot
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # Plot with more bins and a nicer color
    sns.histplot(predictions_df['error'], kde=True, bins=30, ax=ax, color='steelblue', 
                 edgecolor='black', alpha=0.7, line_kws={'linewidth': 2})
    
    ax.set_title('Distribution of Prediction Errors', fontsize=16, fontweight='bold')
    ax.set_xlabel('Error (Predicted - Validation)', fontsize=14)
    ax.set_ylabel('Frequency', fontsize=14)
    ax.grid(True, linestyle='--', alpha=0.7)
    
    # Add error statistics
    mean_error = predictions_df['error'].mean()
    std_error = predictions_df['error'].std()
    median_error = predictions_df['error'].median()
    
    ax.axvline(mean_error, color='r', linestyle='--', linewidth=2, label=f'Mean: {mean_error:.4f}')
    ax.axvline(median_error, color='g', linestyle='--', linewidth=2, label=f'Median: {median_error:.4f}')
    ax.axvline(mean_error + std_error, color='purple', linestyle=':', linewidth=1.5, label=f'Std: {std_error:.4f}')
    ax.axvline(mean_error - std_error, color='purple', linestyle=':', linewidth=1.5)
    
    ax.legend(fontsize=12)
    
    # Save plot
    ensure_dir(output_dir)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    plot_path = os.path.join(output_dir, f"error_distribution_{timestamp}.{save_format}")
    
    fig.savefig(plot_path, dpi=dpi, bbox_inches='tight')
    plt.close(fig)
    
    logger.info(f"Error distribution plot saved to {plot_path}")
    return plot_path


def create_residue_type_analysis(
    predictions_df: pd.DataFrame,
    output_dir: str,
    save_format: str = 'png',
    dpi: int = 300
) -> Optional[str]:
    """
    Create a box plot of prediction errors grouped by residue type.
    
    Args:
        predictions_df: DataFrame containing predictions and actual values
        output_dir: Directory to save the plot
        save_format: Format to save the plot (png, jpg, etc.)
        dpi: DPI for the saved plot
        
    Returns:
        Path to the saved plot, or None if residue type information is not available
    """
    if 'resname' not in predictions_df.columns:
        logger.warning("Residue type information not available for residue type analysis")
        return None
    
    logger.info("Creating residue type analysis plot")
    
    # Calculate errors if not already done
    if 'error' not in predictions_df.columns:
        predictions_df['error'] = predictions_df['predicted_rmsf'] - predictions_df['actual_rmsf']
    
    # Calculate absolute errors
    predictions_df['abs_error'] = np.abs(predictions_df['error'])
    
    # Create plot
    plt.figure(figsize=(12, 8))
    
    # Create box plot with improved styling
    ax = sns.boxplot(x='resname', y='abs_error', hue='resname', data=predictions_df, 
                    palette='viridis', width=0.6, linewidth=1.5, legend=False,
                    fliersize=5, flierprops=dict(marker='o', markerfacecolor='red'))
    
    ax.set_title('Prediction Error by Residue Type', fontsize=16, fontweight='bold')
    ax.set_xlabel('Residue Type', fontsize=14)
    ax.set_ylabel('Absolute Error', fontsize=14)
    ax.grid(True, linestyle='--', alpha=0.7)
    
    # Rotate x-axis labels if there are many residue types
    if predictions_df['resname'].nunique() > 10:
        plt.xticks(rotation=45, ha='right', fontsize=12)
    
    # Add number of samples for each residue type
    restype_counts = predictions_df['resname'].value_counts()
    for i, restype in enumerate(ax.get_xticklabels()):
        restype_text = restype.get_text()
        if restype_text in restype_counts:
            count = restype_counts[restype_text]
            ax.text(i, -0.1, f'n={count}', ha='center', va='top', rotation=45,
                   transform=ax.get_xaxis_transform(), fontsize=10)
    
    plt.tight_layout()
    
    # Save plot
    ensure_dir(output_dir)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    plot_path = os.path.join(output_dir, f"residue_type_analysis_{timestamp}.{save_format}")
    
    plt.savefig(plot_path, dpi=dpi, bbox_inches='tight')
    plt.close()
    
    logger.info(f"Residue type analysis plot saved to {plot_path}")
    return plot_path


def create_amino_acid_performance(
    predictions_df: pd.DataFrame,
    output_dir: str,
    save_format: str = 'png',
    dpi: int = 300
) -> Optional[str]:
    """
    Create a histogram of amino acid performance metrics.
    
    Args:
        predictions_df: DataFrame containing predictions and actual values
        output_dir: Directory to save the plot
        save_format: Format to save the plot (png, jpg, etc.)
        dpi: DPI for the saved plot
        
    Returns:
        Path to the saved plot, or None if residue type information is not available
    """
    if 'resname' not in predictions_df.columns:
        logger.warning("Residue type information not available for amino acid performance analysis")
        return None
    
    logger.info("Creating amino acid performance plot")
    
    # Calculate errors if not already done
    if 'error' not in predictions_df.columns:
        predictions_df['error'] = predictions_df['predicted_rmsf'] - predictions_df['actual_rmsf']
    
    # Calculate metrics for each amino acid
    aa_metrics = []
    
    for resname in sorted(predictions_df['resname'].unique()):
        resname_df = predictions_df[predictions_df['resname'] == resname]
        y_true = resname_df['actual_rmsf'].values
        y_pred = resname_df['predicted_rmsf'].values
        
        mse = ((y_pred - y_true) ** 2).mean()
        rmse = np.sqrt(mse)
        mae = np.abs(y_pred - y_true).mean()
        r2 = r2_score(y_true, y_pred) if len(y_true) > 1 else np.nan
        
        aa_metrics.append({
            'resname': resname,
            'count': len(resname_df),
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'r2': r2
        })
    
    aa_metrics_df = pd.DataFrame(aa_metrics)
    
    # Create plot
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    axes = axes.flatten()
    
    # Plot RMSE
    sns.barplot(x='resname', y='rmse', hue='resname', data=aa_metrics_df, ax=axes[0], palette='viridis', legend=False)
    axes[0].set_title('RMSE by Amino Acid', fontsize=14, fontweight='bold')
    axes[0].set_xlabel('Amino Acid', fontsize=12)
    axes[0].set_ylabel('RMSE', fontsize=12)
    axes[0].grid(True, linestyle='--', alpha=0.7)
    
    # Plot MAE
    sns.barplot(x='resname', y='mae', hue='resname', data=aa_metrics_df, ax=axes[1], palette='magma', legend=False)
    axes[1].set_title('MAE by Amino Acid', fontsize=14, fontweight='bold')
    axes[1].set_xlabel('Amino Acid', fontsize=12)
    axes[1].set_ylabel('MAE', fontsize=12)
    axes[1].grid(True, linestyle='--', alpha=0.7)
    
    # Plot R²
    sns.barplot(x='resname', y='r2', hue='resname', data=aa_metrics_df, ax=axes[2], palette='plasma')
    axes[2].set_title('R² by Amino Acid', fontsize=14, fontweight='bold')
    axes[2].set_xlabel('Amino Acid', fontsize=12)
    axes[2].set_ylabel('R²', fontsize=12)
    axes[2].grid(True, linestyle='--', alpha=0.7)
    
    # Plot sample count
    sns.barplot(x='resname', y='count',hue='resname', data=aa_metrics_df, ax=axes[3], palette='crest')
    axes[3].set_title('Sample Count by Amino Acid', fontsize=14, fontweight='bold')
    axes[3].set_xlabel('Amino Acid', fontsize=12)
    axes[3].set_ylabel('Count', fontsize=12)
    axes[3].grid(True, linestyle='--', alpha=0.7)
    
    # Rotate x-axis labels
    for ax in axes:
    # First get the current tick positions
        ticks = ax.get_xticks()
        # Then set the labels with rotation
        ax.set_xticks(ticks)
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=10)
    
    plt.tight_layout()
    
    # Save plot
    ensure_dir(output_dir)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    plot_path = os.path.join(output_dir, f"amino_acid_performance_{timestamp}.{save_format}")
    
    fig.savefig(plot_path, dpi=dpi, bbox_inches='tight')
    plt.close(fig)
    
    logger.info(f"Amino acid performance plot saved to {plot_path}")
    return plot_path


def create_residue_error_histogram(
    predictions_df: pd.DataFrame,
    output_dir: str,
    save_format: str = 'png',
    dpi: int = 300
) -> str:
    """
    Create a histogram showing error distribution for each residue.
    
    Args:
        predictions_df: DataFrame containing predictions and actual values
        output_dir: Directory to save the plot
        save_format: Format to save the plot (png, jpg, etc.)
        dpi: DPI for the saved plot
        
    Returns:
        Path to the saved plot
    """
    logger.info("Creating residue error histogram")
    
    # Ensure we have error column
    if 'error' not in predictions_df.columns:
        predictions_df['error'] = predictions_df['predicted_rmsf'] - predictions_df['actual_rmsf']
    
    # Get absolute error
    predictions_df['abs_error'] = np.abs(predictions_df['error'])
    
    # Group by residue ID if available and compute mean error
    if 'resid' in predictions_df.columns:
        residue_errors = predictions_df.groupby('resid')['abs_error'].mean().reset_index()
        residue_errors = residue_errors.sort_values('resid')
        
        # Create plot
        fig, ax = plt.subplots(figsize=(14, 8))
        
        # Create bar plot with color gradient based on error magnitude
        cmap = plt.cm.get_cmap('viridis_r')
        norm = plt.Normalize(residue_errors['abs_error'].min(), residue_errors['abs_error'].max())
        colors = [cmap(norm(value)) for value in residue_errors['abs_error']]
        
        bars = ax.bar(residue_errors['resid'], residue_errors['abs_error'], color=colors, width=0.8)
        
        # Add colorbar
        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
        sm.set_array([])
        cbar = plt.colorbar(sm, ax=ax)
        cbar.set_label('Absolute Error Magnitude', fontsize=12)
        
        ax.set_title('Mean Absolute Error by Residue Position', fontsize=16, fontweight='bold')
        ax.set_xlabel('Residue ID', fontsize=14)
        ax.set_ylabel('Mean Absolute Error', fontsize=14)
        ax.grid(True, linestyle='--', alpha=0.7, axis='y')
        
        # Add statistics
        highest_error_resid = residue_errors.loc[residue_errors['abs_error'].idxmax()]
        lowest_error_resid = residue_errors.loc[residue_errors['abs_error'].idxmin()]
        
        # Annotate highest and lowest error residues
        ax.annotate(f"Highest error: {highest_error_resid['abs_error']:.4f}",
                    xy=(highest_error_resid['resid'], highest_error_resid['abs_error']),
                    xytext=(0, 20), textcoords='offset points',
                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=.2'),
                    fontsize=12, ha='center')
        
        ax.annotate(f"Lowest error: {lowest_error_resid['abs_error']:.4f}",
                    xy=(lowest_error_resid['resid'], lowest_error_resid['abs_error']),
                    xytext=(0, -20), textcoords='offset points',
                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=.2'),
                    fontsize=12, ha='center')
        
        # Add a horizontal line for mean error
        mean_error = residue_errors['abs_error'].mean()
        ax.axhline(mean_error, color='red', linestyle='--', linewidth=1.5, 
                   label=f'Mean Error: {mean_error:.4f}')
        ax.legend(fontsize=12)
        
        # Remove every second tick if there are too many residues
        if len(residue_errors) > 30:
            for idx, label in enumerate(ax.xaxis.get_ticklabels()):
                if idx % 2 != 0:
                    label.set_visible(False)
        
        plt.tight_layout()
        
        # Save plot
        ensure_dir(output_dir)
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        plot_path = os.path.join(output_dir, f"residue_error_histogram_{timestamp}.{save_format}")
        
        fig.savefig(plot_path, dpi=dpi, bbox_inches='tight')
        plt.close(fig)
        
        logger.info(f"Residue error histogram saved to {plot_path}")
        return plot_path
    else:
        logger.warning("Residue ID information not available for residue error histogram")
        return None


def create_residue_type_error_histogram(
    predictions_df: pd.DataFrame,
    output_dir: str,
    save_format: str = 'png',
    dpi: int = 300
) -> str:
    """
    Create a histogram showing error distribution by residue type (amino acid).
    
    Args:
        predictions_df: DataFrame containing predictions and actual values
        output_dir: Directory to save the plot
        save_format: Format to save the plot (png, jpg, etc.)
        dpi: DPI for the saved plot
        
    Returns:
        Path to the saved plot
    """
    logger.info("Creating residue type error histogram")
    
    # Check if we have residue type information
    if 'resname' not in predictions_df.columns:
        logger.warning("Residue type information not available for residue type error histogram")
        return None
    
    # Ensure we have error column
    if 'error' not in predictions_df.columns:
        predictions_df['error'] = predictions_df['predicted_rmsf'] - predictions_df['actual_rmsf']
    
    # Get absolute error
    predictions_df['abs_error'] = np.abs(predictions_df['error'])
    
    # Group by residue type and compute mean absolute error
    residue_type_errors = predictions_df.groupby('resname')['abs_error'].mean().reset_index()
    
    # Sort by error for better visualization
    residue_type_errors = residue_type_errors.sort_values('abs_error', ascending=False)
    
    # Get sample counts for each residue type
    residue_counts = predictions_df['resname'].value_counts().reset_index()
    residue_counts.columns = ['resname', 'count']
    
    # Merge with errors
    residue_type_errors = pd.merge(residue_type_errors, residue_counts, on='resname', how='left')
    
    # Create plot
    fig, ax = plt.subplots(figsize=(14, 8))
    
    # Create bar plot with color gradient based on error magnitude
    cmap = plt.cm.get_cmap('viridis_r')
    norm = plt.Normalize(residue_type_errors['abs_error'].min(), residue_type_errors['abs_error'].max())
    colors = [cmap(norm(value)) for value in residue_type_errors['abs_error']]
    
    # Create bars
    bars = ax.bar(residue_type_errors['resname'], residue_type_errors['abs_error'], color=colors, width=0.7)
    
    # Add colorbar
    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
    sm.set_array([])
    cbar = plt.colorbar(sm, ax=ax)
    cbar.set_label('Absolute Error Magnitude', fontsize=12)
    
    ax.set_title('Mean Absolute Error by Amino Acid Type', fontsize=16, fontweight='bold')
    ax.set_xlabel('Amino Acid', fontsize=14)
    ax.set_ylabel('Mean Absolute Error', fontsize=14)
    ax.grid(True, linestyle='--', alpha=0.7, axis='y')
    
    # Add sample count above each bar
    for i, (_, row) in enumerate(residue_type_errors.iterrows()):
        ax.text(i, row['abs_error'] + 0.01, f"n={row['count']}", 
                ha='center', va='bottom', fontsize=10, rotation=0)
    
    # Add statistics
    highest_error_aa = residue_type_errors.iloc[0]
    lowest_error_aa = residue_type_errors.iloc[-1]
    
    # Annotate highest and lowest error amino acids
    ax.annotate(f"{highest_error_aa['resname']}: {highest_error_aa['abs_error']:.4f}",
                xy=(0, highest_error_aa['abs_error']),
                xytext=(1, highest_error_aa['abs_error'] * 1.1), 
                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=.2'),
                fontsize=12)
    
    ax.annotate(f"{lowest_error_aa['resname']}: {lowest_error_aa['abs_error']:.4f}",
                xy=(len(residue_type_errors)-1, lowest_error_aa['abs_error']),
                xytext=(len(residue_type_errors)-2, lowest_error_aa['abs_error'] * 1.5), 
                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=.2'),
                fontsize=12)
    
    # Add a horizontal line for mean error
    mean_error = residue_type_errors['abs_error'].mean()
    ax.axhline(mean_error, color='red', linestyle='--', linewidth=1.5, 
               label=f'Mean Error: {mean_error:.4f}')
    ax.legend(fontsize=12)
    
    plt.tight_layout()
    
    # Save plot
    ensure_dir(output_dir)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    plot_path = os.path.join(output_dir, f"residue_type_error_histogram_{timestamp}.{save_format}")
    
    fig.savefig(plot_path, dpi=dpi, bbox_inches='tight')
    plt.close(fig)
    
    logger.info(f"Residue type error histogram saved to {plot_path}")
    return plot_path


def create_predicted_vs_validation_scatter_density(
    predictions_df: pd.DataFrame,
    output_dir: str,
    save_format: str = 'png',
    dpi: int = 300
) -> str:
    """
    Create a scatter plot with density contours for predicted vs. validation RMSF values.
    
    Args:
        predictions_df: DataFrame containing predictions and actual values
        output_dir: Directory to save the plot
        save_format: Format to save the plot (png, jpg, etc.)
        dpi: DPI for the saved plot
        
    Returns:
        Path to the saved plot
    """
    logger.info("Creating predicted vs. validation scatter density plot")
    
    # Extract predictions and actual values
    y_true = predictions_df['actual_rmsf'].values
    y_pred = predictions_df['predicted_rmsf'].values
    
    # Calculate R² and other metrics
    r2 = r2_score(y_true, y_pred)
    rmse = np.sqrt(np.mean((y_pred - y_true)**2))
    
    # Create plot
    fig, ax = plt.subplots(figsize=(10, 8))
    
    # Use kernel density estimate for the joint distribution
    xy = np.vstack([y_true, y_pred])
    kernel = gaussian_kde(xy)
    
    # Get the range for creating the density map
    min_val = min(np.min(y_true), np.min(y_pred))
    max_val = max(np.max(y_true), np.max(y_pred))
    margin = (max_val - min_val) * 0.1
    x_range = np.linspace(min_val - margin, max_val + margin, 100)
    y_range = np.linspace(min_val - margin, max_val + margin, 100)
    X, Y = np.meshgrid(x_range, y_range)
    positions = np.vstack([X.ravel(), Y.ravel()])
    
    # Evaluate the KDE at the grid positions
    Z = kernel(positions)
    Z = Z.reshape(X.shape)
    
    # Create the scatter plot of actual points
    scatter = ax.scatter(y_true, y_pred, c='steelblue', s=20, alpha=0.3, edgecolor='none')
    
    # Add contour lines for the density
    contour = ax.contour(X, Y, Z, cmap='viridis', levels=7, alpha=0.8)
    
    # Add perfect prediction line
    ax.plot([min_val - margin, max_val + margin], [min_val - margin, max_val + margin], 'r--', linewidth=2.0, label='Perfect Prediction')
    
    # Add metrics as text box
    metrics_text = (
        f'R²: {r2:.4f}\n'
        f'RMSE: {rmse:.4f}\n'
        f'Samples: {len(y_true)}'
    )
    props = dict(boxstyle='round', facecolor='white', alpha=0.8)
    ax.text(0.05, 0.95, metrics_text, transform=ax.transAxes, fontsize=12,
            verticalalignment='top', bbox=props)
    
    ax.set_title('Predicted vs. Validation RMSF with Density Contours', fontsize=16, fontweight='bold')
    ax.set_xlabel('Validation RMSF', fontsize=14)
    ax.set_ylabel('Predicted RMSF', fontsize=14)
    ax.grid(True, linestyle='--', alpha=0.7)
    ax.legend(loc='lower right', fontsize=12)
    
    # Make plot square
    ax.set_aspect('equal')
    ax.set_xlim(min_val - margin, max_val + margin)
    ax.set_ylim(min_val - margin, max_val + margin)
    
    # Save plot
    ensure_dir(output_dir)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    plot_path = os.path.join(output_dir, f"predicted_vs_validation_density_{timestamp}.{save_format}")
    
    fig.savefig(plot_path, dpi=dpi, bbox_inches='tight')
    plt.close(fig)
    
    logger.info(f"Predicted vs. validation scatter density plot saved to {plot_path}")
    return plot_path


def create_visualizations(
    config: Dict[str, Any],
    train_history: Optional[Dict[str, List[float]]],
    predictions_path: str
) -> List[str]:
    """
    Create visualizations for model performance and analysis.
    
    Args:
        config: Configuration dictionary
        train_history: Training history dictionary (optional)
        predictions_path: Path to predictions file
        
    Returns:
        List of paths to created visualizations
    """
    logger.info("Creating visualizations")
    
    # Load predictions
    predictions_df = pd.read_csv(predictions_path)
    
    # Create output directory
    output_dir = os.path.join(config["output"]["base_dir"], "visualizations")
    ensure_dir(output_dir)
    
    # Get visualization settings
    viz_config = config.get("visualization", {})
    save_format = viz_config.get("save_format", "png")
    dpi = viz_config.get("dpi", 300)
    max_scatter_points = viz_config.get("max_scatter_points", 1000)
    
    # Create visualizations
    visualization_paths = []
    
    if train_history is None and viz_config.get("plot_loss", True):
        logger.warning("Training history not provided, skipping loss curve plot")

    # Loss curve (if training history is available)
    if train_history is not None and viz_config.get("plot_loss", True):
        loss_curve_path = create_loss_curve(
            train_history, output_dir, save_format, dpi
        )
        visualization_paths.append(loss_curve_path)
    
    # Prediction scatter plot (improved with R²)
    if viz_config.get("plot_predictions", True):
        scatter_path = create_prediction_scatter(
            predictions_df, output_dir, save_format, dpi, max_scatter_points
        )
        visualization_paths.append(scatter_path)
    
    # Predicted vs validation with density (new and improved)
    density_scatter_path = create_predicted_vs_validation_scatter_density(
        predictions_df, output_dir, save_format, dpi
    )
    visualization_paths.append(density_scatter_path)
    
    # Error distribution
    if viz_config.get("plot_error_distribution", True):
        error_dist_path = create_error_distribution(
            predictions_df, output_dir, save_format, dpi
        )
        visualization_paths.append(error_dist_path)
    
    # Residue error histogram
    residue_error_path = create_residue_error_histogram(
        predictions_df, output_dir, save_format, dpi
    )
    if residue_error_path:
        visualization_paths.append(residue_error_path)
    
    # Residue type error histogram (new)
    residue_type_error_path = create_residue_type_error_histogram(
        predictions_df, output_dir, save_format, dpi
    )
    if residue_type_error_path:
        visualization_paths.append(residue_type_error_path)
    
    # Residue type analysis
    if viz_config.get("plot_residue_type_analysis", True):
        residue_type_path = create_residue_type_analysis(
            predictions_df, output_dir, save_format, dpi
        )
        if residue_type_path:
            visualization_paths.append(residue_type_path)
    
    # Amino acid performance
    if viz_config.get("plot_amino_acid_performance", True):
        aa_performance_path = create_amino_acid_performance(
            predictions_df, output_dir, save_format, dpi
        )
        if aa_performance_path:
            visualization_paths.append(aa_performance_path)
    
    logger.info(f"Created {len(visualization_paths)} visualizations")
    return visualization_paths
===== FILE: src/voxelflex/cli/commands/evaluate.py =====
"""
Evaluation command for Voxelflex.

This module handles evaluating the performance of trained RMSF models.
"""


import os
import time
import json
import gc
from typing import Dict, Any, Optional

import numpy as np
import pandas as pd
import torch  # Add this import
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

from voxelflex.utils.logging_utils import get_logger
from voxelflex.utils.file_utils import ensure_dir, save_json
from voxelflex.utils.system_utils import clear_memory, check_memory_usage  # Add these imports

logger = get_logger(__name__)

logger = get_logger(__name__)




def evaluate_model(
    config: Dict[str, Any],
    model_path: str,
    predictions_path: Optional[str] = None
) -> str:
    """
    Evaluate model performance using various metrics with enhanced memory management.
    
    Args:
        config: Configuration dictionary
        model_path: Path to the trained model file
        predictions_path: Path to predictions file. If None, predictions will be made.
        
    Returns:
        Path to the metrics file
    """
    logger.info("Evaluating model performance with optimized memory handling")
    
    # MEMORY OPTIMIZATION: Check initial memory usage
    memory_stats = check_memory_usage()
    logger.info(f"Initial memory: System: {memory_stats['system_percent']}% used, "
               f"Process: {memory_stats['process_rss_gb']:.2f} GB")
    
    # Extract domain information from model if available
    try:
        # Load checkpoint but be careful with memory
        device = torch.device('cpu')  # Use CPU for checkpoint loading to save GPU memory
        checkpoint = torch.load(model_path, map_location=device)
        processed_domains = checkpoint.get('processed_domains', None)
        
        if processed_domains:
            logger.info(f"Model was trained on {len(processed_domains)} domains")
        
        # Extract only what we need and clear the rest
        config_from_checkpoint = checkpoint.get('config', {})
        # We don't need the full checkpoint anymore
        del checkpoint
        clear_memory(force_gc=True)
        
    except Exception as e:
        logger.warning(f"Could not extract domain information from model: {str(e)}")
    
    # If predictions_path is not provided, generate predictions
    if predictions_path is None:
        from voxelflex.cli.commands.predict import predict_rmsf
        # Force memory clearing before prediction
        clear_memory(force_gc=True, clear_cuda=True)
        predictions_path = predict_rmsf(config, model_path)
    
    # MEMORY OPTIMIZATION: Load predictions in chunks for large files
    logger.info(f"Loading predictions from {predictions_path}")
    
    try:
        # Check file size to determine if chunking is needed
        file_size_mb = os.path.getsize(predictions_path) / (1024 * 1024)
        
        if file_size_mb > 500:  # For files larger than 500MB
            logger.info(f"Large predictions file detected ({file_size_mb:.1f} MB). Loading in chunks.")
            
            # Read in chunks with specified dtype to reduce memory usage
            predictions_df = pd.read_csv(
                predictions_path,
                dtype={
                    'domain_id': 'category',  # Use category dtype for domain_id to save memory
                    'resid': 'int32',         # Use int32 instead of int64
                    'resname': 'category',    # Use category dtype for resname to save memory
                    'predicted_rmsf': 'float32',  # Use float32 instead of float64
                    'actual_rmsf': 'float32'      # Use float32 instead of float64
                },
                chunksize=100000  # Load 100k rows at a time
            )
            
            # Process chunks to calculate basic statistics first
            chunk_list = []
            total_rows = 0
            y_true_sum = 0
            y_pred_sum = 0
            y_true_min = float('inf')
            y_true_max = float('-inf')
            
            for i, chunk in enumerate(predictions_df):
                logger.info(f"Processing chunk {i+1} for basic statistics")
                total_rows += len(chunk)
                
                # Calculate running statistics
                y_true_sum += chunk['actual_rmsf'].sum()
                y_pred_sum += chunk['predicted_rmsf'].sum()
                y_true_min = min(y_true_min, chunk['actual_rmsf'].min())
                y_true_max = max(y_true_max, chunk['actual_rmsf'].max())
                
                # Add to list but monitor memory
                chunk_list.append(chunk)
                
                # Check memory pressure and clear if needed
                if i % 5 == 0 and i > 0:
                    memory_stats = check_memory_usage()
                    if memory_stats['system_percent'] > 80:
                        logger.warning(f"High memory pressure ({memory_stats['system_percent']}%). "
                                      f"Clearing memory after chunk {i+1}")
                        clear_memory(force_gc=True)
            
            # Now combine chunks but be careful with memory
            try:
                predictions_df = pd.concat(chunk_list, ignore_index=True)
                del chunk_list
                clear_memory(force_gc=True)
            except Exception as e:
                logger.error(f"Error combining chunks: {str(e)}")
                # Fall back to processing each chunk separately
                logger.warning("Falling back to processing chunks separately")
                predictions_df = pd.read_csv(
                    predictions_path,
                    dtype={
                        'domain_id': 'category',
                        'resid': 'int32',
                        'resname': 'category',
                        'predicted_rmsf': 'float32',
                        'actual_rmsf': 'float32'
                    },
                    chunksize=100000
                )
        else:
            # Standard loading for smaller files with optimized dtypes
            predictions_df = pd.read_csv(
                predictions_path,
                dtype={
                    'domain_id': 'category',
                    'resid': 'int32',
                    'resname': 'category',
                    'predicted_rmsf': 'float32',
                    'actual_rmsf': 'float32'
                }
            )
    except Exception as e:
        logger.error(f"Error loading predictions: {str(e)}")
        raise
    
    # MEMORY OPTIMIZATION: Check memory after loading predictions
    memory_stats = check_memory_usage()
    logger.info(f"Memory after loading predictions: {memory_stats['system_percent']}%, "
               f"{memory_stats['process_rss_gb']:.2f} GB")
    
    # Log some information about the domains in the predictions
    if isinstance(predictions_df, pd.DataFrame) and 'domain_id' in predictions_df.columns:
        domains_in_predictions = predictions_df['domain_id'].nunique()
        total_residues = len(predictions_df)
        logger.info(f"Evaluating predictions for {domains_in_predictions} domains with {total_residues} total residues")
    
    # Calculate overall metrics with memory-efficient approach
    if isinstance(predictions_df, pd.DataFrame):
        # For DataFrame case (smaller files)
        y_true = predictions_df['actual_rmsf'].values
        y_pred = predictions_df['predicted_rmsf'].values
        
        # Calculate metrics
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)
        
        # Calculate coefficient of variation of RMSD
        cv_rmsd = rmse / np.mean(y_true) * 100
        
        # Calculate relative error metrics
        mean_relative_error = np.mean(np.abs(y_pred - y_true) / np.maximum(0.01, y_true)) * 100
        median_relative_error = np.median(np.abs(y_pred - y_true) / np.maximum(0.01, y_true)) * 100
        
    else:
        # For chunked DataFrame case (larger files)
        # Initialize metrics
        sum_squared_error = 0
        sum_absolute_error = 0
        sum_true = 0
        sum_pred = 0
        sum_true_squared = 0
        sum_pred_squared = 0
        sum_product = 0
        count = 0
        sum_relative_error = 0
        relative_errors = []
        
        # Process each chunk
        for i, chunk in enumerate(predictions_df):
            logger.info(f"Processing metrics for chunk {i+1}")
            
            chunk_y_true = chunk['actual_rmsf'].values
            chunk_y_pred = chunk['predicted_rmsf'].values
            chunk_count = len(chunk_y_true)
            
            # Update running sums for metrics
            sum_squared_error += np.sum((chunk_y_pred - chunk_y_true) ** 2)
            sum_absolute_error += np.sum(np.abs(chunk_y_pred - chunk_y_true))
            sum_true += np.sum(chunk_y_true)
            sum_pred += np.sum(chunk_y_pred)
            sum_true_squared += np.sum(chunk_y_true ** 2)
            sum_pred_squared += np.sum(chunk_y_pred ** 2)
            sum_product += np.sum(chunk_y_true * chunk_y_pred)
            
            # Collect relative errors for median calculation
            chunk_relative_errors = np.abs(chunk_y_pred - chunk_y_true) / np.maximum(0.01, chunk_y_true) * 100
            sum_relative_error += np.sum(chunk_relative_errors)
            relative_errors.extend(chunk_relative_errors.tolist())
            
            count += chunk_count
            
            # Clear memory between chunks
            if i % 3 == 0:
                clear_memory(force_gc=True)
        
        # Calculate final metrics
        mse = sum_squared_error / count
        rmse = np.sqrt(mse)
        mae = sum_absolute_error / count
        
        # Calculate R² manually
        mean_true = sum_true / count
        mean_pred = sum_pred / count
        numerator = sum_product - count * mean_true * mean_pred
        denominator_true = sum_true_squared - count * mean_true ** 2
        denominator_pred = sum_pred_squared - count * mean_pred ** 2
        r2 = (numerator ** 2) / (denominator_true * denominator_pred)
        
        # Calculate coefficient of variation of RMSD
        cv_rmsd = rmse / (sum_true / count) * 100
        
        # Calculate relative error metrics
        mean_relative_error = sum_relative_error / count
        median_relative_error = np.median(np.array(relative_errors))
        
        # Clear relative errors array to save memory
        del relative_errors
        clear_memory(force_gc=True)
    
    # Calculate domain-level metrics if domain info is available - with memory optimization
    domain_metrics = {}
    if isinstance(predictions_df, pd.DataFrame) and 'domain_id' in predictions_df.columns:
        # Process domains in batches to manage memory
        unique_domains = predictions_df['domain_id'].unique()
        domain_batch_size = min(50, len(unique_domains))  # Process 50 domains at a time or fewer
        
        for batch_start in range(0, len(unique_domains), domain_batch_size):
            batch_end = min(batch_start + domain_batch_size, len(unique_domains))
            batch_domains = unique_domains[batch_start:batch_end]
            
            logger.info(f"Processing domain metrics batch {batch_start//domain_batch_size + 1} "
                       f"(domains {batch_start} to {batch_end-1})")
            
            for domain in batch_domains:
                domain_df = predictions_df[predictions_df['domain_id'] == domain]
                domain_y_true = domain_df['actual_rmsf'].values
                domain_y_pred = domain_df['predicted_rmsf'].values
                
                # Skip if we don't have enough data
                if len(domain_y_true) < 2:
                    continue
                
                try:
                    domain_mse = mean_squared_error(domain_y_true, domain_y_pred)
                    domain_rmse = np.sqrt(domain_mse)
                    domain_mae = mean_absolute_error(domain_y_true, domain_y_pred)
                    domain_r2 = r2_score(domain_y_true, domain_y_pred)
                    
                    # Additional metrics for better evaluation
                    domain_mean_true = np.mean(domain_y_true)
                    domain_mean_pred = np.mean(domain_y_pred)
                    domain_median_true = np.median(domain_y_true)
                    domain_median_pred = np.median(domain_y_pred)
                    domain_cv_rmsd = domain_rmse / domain_mean_true * 100 if domain_mean_true > 0 else float('inf')
                    
                    # Calculate correlation coefficient
                    domain_corr = np.corrcoef(domain_y_true, domain_y_pred)[0, 1]
                    
                    domain_metrics[domain] = {
                        'mse': float(domain_mse),
                        'rmse': float(domain_rmse),
                        'mae': float(domain_mae),
                        'r2': float(domain_r2),
                        'corr': float(domain_corr),
                        'cv_rmsd': float(domain_cv_rmsd),
                        'mean_true': float(domain_mean_true),
                        'mean_pred': float(domain_mean_pred),
                        'median_true': float(domain_median_true),
                        'median_pred': float(domain_median_pred),
                        'num_residues': int(len(domain_df))
                    }
                except Exception as e:
                    logger.warning(f"Error calculating metrics for domain {domain}: {str(e)}")
            
            # Clear memory after each batch
            clear_memory(force_gc=True)
            
            # Check memory pressure and take emergency measures if needed
            memory_stats = check_memory_usage()
            if memory_stats['system_percent'] > 85:
                logger.warning(f"Critical memory pressure during domain metrics: {memory_stats['system_percent']}%")
                logger.warning(f"Stopping domain metrics calculation to preserve memory integrity")
                break
    elif not isinstance(predictions_df, pd.DataFrame):
        # For chunked processing (large files)
        logger.info("Processing domain metrics for large chunked files")
        
        # Get unique domains from all chunks
        unique_domains = set()
        domain_residue_counts = {}
        
        # First pass to identify unique domains and count residues
        for i, chunk in enumerate(predictions_df):
            for domain in chunk['domain_id'].unique():
                if domain not in unique_domains:
                    unique_domains.add(domain)
                    domain_residue_counts[domain] = 0
                
                domain_residue_counts[domain] += len(chunk[chunk['domain_id'] == domain])
            
            # Reset iterator for next pass
            if i == 0:
                predictions_df = pd.read_csv(
                    predictions_path,
                    dtype={
                        'domain_id': 'category',
                        'resid': 'int32',
                        'resname': 'category',
                        'predicted_rmsf': 'float32',
                        'actual_rmsf': 'float32'
                    },
                    chunksize=100000
                )
        
        # Second pass for metrics calculation
        unique_domains = list(unique_domains)
        domain_batch_size = min(20, len(unique_domains))  # Process fewer domains at a time for chunked files
        
        for batch_start in range(0, len(unique_domains), domain_batch_size):
            batch_end = min(batch_start + domain_batch_size, len(unique_domains))
            batch_domains = unique_domains[batch_start:batch_end]
            
            logger.info(f"Processing domain metrics batch {batch_start//domain_batch_size + 1} "
                       f"(domains {batch_start} to {batch_end-1})")
            
            # Initialize domain data collectors
            domain_data_collectors = {domain: {'true': [], 'pred': []} for domain in batch_domains}
            
            # Reset iterator for processing
            predictions_df = pd.read_csv(
                predictions_path,
                dtype={
                    'domain_id': 'category',
                    'resid': 'int32',
                    'resname': 'category',
                    'predicted_rmsf': 'float32',
                    'actual_rmsf': 'float32'
                },
                chunksize=100000
            )
            
            # Collect data for each domain
            for chunk in predictions_df:
                for domain in batch_domains:
                    domain_rows = chunk[chunk['domain_id'] == domain]
                    if len(domain_rows) > 0:
                        domain_data_collectors[domain]['true'].extend(domain_rows['actual_rmsf'].values)
                        domain_data_collectors[domain]['pred'].extend(domain_rows['predicted_rmsf'].values)
                
                # Clear chunk from memory
                del chunk
                clear_memory(force_gc=True)
            
            # Calculate metrics for collected domain data
            for domain in batch_domains:
                domain_y_true = np.array(domain_data_collectors[domain]['true'])
                domain_y_pred = np.array(domain_data_collectors[domain]['pred'])
                
                # Skip if we don't have enough data
                if len(domain_y_true) < 2:
                    continue
                
                try:
                    domain_mse = mean_squared_error(domain_y_true, domain_y_pred)
                    domain_rmse = np.sqrt(domain_mse)
                    domain_mae = mean_absolute_error(domain_y_true, domain_y_pred)
                    domain_r2 = r2_score(domain_y_true, domain_y_pred)
                    
                    # Additional metrics for better evaluation
                    domain_mean_true = np.mean(domain_y_true)
                    domain_mean_pred = np.mean(domain_y_pred)
                    domain_median_true = np.median(domain_y_true)
                    domain_median_pred = np.median(domain_y_pred)
                    domain_cv_rmsd = domain_rmse / domain_mean_true * 100 if domain_mean_true > 0 else float('inf')
                    
                    # Calculate correlation coefficient
                    domain_corr = np.corrcoef(domain_y_true, domain_y_pred)[0, 1]
                    
                    domain_metrics[domain] = {
                        'mse': float(domain_mse),
                        'rmse': float(domain_rmse),
                        'mae': float(domain_mae),
                        'r2': float(domain_r2),
                        'corr': float(domain_corr),
                        'cv_rmsd': float(domain_cv_rmsd),
                        'mean_true': float(domain_mean_true),
                        'mean_pred': float(domain_mean_pred),
                        'median_true': float(domain_median_true),
                        'median_pred': float(domain_median_pred),
                        'num_residues': int(domain_residue_counts[domain])
                    }
                except Exception as e:
                    logger.warning(f"Error calculating metrics for domain {domain}: {str(e)}")
            
            # Clear collectors to free memory
            del domain_data_collectors
            clear_memory(force_gc=True)
            
            # Check memory pressure and take emergency measures if needed
            memory_stats = check_memory_usage()
            if memory_stats['system_percent'] > 85:
                logger.warning(f"Critical memory pressure during domain metrics: {memory_stats['system_percent']}%")
                logger.warning(f"Stopping domain metrics calculation to preserve memory integrity")
                break
    
    # MEMORY OPTIMIZATION: Check memory after domain-level metrics
    memory_stats = check_memory_usage()
    logger.info(f"Memory after domain metrics: {memory_stats['system_percent']}%, "
              f"{memory_stats['process_rss_gb']:.2f} GB")
    
    # Calculate residue type metrics if residue type info is available - with memory optimization
    residue_type_metrics = {}
    
    # Define a function to calculate metrics for residue types
    def calculate_residue_type_metrics(data_source):
        nonlocal residue_type_metrics
        
        if isinstance(data_source, pd.DataFrame):
            # For DataFrame case
            if 'resname' in data_source.columns:
                # Get unique residue types with at least 10 data points
                valid_restypes = []
                restype_counts = {}
                
                for resname in data_source['resname'].dropna().unique():
                    resname_df = data_source[data_source['resname'] == resname]
                    restype_counts[resname] = len(resname_df)
                    
                    if len(resname_df) >= 10:  # Need at least 10 points for meaningful statistics
                        valid_restypes.append(resname)
                
                # Calculate metrics for each valid residue type
                for resname in valid_restypes:
                    resname_df = data_source[data_source['resname'] == resname]
                    resname_y_true = resname_df['actual_rmsf'].values
                    resname_y_pred = resname_df['predicted_rmsf'].values
                    
                    try:
                        restype_mse = mean_squared_error(resname_y_true, resname_y_pred)
                        restype_rmse = np.sqrt(restype_mse)
                        restype_mae = mean_absolute_error(resname_y_true, resname_y_pred)
                        restype_r2 = r2_score(resname_y_true, resname_y_pred)
                        
                        # Additional statistics for better analysis
                        mean_true = np.mean(resname_y_true)
                        mean_pred = np.mean(resname_y_pred)
                        median_true = np.median(resname_y_true)
                        median_pred = np.median(resname_y_pred)
                        
                        # Calculate normalized RMSE (NRMSE)
                        range_true = np.max(resname_y_true) - np.min(resname_y_true)
                        nrmse = restype_rmse / range_true if range_true > 0 else float('inf')
                        
                        # Calculate correlation coefficient
                        restype_corr = np.corrcoef(resname_y_true, resname_y_pred)[0, 1]
                        
                        residue_type_metrics[resname] = {
                            'mse': float(restype_mse),
                            'rmse': float(restype_rmse),
                            'mae': float(restype_mae),
                            'r2': float(restype_r2),
                            'nrmse': float(nrmse),
                            'corr': float(restype_corr),
                            'mean_true': float(mean_true),
                            'mean_pred': float(mean_pred),
                            'median_true': float(median_true),
                            'median_pred': float(median_pred),
                            'num_residues': int(len(resname_df))
                        }
                    except Exception as e:
                        logger.warning(f"Error calculating metrics for residue type {resname}: {str(e)}")
        else:
            # For chunked DataFrame case
            # First pass to identify unique residue types and count
            residue_type_counts = {}
            
            for chunk in data_source:
                if 'resname' in chunk.columns:
                    for resname in chunk['resname'].dropna().unique():
                        if resname not in residue_type_counts:
                            residue_type_counts[resname] = 0
                        
                        residue_type_counts[resname] += len(chunk[chunk['resname'] == resname])
            
            # Identify valid residue types (at least 10 data points)
            valid_restypes = [resname for resname, count in residue_type_counts.items() if count >= 10]
            
            # Reset iterator for next pass
            nonlocal predictions_path
            predictions_df = pd.read_csv(
                predictions_path,
                dtype={
                    'domain_id': 'category',
                    'resid': 'int32',
                    'resname': 'category',
                    'predicted_rmsf': 'float32',
                    'actual_rmsf': 'float32'
                },
                chunksize=100000
            )
            
            # Second pass for metrics calculation
            # Process residue types in batches to manage memory
            restype_batch_size = min(10, len(valid_restypes))
            
            for batch_start in range(0, len(valid_restypes), restype_batch_size):
                batch_end = min(batch_start + restype_batch_size, len(valid_restypes))
                batch_restypes = valid_restypes[batch_start:batch_end]
                
                logger.info(f"Processing residue type metrics batch {batch_start//restype_batch_size + 1} "
                           f"(types {batch_start} to {batch_end-1})")
                
                # Initialize residue type data collectors
                restype_data_collectors = {resname: {'true': [], 'pred': []} for resname in batch_restypes}
                
                # Collect data for each residue type
                for chunk in predictions_df:
                    for resname in batch_restypes:
                        resname_rows = chunk[chunk['resname'] == resname]
                        if len(resname_rows) > 0:
                            restype_data_collectors[resname]['true'].extend(resname_rows['actual_rmsf'].values)
                            restype_data_collectors[resname]['pred'].extend(resname_rows['predicted_rmsf'].values)
                    
                    # Clear chunk from memory
                    del chunk
                    clear_memory(force_gc=True)
                
                # Reset iterator for next batch
                predictions_df = pd.read_csv(
                    predictions_path,
                    dtype={
                        'domain_id': 'category',
                        'resid': 'int32',
                        'resname': 'category',
                        'predicted_rmsf': 'float32',
                        'actual_rmsf': 'float32'
                    },
                    chunksize=100000
                )
                
                # Calculate metrics for collected residue type data
                for resname in batch_restypes:
                    resname_y_true = np.array(restype_data_collectors[resname]['true'])
                    resname_y_pred = np.array(restype_data_collectors[resname]['pred'])
                    
                    # Skip if we don't have enough data
                    if len(resname_y_true) < 10:
                        continue
                    
                    try:
                        restype_mse = mean_squared_error(resname_y_true, resname_y_pred)
                        restype_rmse = np.sqrt(restype_mse)
                        restype_mae = mean_absolute_error(resname_y_true, resname_y_pred)
                        restype_r2 = r2_score(resname_y_true, resname_y_pred)
                        
                        # Additional statistics for better analysis
                        mean_true = np.mean(resname_y_true)
                        mean_pred = np.mean(resname_y_pred)
                        median_true = np.median(resname_y_true)
                        median_pred = np.median(resname_y_pred)
                        
                        # Calculate normalized RMSE (NRMSE)
                        range_true = np.max(resname_y_true) - np.min(resname_y_true)
                        nrmse = restype_rmse / range_true if range_true > 0 else float('inf')
                        
                        # Calculate correlation coefficient
                        restype_corr = np.corrcoef(resname_y_true, resname_y_pred)[0, 1]
                        
                        residue_type_metrics[resname] = {
                            'mse': float(restype_mse),
                            'rmse': float(restype_rmse),
                            'mae': float(restype_mae),
                            'r2': float(restype_r2),
                            'nrmse': float(nrmse),
                            'corr': float(restype_corr),
                            'mean_true': float(mean_true),
                            'mean_pred': float(mean_pred),
                            'median_true': float(median_true),
                            'median_pred': float(median_pred),
                            'num_residues': int(residue_type_counts[resname])
                        }
                    except Exception as e:
                        logger.warning(f"Error calculating metrics for residue type {resname}: {str(e)}")
                
                # Clear collectors to free memory
                del restype_data_collectors
                clear_memory(force_gc=True)
                
                # Check memory pressure and take emergency measures if needed
                memory_stats = check_memory_usage()
                if memory_stats['system_percent'] > 85:
                    logger.warning(f"Critical memory pressure during residue type metrics: {memory_stats['system_percent']}%")
                    logger.warning(f"Stopping residue type metrics calculation to preserve memory integrity")
                    break
    
    # Calculate residue type metrics
    if isinstance(predictions_df, pd.DataFrame) or not isinstance(predictions_df, pd.DataFrame):
        try:
            calculate_residue_type_metrics(predictions_df)
        except Exception as e:
            logger.error(f"Error calculating residue type metrics: {str(e)}")
    
    # MEMORY OPTIMIZATION: Check memory after residue type metrics
    memory_stats = check_memory_usage()
    logger.info(f"Memory after residue type metrics: {memory_stats['system_percent']}%, "
               f"{memory_stats['process_rss_gb']:.2f} GB")
    
    # Calculate metrics for different RMSF ranges with memory optimization
    flexibility_metrics = {}
    
    # Define a function to calculate flexibility metrics
    def calculate_flexibility_metrics(data_source):
        nonlocal flexibility_metrics
        
        if isinstance(data_source, pd.DataFrame):
            # For DataFrame case
            y_true = data_source['actual_rmsf'].values
            y_pred = data_source['predicted_rmsf'].values
            
            # Define RMSF flexibility ranges
            low_flex_threshold = np.percentile(y_true, 33.3)
            high_flex_threshold = np.percentile(y_true, 66.7)
            
            # Low flexibility regions
            low_flex_mask = y_true <= low_flex_threshold
            if np.sum(low_flex_mask) >= 10:
                low_flex_true = y_true[low_flex_mask]
                low_flex_pred = y_pred[low_flex_mask]
                
                low_flex_metrics = {
                    'mse': float(mean_squared_error(low_flex_true, low_flex_pred)),
                    'rmse': float(np.sqrt(mean_squared_error(low_flex_true, low_flex_pred))),
                    'mae': float(mean_absolute_error(low_flex_true, low_flex_pred)),
                    'r2': float(r2_score(low_flex_true, low_flex_pred)),
                    'count': int(np.sum(low_flex_mask)),
                    'threshold': float(low_flex_threshold),
                    'mean_true': float(np.mean(low_flex_true)),
                    'mean_pred': float(np.mean(low_flex_pred))
                }
                flexibility_metrics['low_flexibility'] = low_flex_metrics
            
            # Medium flexibility regions
            med_flex_mask = (y_true > low_flex_threshold) & (y_true <= high_flex_threshold)
            if np.sum(med_flex_mask) >= 10:
                med_flex_true = y_true[med_flex_mask]
                med_flex_pred = y_pred[med_flex_mask]
                
                med_flex_metrics = {
                    'mse': float(mean_squared_error(med_flex_true, med_flex_pred)),
                    'rmse': float(np.sqrt(mean_squared_error(med_flex_true, med_flex_pred))),
                    'mae': float(mean_absolute_error(med_flex_true, med_flex_pred)),
                    'r2': float(r2_score(med_flex_true, med_flex_pred)),
                    'count': int(np.sum(med_flex_mask)),
                    'lower_threshold': float(low_flex_threshold),
                    'upper_threshold': float(high_flex_threshold),
                    'mean_true': float(np.mean(med_flex_true)),
                    'mean_pred': float(np.mean(med_flex_pred))
                }
                flexibility_metrics['medium_flexibility'] = med_flex_metrics
            
            # High flexibility regions
            high_flex_mask = y_true > high_flex_threshold
            if np.sum(high_flex_mask) >= 10:
                high_flex_true = y_true[high_flex_mask]
                high_flex_pred = y_pred[high_flex_mask]
                
                high_flex_metrics = {
                    'mse': float(mean_squared_error(high_flex_true, high_flex_pred)),
                    'rmse': float(np.sqrt(mean_squared_error(high_flex_true, high_flex_pred))),
                    'mae': float(mean_absolute_error(high_flex_true, high_flex_pred)),
                    'r2': float(r2_score(high_flex_true, high_flex_pred)),
                    'count': int(np.sum(high_flex_mask)),
                    'threshold': float(high_flex_threshold),
                    'mean_true': float(np.mean(high_flex_true)),
                    'mean_pred': float(np.mean(high_flex_pred))
                }
                flexibility_metrics['high_flexibility'] = high_flex_metrics
        else:
            # For chunked DataFrame case
            # First pass to calculate percentiles
            y_true_values = []
            
            # Sample up to 100,000 values for percentile calculation
            total_sampled = 0
            for chunk in data_source:
                if total_sampled < 100000:
                    sample_size = min(len(chunk), 100000 - total_sampled)
                    if sample_size > 0:
                        sampled_indices = np.random.choice(len(chunk), sample_size, replace=False)
                        y_true_values.extend(chunk['actual_rmsf'].values[sampled_indices])
                        total_sampled += sample_size
            
            # Calculate percentiles
            y_true_array = np.array(y_true_values)
            low_flex_threshold = np.percentile(y_true_array, 33.3)
            high_flex_threshold = np.percentile(y_true_array, 66.7)
            
            # Clear sampled values to save memory
            del y_true_values, y_true_array
            clear_memory(force_gc=True)
            
            # Reset iterator for next pass
            nonlocal predictions_path
            predictions_df = pd.read_csv(
                predictions_path,
                dtype={
                    'domain_id': 'category',
                    'resid': 'int32',
                    'resname': 'category',
                    'predicted_rmsf': 'float32',
                    'actual_rmsf': 'float32'
                },
                chunksize=100000
            )
            
            # Initialize collectors for each flexibility range
            low_flex_collector = {'true': [], 'pred': [], 'count': 0}
            med_flex_collector = {'true': [], 'pred': [], 'count': 0}
            high_flex_collector = {'true': [], 'pred': [], 'count': 0}
            
            # Second pass to collect data for each flexibility range
            for chunk in predictions_df:
                chunk_y_true = chunk['actual_rmsf'].values
                chunk_y_pred = chunk['predicted_rmsf'].values
                
                # Low flexibility
                low_flex_mask = chunk_y_true <= low_flex_threshold
                if np.sum(low_flex_mask) > 0:
                    low_flex_collector['true'].extend(chunk_y_true[low_flex_mask])
                    low_flex_collector['pred'].extend(chunk_y_pred[low_flex_mask])
                    low_flex_collector['count'] += np.sum(low_flex_mask)
                
                # Medium flexibility
                med_flex_mask = (chunk_y_true > low_flex_threshold) & (chunk_y_true <= high_flex_threshold)
                if np.sum(med_flex_mask) > 0:
                    med_flex_collector['true'].extend(chunk_y_true[med_flex_mask])
                    med_flex_collector['pred'].extend(chunk_y_pred[med_flex_mask])
                    med_flex_collector['count'] += np.sum(med_flex_mask)
                
                # High flexibility
                high_flex_mask = chunk_y_true > high_flex_threshold
                if np.sum(high_flex_mask) > 0:
                    high_flex_collector['true'].extend(chunk_y_true[high_flex_mask])
                    high_flex_collector['pred'].extend(chunk_y_pred[high_flex_mask])
                    high_flex_collector['count'] += np.sum(high_flex_mask)
                
                # Clear chunk from memory
                del chunk
                clear_memory(force_gc=True)
                
                # Sample data if collectors get too large to avoid memory issues
                for collector in [low_flex_collector, med_flex_collector, high_flex_collector]:
                    if len(collector['true']) > 100000:
                        sample_indices = np.random.choice(len(collector['true']), 50000, replace=False)
                        collector['true'] = [collector['true'][i] for i in sample_indices]
                        collector['pred'] = [collector['pred'][i] for i in sample_indices]
                
                # Check memory pressure and take emergency measures if needed
                memory_stats = check_memory_usage()
                if memory_stats['system_percent'] > 85:
                    logger.warning(f"Critical memory pressure during flexibility metrics: {memory_stats['system_percent']}%")
                    logger.warning(f"Stopping flexibility metrics calculation to preserve memory integrity")
                    break
            
            # Calculate metrics for each flexibility range
            # Low flexibility
            if low_flex_collector['count'] >= 10:
                low_flex_true = np.array(low_flex_collector['true'])
                low_flex_pred = np.array(low_flex_collector['pred'])
                
                low_flex_metrics = {
                    'mse': float(mean_squared_error(low_flex_true, low_flex_pred)),
                    'rmse': float(np.sqrt(mean_squared_error(low_flex_true, low_flex_pred))),
                    'mae': float(mean_absolute_error(low_flex_true, low_flex_pred)),
                    'r2': float(r2_score(low_flex_true, low_flex_pred)),
                    'count': int(low_flex_collector['count']),
                    'threshold': float(low_flex_threshold),
                    'mean_true': float(np.mean(low_flex_true)),
                    'mean_pred': float(np.mean(low_flex_pred))
                }
                flexibility_metrics['low_flexibility'] = low_flex_metrics
                
                # Clear collector to save memory
                del low_flex_true, low_flex_pred
                clear_memory(force_gc=True)
            
            # Medium flexibility
            if med_flex_collector['count'] >= 10:
                med_flex_true = np.array(med_flex_collector['true'])
                med_flex_pred = np.array(med_flex_collector['pred'])
                
                med_flex_metrics = {
                    'mse': float(mean_squared_error(med_flex_true, med_flex_pred)),
                    'rmse': float(np.sqrt(mean_squared_error(med_flex_true, med_flex_pred))),
                    'mae': float(mean_absolute_error(med_flex_true, med_flex_pred)),
                    'r2': float(r2_score(med_flex_true, med_flex_pred)),
                    'count': int(med_flex_collector['count']),
                    'lower_threshold': float(low_flex_threshold),
                    'upper_threshold': float(high_flex_threshold),
                    'mean_true': float(np.mean(med_flex_true)),
                    'mean_pred': float(np.mean(med_flex_pred))
                }
                flexibility_metrics['medium_flexibility'] = med_flex_metrics
                
                # Clear collector to save memory
                del med_flex_true, med_flex_pred
                clear_memory(force_gc=True)
            
            # High flexibility
            if high_flex_collector['count'] >= 10:
                high_flex_true = np.array(high_flex_collector['true'])
                high_flex_pred = np.array(high_flex_collector['pred'])
                
                high_flex_metrics = {
                    'mse': float(mean_squared_error(high_flex_true, high_flex_pred)),
                    'rmse': float(np.sqrt(mean_squared_error(high_flex_true, high_flex_pred))),
                    'mae': float(mean_absolute_error(high_flex_true, high_flex_pred)),
                    'r2': float(r2_score(high_flex_true, high_flex_pred)),
                    'count': int(high_flex_collector['count']),
                    'threshold': float(high_flex_threshold),
                    'mean_true': float(np.mean(high_flex_true)),
                    'mean_pred': float(np.mean(high_flex_pred))
                }
                flexibility_metrics['high_flexibility'] = high_flex_metrics
                
                # Clear collector to save memory
                del high_flex_true, high_flex_pred
                clear_memory(force_gc=True)
            
            # Clear all collectors to save memory
            del low_flex_collector, med_flex_collector, high_flex_collector
            clear_memory(force_gc=True)
    
    # Calculate flexibility metrics
    if isinstance(predictions_df, pd.DataFrame) or not isinstance(predictions_df, pd.DataFrame):
        try:
            calculate_flexibility_metrics(predictions_df)
        except Exception as e:
            logger.error(f"Error calculating flexibility metrics: {str(e)}")
    
    # MEMORY OPTIMIZATION: Check memory after flexibility metrics
    memory_stats = check_memory_usage()
    logger.info(f"Memory after flexibility metrics: {memory_stats['system_percent']}%, "
               f"{memory_stats['process_rss_gb']:.2f} GB")
    
    # Log overall metrics
    logger.info(f"Overall Mean Squared Error (MSE): {mse:.6f}")
    logger.info(f"Overall Root Mean Squared Error (RMSE): {rmse:.6f}")
    logger.info(f"Overall Mean Absolute Error (MAE): {mae:.6f}")
    logger.info(f"Overall R²: {r2:.6f}")
    logger.info(f"Overall CV-RMSD: {cv_rmsd:.2f}%")
    logger.info(f"Mean Relative Error: {mean_relative_error:.2f}%")
    
    # Save metrics
    metrics = {
        'overall': {
            'mse': float(mse),
            'rmse': float(rmse),
            'mae': float(mae),
            'r2': float(r2),
            'cv_rmsd': float(cv_rmsd),
            'mean_relative_error': float(mean_relative_error),
            'median_relative_error': float(median_relative_error),
            'num_samples': int(count) if not isinstance(predictions_df, pd.DataFrame) else int(len(predictions_df)),
            'num_domains': int(len(domain_metrics)) if domain_metrics else None,
        }
    }
    
    # Add mean and median info to overall metrics if possible
    if isinstance(predictions_df, pd.DataFrame):
        metrics['overall'].update({
            'mean_true': float(np.mean(predictions_df['actual_rmsf'])),
            'mean_pred': float(np.mean(predictions_df['predicted_rmsf'])),
            'median_true': float(np.median(predictions_df['actual_rmsf'])),
            'median_pred': float(np.median(predictions_df['predicted_rmsf'])),
            'std_true': float(np.std(predictions_df['actual_rmsf'])),
            'std_pred': float(np.std(predictions_df['predicted_rmsf']))
        })
    
    # Add other metrics
    metrics['domains'] = domain_metrics
    metrics['residue_types'] = residue_type_metrics
    metrics['flexibility_regions'] = flexibility_metrics
    
    # Add model information if available
    try:
        device = torch.device('cpu')  # Use CPU for checkpoint loading to save GPU memory
        checkpoint = torch.load(model_path, map_location=device)
        
        model_info = {
            'architecture': checkpoint.get('config', {}).get('model', {}).get('architecture', 'unknown'),
            'total_domains_used': len(checkpoint.get('processed_domains', [])),
            'learning_rate': checkpoint.get('config', {}).get('training', {}).get('learning_rate', 'unknown'),
            'epochs': checkpoint.get('epoch', 'unknown'),
            'best_val_loss': checkpoint.get('best_val_loss', 'unknown')
        }
        metrics['model_info'] = model_info
        
        del checkpoint
        clear_memory(force_gc=True)
    except Exception as e:
        logger.warning(f"Could not extract model information: {str(e)}")
    
    # Save domain performance rankings
    if domain_metrics:
        try:
            # Rank domains by R² performance
            domain_performances = [(domain, metrics['r2']) for domain, metrics in domain_metrics.items()]
            domain_performances.sort(key=lambda x: x[1], reverse=True)
            
            # Only take top/bottom 10 for memory efficiency
            best_domains = domain_performances[:10]
            worst_domains = domain_performances[-10:]
            
            domain_rankings = {
                'best_domains': {domain: domain_metrics[domain] for domain, _ in best_domains},
                'worst_domains': {domain: domain_metrics[domain] for domain, _ in worst_domains}
            }
            
            metrics['domain_rankings'] = domain_rankings
        except Exception as e:
            logger.warning(f"Error creating domain rankings: {str(e)}")
    
    # Save residue type rankings
    if residue_type_metrics:
        try:
            # Rank residue types by R² performance
            restype_performances = [(restype, metrics['r2']) for restype, metrics in residue_type_metrics.items()]
            restype_performances.sort(key=lambda x: x[1], reverse=True)
            
            # Only take top/bottom 5 for memory efficiency
            best_restypes = restype_performances[:5]
            worst_restypes = restype_performances[-5:]
            
            restype_rankings = {
                'best_residue_types': {restype: residue_type_metrics[restype] for restype, _ in best_restypes},
                'worst_residue_types': {restype: residue_type_metrics[restype] for restype, _ in worst_restypes}
            }
            
            metrics['residue_type_rankings'] = restype_rankings
        except Exception as e:
            logger.warning(f"Error creating residue type rankings: {str(e)}")
    
    # Clear memory before saving
    clear_memory(force_gc=True)
    
    # Save metrics
    metrics_dir = os.path.join(config["output"]["base_dir"], "metrics")
    ensure_dir(metrics_dir)
    
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    metrics_path = os.path.join(metrics_dir, f"metrics_{timestamp}.json")
    
    save_json(metrics, metrics_path)
    logger.info(f"Metrics saved to {metrics_path}")
    
    # Generate summary for console output
    logger.info("=" * 40)
    logger.info("EVALUATION SUMMARY")
    logger.info("=" * 40)
    logger.info(f"Overall R²: {r2:.4f}")
    logger.info(f"RMSE: {rmse:.4f}")
    logger.info(f"MAE: {mae:.4f}")
    logger.info(f"CV-RMSD: {cv_rmsd:.2f}%")
    
    if 'domains' in metrics:
        r2_values = [m['r2'] for m in metrics['domains'].values()]
        logger.info(f"Domain R² - Mean: {np.mean(r2_values):.4f}, Median: {np.median(r2_values):.4f}")
        logger.info(f"Domains with R² > 0.5: {sum(1 for r in r2_values if r > 0.5)} out of {len(r2_values)}")
    
    logger.info("=" * 40)
    
    # Final memory check
    memory_stats = check_memory_usage()
    logger.info(f"Final memory: {memory_stats['system_percent']}%, "
               f"{memory_stats['process_rss_gb']:.2f} GB")
    
    return metrics_path
===== FILE: src/voxelflex/cli/commands/predict.py =====
"""
Prediction command for Voxelflex (Memory-Optimized).

This version uses domain streaming and chunked loading akin to 'train.py' to
prevent memory blowups for large test sets.
"""

import os
import time
import json
from typing import Dict, Any, List, Optional, Tuple

import numpy as np
import pandas as pd
import torch
import h5py
import psutil
from torch.utils.data import DataLoader

from voxelflex.data.data_loader import (
    load_rmsf_data,
    RMSFDataset,
    create_domain_mapping,
    create_optimized_rmsf_lookup,
    check_memory_usage,
    clear_memory,
)
from voxelflex.models.cnn_models import get_model
from voxelflex.utils.logging_utils import (
    get_logger,
    EnhancedProgressBar,
    log_memory_usage,
)
from voxelflex.utils.file_utils import ensure_dir
from voxelflex.utils.system_utils import (
    get_device,
    set_num_threads,
    is_memory_critical,
    adjust_workers_for_memory,
    emergency_memory_reduction
)

# If you have a function like 'load_domain_batch' or 'prepare_dataloaders'
# in your codebase (from train.py), import and reuse it here:
from voxelflex.data.data_loader import load_domain_batch

from voxelflex.utils.system_utils import MEMORY_WARNING_THRESHOLD, MEMORY_CRITICAL_THRESHOLD, MEMORY_EMERGENCY_THRESHOLD


logger = get_logger(__name__)


def predict_rmsf(
    config: Dict[str, Any],
    model_path: str,
    domain_ids: Optional[List[str]] = None
) -> str:
    """
    Make predictions with a trained model using domain streaming with improved memory management.
    
    Args:
        config: Configuration dictionary
        model_path: Path to the trained model file
        domain_ids: Optional subset of domain IDs to predict on.
                   If not provided, will infer from all domains in the voxel file.
        
    Returns:
        Path to the predictions CSV file
    """
    logger.info("=" * 60)
    logger.info("STARTING MEMORY-OPTIMIZED PREDICTION PROCESS")
    logger.info("=" * 60)
    logger.info(f"Model checkpoint: {model_path}")
    
    # 1. Check memory right away
    memory_stats = check_memory_usage()
    logger.info(f"Initial memory usage: System: {memory_stats['system_percent']}%, "
                f"Process: {memory_stats['process_rss_gb']:.2f} GB")
    
    # MEMORY OPTIMIZATION: If memory is already high, try to reduce it
    if memory_stats['system_percent'] > MEMORY_WARNING_THRESHOLD * 100:
        logger.warning(f"Starting prediction with high memory usage: {memory_stats['system_percent']}%")
        logger.warning("Attempting memory reduction before continuing")
        emergency_memory_reduction()
        
        # Check again after reduction
        memory_stats = check_memory_usage()
        if memory_stats['system_percent'] > MEMORY_CRITICAL_THRESHOLD * 100:
            logger.error(f"Cannot start prediction with memory usage at {memory_stats['system_percent']}%")
            logger.error("Please free up system memory before running prediction")
            raise MemoryError("Insufficient memory to begin prediction")

    # 2. Get device (CPU/GPU)
    device = get_device(config["system_utilization"]["adjust_for_gpu"])
    logger.info(f"Using device: {device}")
    
    # 3. Load the model checkpoint
    clear_memory(force_gc=True, clear_cuda=(device.type == 'cuda'))
    logger.info(f"Loading model from {model_path}")
    
    try:
        # MEMORY OPTIMIZATION: Load checkpoint carefully
        checkpoint = torch.load(model_path, map_location='cpu')  # Initially load to CPU
        model_config = checkpoint.get('config', {}).get('model', config['model'])
        input_shape = checkpoint.get('input_shape')
        
        # Create the model
        model = get_model(
            architecture=model_config['architecture'],
            input_channels=model_config['input_channels'],
            channel_growth_rate=model_config['channel_growth_rate'],
            num_residual_blocks=model_config['num_residual_blocks'],
            dropout_rate=model_config['dropout_rate'],
            base_filters=model_config['base_filters']
        )
        
        # Load the state dict
        model.load_state_dict(checkpoint['model_state_dict'])
        
        # Only now move to device
        model.to(device)
        model.eval()
        
        # MEMORY OPTIMIZATION: Extract only what we need, then delete checkpoint
        processed_domains = checkpoint.get('processed_domains', [])
        logger.info(f"Model was trained on {len(processed_domains)} domains")
        
        del checkpoint
        clear_memory(force_gc=True, clear_cuda=(device.type == 'cuda'))
    except Exception as e:
        logger.error(f"Error loading model: {str(e)}")
        raise
    
    # 4. Load RMSF data in a memory-efficient way
    logger.info("Loading RMSF data for residue information...")
    try:
        rmsf_data = load_rmsf_data(
            rmsf_dir=config["input"]["rmsf_dir"],
            replica=config["input"].get("replica", "replica_average"),
            temperature=config["input"]["temperature"]
        )
        # Create a global RMSF lookup to speed up merges
        global_rmsf_lookup = create_optimized_rmsf_lookup(rmsf_data)
        
        # MEMORY OPTIMIZATION: Check memory after loading RMSF data
        memory_stats = check_memory_usage()
        logger.info(f"Memory after loading RMSF data: {memory_stats['system_percent']}%")
        
        if memory_stats['system_percent'] > MEMORY_CRITICAL_THRESHOLD * 100:
            logger.warning(f"Critical memory usage after loading RMSF data: {memory_stats['system_percent']}%")
            emergency_memory_reduction()
    except Exception as e:
        logger.error(f"Error loading RMSF data: {str(e)}")
        raise
    
    # 5. Figure out which domains we are predicting. If domain_ids not given, use all.
    voxel_file = config["input"]["voxel_file"]
    if not os.path.exists(voxel_file):
        raise FileNotFoundError(f"Voxel file not found: {voxel_file}")
    
    try:
        all_available_domains = []
        with h5py.File(voxel_file, 'r') as f:
            all_available_domains = list(f.keys())
        
        logger.info(f"Found {len(all_available_domains)} domains in HDF5 file")
        
        if domain_ids and len(domain_ids) > 0:
            # Filter the HDF5 domains based on the user-provided domain list
            all_domains = []
            for d in all_available_domains:
                base_d = d.split('_')[0]
                if base_d in domain_ids or d in domain_ids:
                    all_domains.append(d)
            if not all_domains:
                logger.warning("None of the specified domain_ids found. Using all available domains instead.")
                all_domains = all_available_domains
        else:
            # Use everything
            all_domains = all_available_domains
        
        logger.info(f"Total domains available for prediction: {len(all_domains)}")
    except Exception as e:
        logger.error(f"Error reading domains from HDF5 file: {str(e)}")
        raise
    
    # 6. MEMORY OPTIMIZATION: Decide how many domains to load per batch based on memory
    memory_stats = check_memory_usage()
    system_memory_percent = memory_stats["system_percent"]
    
    # Calculate domains_per_batch conservatively based on current memory pressure
    if system_memory_percent > 70:  # High memory pressure
        domains_per_batch = min(10, config["prediction"].get("domains_per_batch", 50) // 4)
        logger.warning(f"High memory pressure ({system_memory_percent:.1f}%), using reduced batch size of {domains_per_batch} domains")
    elif system_memory_percent > 60:  # Moderate memory pressure
        domains_per_batch = min(20, config["prediction"].get("domains_per_batch", 50) // 2)
        logger.warning(f"Moderate memory pressure ({system_memory_percent:.1f}%), using reduced batch size of {domains_per_batch} domains")
    else:  # Normal memory pressure
        domains_per_batch = min(50, config["prediction"].get("domains_per_batch", 50))
        logger.info(f"Normal memory usage ({system_memory_percent:.1f}%), using batch size of {domains_per_batch} domains")
    
    logger.info(f"Using domain batch size: {domains_per_batch}")
    
    # 7. Create domain batches
    domain_indices = np.arange(len(all_domains))
    test_domain_batches = [
        domain_indices[i : i + domains_per_batch]
        for i in range(0, len(domain_indices), domains_per_batch)
    ]
    logger.info(f"Created {len(test_domain_batches)} domain batches for prediction")
    
    # 8. MEMORY OPTIMIZATION: Prepare to store predictions more efficiently
    # Instead of accumulating in memory, write directly to disk in chunks
    predictions_dir = os.path.join(config["output"]["base_dir"], "metrics")
    ensure_dir(predictions_dir)
    
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    predictions_path = os.path.join(predictions_dir, f"predictions_{timestamp}.csv")
    
    # Write CSV header
    with open(predictions_path, 'w') as f:
        f.write("domain_id,resid,resname,predicted_rmsf,actual_rmsf\n")
    
    # 9. For progress logging
    show_progress = config["logging"]["show_progress_bars"]
    outer_progress = None
    if show_progress:
        outer_progress = EnhancedProgressBar(
            total=len(test_domain_batches),
            prefix="Overall Prediction Batches",
            suffix="Complete",
            stage_info="PREDICTION"
        )
    
    # 10. MEMORY OPTIMIZATION: Track batches processed and total predictions for reporting
    batches_processed = 0
    total_predictions = 0
    
    # 11. Predict in a loop over domain batches
    with torch.no_grad():
        for batch_idx, domain_batch_idx in enumerate(test_domain_batches):
            batch_start_time = time.time()
            
            # MEMORY OPTIMIZATION: Check memory before loading batch
            memory_stats = check_memory_usage()
            if memory_stats['system_percent'] > MEMORY_CRITICAL_THRESHOLD * 100:
                logger.warning(f"Critical memory usage ({memory_stats['system_percent']:.1f}%) before batch {batch_idx+1}")
                logger.warning("Performing emergency memory reduction")
                emergency_memory_reduction()
                
                # If still critical, we need to skip this batch
                memory_stats = check_memory_usage()
                if memory_stats['system_percent'] > MEMORY_EMERGENCY_THRESHOLD * 100:
                    logger.error(f"Memory usage still critical ({memory_stats['system_percent']:.1f}%) after reduction")
                    logger.error(f"Skipping batch {batch_idx+1} to prevent system crash")
                    
                    if outer_progress:
                        outer_progress.update(batch_idx+1)
                    
                    continue
            
            batch_domains = [all_domains[i] for i in domain_batch_idx]
            
            logger.info(f"\n--- Processing Batch {batch_idx+1}/{len(test_domain_batches)} with {len(batch_domains)} domains ---")
            
            # (a) Load domain batch from HDF5
            try:
                domain_voxel_data = load_domain_batch(domain_batch_idx, all_domains, config)
                
                if not domain_voxel_data:
                    logger.warning("No voxel data loaded for this batch. Skipping.")
                    if outer_progress:
                        outer_progress.update(batch_idx+1)
                    continue
            except Exception as e:
                logger.error(f"Error loading domain batch: {str(e)}")
                if outer_progress:
                    outer_progress.update(batch_idx+1)
                continue
            
            # Check memory after loading domains
            memory_stats = check_memory_usage()
            logger.info(f"Memory after loading domains: {memory_stats['system_percent']}%")
            
            # (b) Create domain mapping
            voxel_domains = list(domain_voxel_data.keys())
            rmsf_domains = rmsf_data['domain_id'].unique().tolist()
            domain_mapping = create_domain_mapping(voxel_domains, rmsf_domains)
            
            # (c) Build a memory-optimized dataset
            try:
                dataset = RMSFDataset(
                    voxel_data=domain_voxel_data,
                    rmsf_data=rmsf_data,
                    domain_mapping=domain_mapping,
                    transform=None,
                    memory_efficient=True,  # CHANGE: Always use memory-efficient mode
                    global_rmsf_lookup=global_rmsf_lookup
                )
            except Exception as e:
                logger.error(f"Error creating dataset: {str(e)}")
                del domain_voxel_data
                clear_memory(force_gc=True, clear_cuda=(device.type == 'cuda'))
                if outer_progress:
                    outer_progress.update(batch_idx+1)
                continue
            
            # (d) MEMORY OPTIMIZATION: Use much smaller batch size for DataLoader
            memory_stats = check_memory_usage()
            if memory_stats['system_percent'] > 80:
                # Very high memory pressure - use minimal batch size
                predicted_batch_size = 8
                logger.warning(f"Very high memory pressure ({memory_stats['system_percent']:.1f}%). Using minimal batch size of {predicted_batch_size}.")
            elif memory_stats['system_percent'] > 70:
                # High memory pressure - use small batch size
                predicted_batch_size = 16
                logger.warning(f"High memory pressure ({memory_stats['system_percent']:.1f}%). Using reduced batch size of {predicted_batch_size}.")
            else:
                # Normal memory pressure - use moderate batch size
                predicted_batch_size = min(32, config["prediction"].get("batch_size", 32))
                logger.info(f"Using batch size: {predicted_batch_size}")
            
            # (e) MEMORY OPTIMIZATION: Use minimal workers
            num_workers = config['system_utilization']['num_workers']
            
            logger.info(f"DataLoader batch_size={predicted_batch_size}, num_workers={num_workers}")
            
            try:
                test_loader = DataLoader(
                    dataset,
                    batch_size=predicted_batch_size,
                    shuffle=False,
                    num_workers=num_workers,
                    pin_memory=(device.type == 'cuda'),
                    persistent_workers=False,
                )
            except Exception as e:
                logger.error(f"Error creating DataLoader: {str(e)}")
                del domain_voxel_data, dataset
                clear_memory(force_gc=True, clear_cuda=(device.type == 'cuda'))
                if outer_progress:
                    outer_progress.update(batch_idx+1)
                continue
            
            # (f) MEMORY OPTIMIZATION: Predict and write directly to file in chunks
            batch_predictions = []
            batch_progress = None
            if show_progress:
                batch_progress = EnhancedProgressBar(
                    total=len(test_loader),
                    prefix=f"Predicting Batch {batch_idx+1}",
                    suffix="Complete",
                    stage_info="BATCH_PRED"
                )
            
            # For chunked file writing
            chunk_size = 1000
            predictions_chunk = []
            total_batch_predictions = 0
            
            sample_offset = 0
            try:
                for i, (inputs, targets) in enumerate(test_loader):
                    # MEMORY OPTIMIZATION: Check memory inside prediction loop
                    if i > 0 and i % 20 == 0:
                        memory_stats = check_memory_usage()
                        if memory_stats['system_percent'] > MEMORY_CRITICAL_THRESHOLD * 100:
                            logger.warning(f"Critical memory usage ({memory_stats['system_percent']:.1f}%) during prediction. Emergency reduction...")
                            emergency_memory_reduction()
                    
                    inputs = inputs.to(device)
                    
                    # forward pass
                    outputs = model(inputs)
                    
                    # Move predictions and targets back to CPU
                    outputs_cpu = outputs.cpu().numpy()
                    targets_cpu = targets.cpu().numpy()
                    
                    # Domain/residue info from dataset
                    start_idx = sample_offset
                    end_idx = sample_offset + len(inputs)
                    sample_indices = range(start_idx, end_idx)
                    
                    # Gather per-sample predictions as CSV rows
                    for idx_in_batch, sample_idx_in_dataset in enumerate(sample_indices):
                        try:
                            domain_id, resid = dataset.samples[sample_idx_in_dataset]
                            pred_val = float(outputs_cpu[idx_in_batch])
                            true_val = float(targets_cpu[idx_in_batch])
                            
                            # Try to get residue name if available
                            resname = "UNK"
                            try:
                                # Check if resname is available via lookup
                                lookup_key = (domain_mapping.get(domain_id, domain_id), int(resid))
                                if lookup_key in global_rmsf_lookup:
                                    domain_filter = rmsf_data['domain_id'] == lookup_key[0]
                                    resid_filter = rmsf_data['resid'] == lookup_key[1]
                                    matching_rows = rmsf_data[domain_filter & resid_filter]
                                    if not matching_rows.empty:
                                        resname = matching_rows.iloc[0]['resname']
                            except Exception:
                                pass  # Keep default "UNK" if lookup fails
                            
                            # Add to chunk
                            predictions_chunk.append(f"{domain_id},{resid},{resname},{pred_val:.6f},{true_val:.6f}")
                            total_batch_predictions += 1
                            
                            # Write chunk to file when it reaches chunk_size
                            if len(predictions_chunk) >= chunk_size:
                                with open(predictions_path, 'a') as f:
                                    f.write('\n'.join(predictions_chunk) + '\n')
                                predictions_chunk = []
                        except Exception as e:
                            logger.warning(f"Error processing prediction for sample {sample_idx_in_dataset}: {str(e)}")
                    
                    sample_offset += len(inputs)
                    
                    # Clean up
                    del inputs, outputs, outputs_cpu, targets_cpu
                    
                    if batch_progress:
                        batch_progress.update(i + 1)
                    
                    # MEMORY OPTIMIZATION: Periodically clear CUDA cache
                    if (i + 1) % 5 == 0 and device.type == 'cuda':
                        torch.cuda.empty_cache()
            except Exception as e:
                logger.error(f"Error during prediction: {str(e)}")
            
            # Write any remaining predictions
            if predictions_chunk:
                with open(predictions_path, 'a') as f:
                    f.write('\n'.join(predictions_chunk) + '\n')
            
            if batch_progress:
                batch_progress.finish()
            
            # Update total predictions count
            total_predictions += total_batch_predictions
            logger.info(f"Processed {total_batch_predictions} predictions from batch {batch_idx+1}")
            
            # Done with this domain batch. Clean up, free memory.
            del domain_voxel_data, dataset, test_loader
            clear_memory(force_gc=True, clear_cuda=(device.type == 'cuda'))
            
            batches_processed += 1
            batch_duration = time.time() - batch_start_time
            logger.info(f"Finished Batch {batch_idx+1}/{len(test_domain_batches)} in {batch_duration:.2f}s")
            
            if outer_progress:
                outer_progress.update(batch_idx+1)
                
            
            # MEMORY OPTIMIZATION: Check if system memory is critical, exit gracefully if needed
            memory_stats = check_memory_usage()
            if memory_stats["system_percent"] > MEMORY_EMERGENCY_THRESHOLD * 100:
                logger.critical(f"System memory critically high ({memory_stats['system_percent']:.1f}%), stopping predictions to prevent crash")
                logger.critical(f"Processed {batches_processed}/{len(test_domain_batches)} batches before stopping")
                break
    
    if outer_progress:
        outer_progress.finish()
    
    logger.info(f"\nCompleted prediction with {total_predictions} total predictions from {batches_processed} batches")
    logger.info(f"Predictions saved to {predictions_path}")
    logger.info("PREDICTION PROCESS COMPLETED SUCCESSFULLY")
    
    # Final memory cleanup
    clear_memory(force_gc=True, clear_cuda=True, aggressive=True)
    
    return predictions_path
===== FILE: src/voxelflex/cli/commands/train.py =====
"""
Training command for Voxelflex.

This module handles the training of RMSF prediction models.
"""

import os
import time
import json
from typing import Dict, Any, Tuple, List, Optional

import numpy as np
import torch
import gc
import torch.nn as nn
import h5py
import torch.optim as optim
from torch.utils.data import DataLoader

from voxelflex.data.data_loader import load_voxel_data, load_domain_batch, load_rmsf_data, prepare_dataloaders, create_domain_mapping, check_memory_usage, clear_memory, RMSFDataset, validate_rmsf_data
from voxelflex.models.cnn_models import get_model
from voxelflex.utils.logging_utils import pipeline_tracker, ProgressBar, get_logger, setup_logging, EnhancedProgressBar, log_memory_usage, log_operation_result, log_section_header, log_stage, log_step
from voxelflex.utils.file_utils import ensure_dir, save_json, load_json, save_domain_registry, load_domain_registry
from voxelflex.utils.system_utils import get_device, check_system_resources, clear_memory, check_memory_usage, emergency_memory_reduction, set_num_threads, is_memory_critical, estimate_batch_size, adjust_workers_for_memory, MEMORY_WARNING_THRESHOLD, MEMORY_CRITICAL_THRESHOLD, MEMORY_EMERGENCY_THRESHOLD

logger = get_logger(__name__)


def train_epoch(
    model: nn.Module,
    train_loader: DataLoader,
    criterion: nn.Module,
    optimizer: optim.Optimizer,
    device: torch.device,
    epoch: int,
    show_progress: bool = True,
    memory_efficient: bool = True,  # Enable memory efficiency by default
    scaler = None,  # Add scaler for mixed precision training
    gradient_clip_norm: Optional[float] = None  # For gradient clipping
) -> float:
    """
    Train model for one epoch with enhanced GPU utilization.
    
    Args:
        model: PyTorch model
        train_loader: Training data loader
        criterion: Loss function
        optimizer: Optimizer
        device: Device to train on (CPU or GPU)
        epoch: Current epoch number
        show_progress: Whether to show progress bar
        memory_efficient: Whether to use memory-efficient mode
        scaler: GradScaler for mixed precision training
        gradient_clip_norm: Maximum norm for gradient clipping
        
    Returns:
        Average training loss for the epoch
    """
    model.train()
    running_loss = 0.0
    total_batches = len(train_loader)
    logger = get_logger(__name__)
    
    if show_progress:
        # Enhanced progress bar with memory tracking
        progress = EnhancedProgressBar(
            total=total_batches, 
            prefix=f"Epoch {epoch+1} Training", 
            suffix="Complete",
            stage_info="Training"
        )
    
    # Log at beginning of epoch
    log_memory_usage(logger)
    
    # Track time for detailed performance monitoring
    batch_times = []
    forward_times = []
    backward_times = []
    
    # MEMORY OPTIMIZATION: Process in larger chunks (increased from 50)
    processed_batches = 0
    chunk_size = 200 if memory_efficient else total_batches  # Process 200 batches at a time
    
    while processed_batches < total_batches:
        end_batch = min(processed_batches + chunk_size, total_batches)
        
        # Process a chunk of batches
        for i, (inputs, targets) in enumerate(train_loader):
            if i < processed_batches:
                continue
            if i >= end_batch:
                break
            
            batch_start = time.time()
            
            # Move data to device
            inputs = inputs.to(device, non_blocking=True)  # Use non_blocking for better CPU-GPU overlap
            targets = targets.to(device, non_blocking=True)
            
            # Zero the parameter gradients
            optimizer.zero_grad(set_to_none=True)  # set_to_none=True is more memory efficient
            
            # Forward pass with mixed precision if available
            forward_start = time.time()
            
            # Use mixed precision training if scaler is provided
            if scaler is not None and device.type == 'cuda':
                with torch.cuda.amp.autocast():
                    outputs = model(inputs)
                    loss = criterion(outputs, targets)
                
                # Backward pass with scaler and gradient clipping
                backward_start = time.time()
                scaler.scale(loss).backward()
                
                # Apply gradient clipping if enabled
                if gradient_clip_norm is not None:
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_norm)
                    
                scaler.step(optimizer)
                scaler.update()
            else:
                # Standard precision training
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                
                # Backward pass
                backward_start = time.time()
                loss.backward()
                
                # Apply gradient clipping if enabled
                if gradient_clip_norm is not None:
                    torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_norm)
                
                optimizer.step()
            
            forward_time = backward_start - forward_start
            backward_time = time.time() - backward_start
            
            forward_times.append(forward_time)
            backward_times.append(backward_time)
            
            # Statistics
            batch_time = time.time() - batch_start
            batch_times.append(batch_time)
            running_loss += loss.item()
            
            if show_progress:
                progress.update(i + 1)
            
            # Periodically log detailed performance metrics (reduced frequency)
            if (i + 1) % 100 == 0 or i + 1 == total_batches:  # Increased from 50
                logger.debug(
                    f"Batch {i+1}/{total_batches} - Loss: {loss.item():.6f}, "
                    f"Time: {batch_time:.3f}s (F: {forward_time:.3f}s, B: {backward_time:.3f}s)"
                )
            
            # Monitor for training divergence
            if loss.item() > 10.0:  # Set a reasonable threshold for divergence
                logger.warning(f"Potential training divergence detected. Batch loss: {loss.item():.6f}")
                
                # Additional debugging for divergence
                if gradient_clip_norm is None:
                    # Log gradient norms to check for explosion
                    grad_norm = 0.0
                    for param in model.parameters():
                        if param.grad is not None:
                            grad_norm += param.grad.data.norm(2).item() ** 2
                    grad_norm = grad_norm ** 0.5
                    logger.warning(f"Gradient norm: {grad_norm:.6f} - Consider enabling gradient clipping")
            
            # MEMORY OPTIMIZATION: Clear memory for inputs and outputs
            del inputs, outputs, loss
            
            # MEMORY OPTIMIZATION: Clear CUDA cache less frequently
            if memory_efficient and device.type == 'cuda' and (i + 1) % 100 == 0:  # Increased from 20
                torch.cuda.empty_cache()
        
        # Update processed batches count
        processed_batches = end_batch
        
        # MEMORY OPTIMIZATION: Check memory less frequently
        if memory_efficient and processed_batches < total_batches:
            memory_stats = check_memory_usage()
            if memory_stats['system_percent'] > 95:  # Increased from 80
                logger.warning(f"Very high memory usage after processing {processed_batches}/{total_batches} batches "
                              f"({memory_stats['system_percent']}%). Clearing memory.")
                clear_memory(force_gc=True, clear_cuda=(device.type == 'cuda'))
    
    if show_progress:
        progress.finish()
    
    # Calculate and log performance statistics
    avg_batch_time = sum(batch_times) / len(batch_times)
    avg_forward_time = sum(forward_times) / len(forward_times)
    avg_backward_time = sum(backward_times) / len(backward_times)
    
    logger.debug(
        f"Epoch {epoch+1} performance - "
        f"Avg batch: {avg_batch_time:.3f}s, "
        f"Avg forward: {avg_forward_time:.3f}s, "
        f"Avg backward: {avg_backward_time:.3f}s"
    )
    
    # MEMORY OPTIMIZATION: Final memory cleanup at end of epoch
    if memory_efficient:
        clear_memory(force_gc=True, clear_cuda=(device.type == 'cuda'))
    
    return running_loss / len(train_loader)

def validate(
    model: nn.Module,
    val_loader: DataLoader,
    criterion: nn.Module,
    device: torch.device,
    show_progress: bool = True,
    memory_efficient: bool = True  # Enable memory efficiency by default
) -> float:
    """
    Validate model on validation set with improved memory management.
    
    Args:
        model: PyTorch model
        val_loader: Validation data loader
        criterion: Loss function
        device: Device to validate on (CPU or GPU)
        show_progress: Whether to show progress bar
        memory_efficient: Whether to use memory-efficient mode
        
    Returns:
        Average validation loss
    """
    model.eval()
    running_loss = 0.0
    total_batches = len(val_loader)
    
    if show_progress:
        progress = EnhancedProgressBar(
            total=total_batches, 
            prefix="Validation", 
            suffix="Complete",
            stage_info="Validation"
        )
    
    # MEMORY OPTIMIZATION: Process in chunks if dataset is large
    processed_batches = 0
    chunk_size = 50 if memory_efficient else total_batches  # Process 50 batches at a time in memory-efficient mode
    
    with torch.no_grad():
        while processed_batches < total_batches:
            end_batch = min(processed_batches + chunk_size, total_batches)
            
            # Process a chunk of batches
            for i, (inputs, targets) in enumerate(val_loader):
                if i < processed_batches:
                    continue
                if i >= end_batch:
                    break
                
                # Move data to device
                inputs = inputs.to(device)
                targets = targets.to(device)
                
                # Forward pass
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                
                # Statistics
                running_loss += loss.item()
                
                if show_progress:
                    progress.update(i + 1)
                
                # MEMORY OPTIMIZATION: Clear memory for inputs and outputs
                del inputs, outputs, loss
                
                # MEMORY OPTIMIZATION: Clear CUDA cache periodically
                if memory_efficient and device.type == 'cuda' and (i + 1) % 20 == 0:
                    torch.cuda.empty_cache()
            
            # Update processed batches count
            processed_batches = end_batch
            
            # MEMORY OPTIMIZATION: Check memory and clear if needed between chunks
            if memory_efficient and processed_batches < total_batches:
                memory_stats = check_memory_usage()
                if memory_stats['system_percent'] > 80:  # If system memory usage > 80%
                    logger.warning(f"High memory usage during validation "
                                  f"({memory_stats['system_percent']}%). Clearing memory.")
                    clear_memory(force_gc=True, clear_cuda=(device.type == 'cuda'))
    
    if show_progress:
        progress.finish()
    
    # MEMORY OPTIMIZATION: Final memory cleanup at end of validation
    if memory_efficient:
        clear_memory(force_gc=True, clear_cuda=(device.type == 'cuda'))
    
    return running_loss / len(val_loader)

def create_domain_batches(domain_indices: List[int], domains_per_batch: int) -> List[List[int]]:
    """
    Create batches of domain indices with a specified number of domains per batch.
    
    Args:
        domain_indices: List of domain indices to split into batches
        domains_per_batch: Number of domains per batch
        
    Returns:
        List of domain index batches
    """
    # Create batches of domain indices
    domain_batches = [
        domain_indices[i:i+domains_per_batch] 
        for i in range(0, len(domain_indices), domains_per_batch)
    ]
    
    return domain_batches



def train_model(config: Dict[str, Any]) -> Tuple[str, Dict[str, List[float]]]:
    """
    Train an RMSF prediction model with domain streaming and improved memory management.
    
    Args:
        config: Configuration dictionary
        
    Returns:
        Tuple of (model_path, training_history)
    """
    # Start the overall training stage
    with log_stage("TRAINING", f"Training {config['model']['architecture']} model"):
        # Log section header
        logger = get_logger(__name__)
        log_section_header(logger, "MODEL TRAINING WITH DOMAIN STREAMING")
        
        # Check if we're resuming from a checkpoint
        resume_checkpoint = config.get("training", {}).get("resume_checkpoint", None)
        start_epoch = 0
        processed_domains_history = set()
        
        # MEMORY OPTIMIZATION: Check and log initial memory usage
        memory_stats = check_memory_usage()
        logger.info(f"Initial memory: System: {memory_stats['system_percent']}% used, "
                   f"Process: {memory_stats['process_rss_gb']:.2f} GB")
        
        # MEMORY OPTIMIZATION: Emergency check - if already at critical levels, try to recover
        if memory_stats['system_percent'] > MEMORY_CRITICAL_THRESHOLD * 100:
            logger.warning(f"Starting with critically high memory usage: {memory_stats['system_percent']}%")
            logger.warning("Attempting emergency memory reduction before training")
            emergency_memory_reduction()
            memory_stats = check_memory_usage()
            if memory_stats['system_percent'] > MEMORY_EMERGENCY_THRESHOLD * 100:
                logger.error(f"Cannot start training with memory usage at {memory_stats['system_percent']}%")
                logger.error("Please free up system memory before starting training")
                raise MemoryError("Insufficient memory to begin training")
        
        # Get device (CPU or GPU)
        device = get_device(config["system_utilization"]["adjust_for_gpu"])
        logger.info(f"Using device: {device}")
        
        # Setup mixed precision training if on GPU
        scaler = None
        if device.type == 'cuda' and config["training"].get("mixed_precision", {}).get("enabled", False):
            mixed_precision_dtype = config["training"]["mixed_precision"].get("dtype", "float16")
            if mixed_precision_dtype == "bfloat16" and torch.cuda.is_available() and hasattr(torch, 'bfloat16'):
                amp_dtype = torch.bfloat16
                logger.info("Using mixed precision training with bfloat16")
            else:
                amp_dtype = torch.float16
                logger.info("Using mixed precision training with float16")
            
            scaler = torch.cuda.amp.GradScaler()
            logger.info("Mixed precision training enabled with GradScaler")
        
        # Check for domain registry if it exists
        domain_registry_path = os.path.join(config["output"]["base_dir"], "domain_registry.json")
        
        # Load or create domain registry for tracking processing status
        if os.path.exists(domain_registry_path):
            try:
                domain_registry = load_json(domain_registry_path)
                logger.info(f"Loaded domain registry with {len(domain_registry)} entries")
            except Exception as e:
                logger.warning(f"Error loading domain registry: {str(e)}")
                domain_registry = {}
        else:
            domain_registry = {}
        
        # ==== DOMAIN DISCOVERY PHASE ====
        logger.info("Starting domain discovery phase")
        
        all_domains = []
        
        try:
            # Open the HDF5 file to get all available domains
            with h5py.File(config["input"]["voxel_file"], 'r') as f:
                all_available_domains = list(f.keys())
                logger.info(f"Found {len(all_available_domains)} total domains in HDF5 file")
                
                # Check if we have a list of specific domains to use
                if config["input"]["domain_ids"] and len(config["input"]["domain_ids"]) > 0:
                    # Filter domains based on specified IDs
                    filtered_domains = []
                    for domain in all_available_domains:
                        base_domain = domain.split('_')[0]
                        if base_domain in config["input"]["domain_ids"]:
                            filtered_domains.append(domain)
                    
                    if not filtered_domains:
                        logger.warning("None of the specified domain_ids were found in the voxel file")
                        logger.warning("Using all available domains instead")
                        all_domains = all_available_domains
                    else:
                        all_domains = filtered_domains
                        logger.info(f"Filtered to {len(all_domains)} domains based on specified domain_ids")
                else:
                    # Use all domains
                    all_domains = all_available_domains
                
                # Apply max_domains limit if specified in config
                if config["input"].get("max_domains") is not None and len(all_domains) > config["input"]["max_domains"]:
                    logger.info(f"Limiting to {config['input']['max_domains']} domains (out of {len(all_domains)} available)")
                    all_domains = all_domains[:config["input"]["max_domains"]]
                    
        except Exception as e:
            logger.error(f"Error during domain discovery: {str(e)}")
            raise
        
        # Update domain registry with all discovered domains
        for domain_id in all_domains:
            if domain_id not in domain_registry:
                domain_registry[domain_id] = {
                    "processed": False,
                    "processing_attempts": 0,
                    "last_processed": None,
                    "error_count": 0
                }
        
        # Prioritize unprocessed domains
        unprocessed_domains = [d for d in all_domains if not domain_registry[d].get("processed", False)]
        processed_domains = [d for d in all_domains if domain_registry[d].get("processed", False)]
        
        if unprocessed_domains:
            logger.info(f"Prioritizing {len(unprocessed_domains)} unprocessed domains")
            
            # Move unprocessed domains to the front but keep some processed ones for continuity
            # Include some processed domains to maintain training continuity
            num_processed_to_include = min(len(processed_domains), len(unprocessed_domains) // 4)
            if num_processed_to_include > 0:
                # Include some processed domains that performed well previously
                processed_domains_sample = processed_domains[:num_processed_to_include]
                all_domains = unprocessed_domains + processed_domains_sample + processed_domains[num_processed_to_include:]
                logger.info(f"Including {num_processed_to_include} previously processed domains for training continuity")
            else:
                all_domains = unprocessed_domains + processed_domains
        
        # Save the full domain list for reference
        full_domain_registry_path = os.path.join(config["output"]["base_dir"], "full_domain_registry.txt")
        save_domain_registry(all_domains, full_domain_registry_path)
        logger.info(f"Saved full domain registry with {len(all_domains)} domains")
        
        # ==== LOAD RMSF DATA ====
        logger.info("Loading RMSF data")
        rmsf_data = load_rmsf_data(
            config["input"]["rmsf_dir"],
            config["input"].get("replica", "replica_average"),
            config["input"]["temperature"]
        )
        
        # MEMORY OPTIMIZATION: Check memory after loading RMSF data
        memory_stats = check_memory_usage()
        logger.info(f"Memory after loading RMSF data: {memory_stats['system_percent']}% used")
        
        # ==== CREATE MODEL ====
        with log_stage("MODEL_CREATION", f"Creating {config['model']['architecture']} model"):
            # Determine input shape by loading a single domain temporarily
            logger.info("Sampling a domain to determine input shape")
            input_shape = None
            
            # Try multiple domains in case some are invalid
            for test_domain in all_domains[:min(10, len(all_domains))]:
                try:
                    with h5py.File(config["input"]["voxel_file"], 'r') as f:
                        domain_group = f[test_domain]
                        first_child_key = list(domain_group.keys())[0]
                        residue_group = domain_group[first_child_key]
                        residue_keys = [k for k in residue_group.keys() if isinstance(k, str) and k.isdigit()]
                        
                        if not residue_keys:
                            logger.warning(f"No residues found in sample domain {test_domain}")
                            continue
                        
                        first_residue = residue_keys[0]
                        residue_data = residue_group[first_residue]
                        voxel_data_raw = residue_data[:]
                        
                        # Transpose if necessary
                        if len(residue_data.shape) == 4 and residue_data.shape[3] in [4, 5]:
                            voxel = np.transpose(voxel_data_raw, (3, 0, 1, 2))
                        else:
                            voxel = voxel_data_raw
                        
                        input_shape = voxel.shape
                        logger.info(f"Determined input shape: {input_shape}")
                        break
                except Exception as e:
                    logger.warning(f"Error sampling domain {test_domain}: {str(e)}")
            
            if input_shape is None:
                raise ValueError("Could not determine input shape from any sampled domain")
            
            # MEMORY OPTIMIZATION: Clear memory after sampling
            clear_memory(force_gc=True, clear_cuda=True)
            
            # Check if resuming from checkpoint
            if resume_checkpoint and os.path.exists(resume_checkpoint):
                logger.info(f"Resuming from checkpoint: {resume_checkpoint}")
                checkpoint = torch.load(resume_checkpoint, map_location=device)
                
                # Extract model architecture and config
                model_config = checkpoint.get('config', {}).get('model', config['model'])
                
                # Create model with same architecture
                model = get_model(
                    architecture=model_config['architecture'],
                    input_channels=model_config['input_channels'],
                    channel_growth_rate=model_config['channel_growth_rate'],
                    num_residual_blocks=model_config['num_residual_blocks'],
                    dropout_rate=model_config['dropout_rate'],
                    base_filters=model_config['base_filters']
                )
                
                # Load model weights
                model.load_state_dict(checkpoint['model_state_dict'])
                
                # Move model to device
                model = model.to(device)
                
                # Get training history and processed domains
                train_losses = checkpoint.get('train_losses', [])
                val_losses = checkpoint.get('val_losses', [])
                processed_domains_history = set(checkpoint.get('processed_domains', []))
                start_epoch = checkpoint.get('epoch', 0)
                
                logger.info(f"Resumed from epoch {start_epoch} with {len(processed_domains_history)} domains processed")
                
                # Clean up checkpoint to free memory
                del checkpoint
                clear_memory(force_gc=True, clear_cuda=True)
            else:
                # Create new model
                logger.info("Building model architecture")
                model = get_model(
                    architecture=config["model"]["architecture"],
                    input_channels=input_shape[0],
                    channel_growth_rate=config["model"]["channel_growth_rate"],
                    num_residual_blocks=config["model"]["num_residual_blocks"],
                    dropout_rate=config["model"]["dropout_rate"],
                    base_filters=config["model"]["base_filters"]
                )
                
                # Move model to device
                model = model.to(device)
                
                # Initialize training history
                train_losses = []
                val_losses = []
            
            # Log model summary (params count)
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            logger.info(f"Model created with {total_params:,} total parameters ({trainable_params:,} trainable)")
            
            # Define loss function and optimizer
            criterion = nn.MSELoss()
            
            # Reduced learning rate to prevent divergence
            initial_lr = float(config["training"]["learning_rate"])
            
            # Check for warmup settings
            use_warmup = config["training"].get("warmup", {}).get("enabled", False)
            if use_warmup and start_epoch < config["training"]["warmup"].get("epochs", 1):
                warmup_epochs = config["training"]["warmup"].get("epochs", 1)
                # Start with a lower learning rate if using warmup
                effective_lr = initial_lr * 0.1
                logger.info(f"Using learning rate warmup over {warmup_epochs} epochs: starting at {effective_lr:.6f}")
            else:
                effective_lr = initial_lr
            
            # Create optimizer (or load from checkpoint)
            if resume_checkpoint and 'optimizer_state_dict' in locals().get('checkpoint', {}):
                optimizer = optim.Adam(
                    model.parameters(),
                    lr=effective_lr,
                    weight_decay=float(config["training"]["weight_decay"])
                )
                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                logger.info("Loaded optimizer state from checkpoint")
            else:
                optimizer = optim.Adam(
                    model.parameters(),
                    lr=effective_lr,
                    weight_decay=float(config["training"]["weight_decay"])
                )
            
            # Create scheduler if specified
            scheduler = None
            if "scheduler" in config.get("training", {}):
                scheduler_config = config["training"]["scheduler"]
                if scheduler_config["type"] == "reduce_on_plateau":
                    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                        optimizer,
                        mode=scheduler_config.get("mode", "min"),
                        factor=float(scheduler_config.get("factor", 0.5)),  # Changed from 0.1 to 0.5
                        patience=int(scheduler_config.get("patience", 10)),
                        verbose=True
                    )
                    logger.info(f"Using ReduceLROnPlateau scheduler with patience {scheduler_config.get('patience', 10)}")
                elif scheduler_config["type"] == "step":
                    scheduler = optim.lr_scheduler.StepLR(
                        optimizer,
                        step_size=int(scheduler_config.get("step_size", 30)),
                        gamma=float(scheduler_config.get("gamma", 0.5))  # Changed from 0.1 to 0.5
                    )
                    logger.info(f"Using StepLR scheduler with step size {scheduler_config.get('step_size', 30)}")
                elif scheduler_config["type"] == "cosine_annealing":
                    T_max = int(scheduler_config.get("T_max", config["training"]["num_epochs"]))
                    # Explicitly convert eta_min to float to avoid type errors
                    eta_min = float(scheduler_config.get("eta_min", 1e-6))
                    scheduler = optim.lr_scheduler.CosineAnnealingLR(
                        optimizer,
                        T_max=T_max,
                        eta_min=eta_min
                    )
                    logger.info(f"Using CosineAnnealingLR scheduler with T_max={T_max}, eta_min={eta_min}")
                    
            # Gradient clipping configuration
            gradient_clip_norm = None
            if config["training"].get("gradient_clipping", {}).get("enabled", False):
                gradient_clip_norm = config["training"]["gradient_clipping"].get("max_norm", 1.0)
                logger.info(f"Gradient clipping enabled with max_norm={gradient_clip_norm}")
                
            # MEMORY OPTIMIZATION: Check memory after model creation
            memory_stats = check_memory_usage()
            logger.info(f"Memory after model creation: {memory_stats['system_percent']}% used")
            
            # Clear memory before starting training
            clear_memory(force_gc=True, clear_cuda=True)
        
        # ==== DOMAIN STREAMING TRAINING ====
        with log_stage("TRAINING", f"Training for {config['training']['num_epochs']} epochs with domain streaming"):
            num_epochs = int(config["training"]["num_epochs"])
            show_progress = config["logging"]["show_progress_bars"]
            
            # Record losses
            epoch_domain_counts = []
            
            # Track best model
            if resume_checkpoint and 'best_val_loss' in locals().get('checkpoint', {}):
                best_val_loss = checkpoint.get('best_val_loss', float('inf'))
                best_epoch = checkpoint.get('best_epoch', 0)
                logger.info(f"Resuming with best validation loss: {best_val_loss:.6f} from epoch {best_epoch}")
            else:
                best_val_loss = float('inf')
                best_epoch = 0
            
            # MEMORY OPTIMIZATION: Calculate domain batch size more conservatively
            memory_stats = check_memory_usage()
            available_memory_gb = memory_stats["system_available_gb"]
            system_memory_total = memory_stats["system_total_gb"]
            system_memory_percent = memory_stats["system_percent"]

            # MAJOR CHANGE: Much more conservative domain batch sizing based on memory pressure
            if system_memory_percent > 60:  # Higher memory pressure
                domains_per_batch = max(10, config["training"]["domain_streaming"].get("initial_domains_per_batch", 100) // 4)
                logger.warning(f"High initial memory usage ({system_memory_percent:.1f}%), using reduced batch size of {domains_per_batch} domains")
            elif available_memory_gb > 30:  # Plenty of memory
                domains_per_batch = max(50, config["training"]["domain_streaming"].get("initial_domains_per_batch", 100) // 2)
                logger.info(f"Good memory availability ({available_memory_gb:.1f} GB free), using {domains_per_batch} domains per batch")
            else:  # Limited memory
                domains_per_batch = max(20, config["training"]["domain_streaming"].get("initial_domains_per_batch", 100) // 3)
                logger.info(f"Limited memory availability ({available_memory_gb:.1f} GB free), using reduced batch size of {domains_per_batch} domains")

            logger.info(f"Using streaming approach with {domains_per_batch} domains per batch")
            logger.info(f"Total domains to process: {len(all_domains)}")

            # Prepare domain batches
            np.random.seed(config.get("training", {}).get("seed", 42))
            domain_indices = np.arange(len(all_domains))
            np.random.shuffle(domain_indices)

            # Split into training, validation and test sets by domains
            train_split = config["training"]["train_split"]
            val_split = config["training"]["val_split"]

            train_idx = int(len(domain_indices) * train_split)
            val_idx = train_idx + int(len(domain_indices) * val_split)

            train_domain_indices = domain_indices[:train_idx]
            val_domain_indices = domain_indices[train_idx:val_idx]
            test_domain_indices = domain_indices[val_idx:]

            logger.info(f"Split domains: {len(train_domain_indices)} training, "
                    f"{len(val_domain_indices)} validation, {len(test_domain_indices)} test")

            # Create domain batches with the updated size
            train_domain_batches = create_domain_batches(train_domain_indices, domains_per_batch)
            val_domain_batches = create_domain_batches(val_domain_indices, domains_per_batch)

            logger.info(f"Created {len(train_domain_batches)} training batches, {len(val_domain_batches)} validation batches")

            # Create global RMSF lookup to reuse across all batches
            from voxelflex.data.data_loader import create_optimized_rmsf_lookup
            global_rmsf_lookup = create_optimized_rmsf_lookup(rmsf_data)
            
            # Create checkpoint directory
            checkpoint_dir = os.path.join(config["output"]["base_dir"], "checkpoints")
            ensure_dir(checkpoint_dir)
            
            # Train the model across epochs
            start_time = time.time()
            total_domains_processed = len(processed_domains_history)
            
            # Track domains processed in this run
            domains_processed_this_run = set(processed_domains_history)
            
            # Create model save directory
            model_dir = os.path.join(config["output"]["base_dir"], "models")
            ensure_dir(model_dir)
            
            # Main epoch loop
            for epoch in range(start_epoch, num_epochs):
                epoch_start_time = time.time()
                
                # Apply learning rate warmup if configured
                if use_warmup and epoch < warmup_epochs:
                    warmup_factor = (epoch + 1) / warmup_epochs
                    adjusted_lr = initial_lr * warmup_factor
                    for param_group in optimizer.param_groups:
                        param_group['lr'] = adjusted_lr
                    logger.info(f"Warmup epoch {epoch+1}/{warmup_epochs}: LR = {adjusted_lr:.6f}")
                
                # Shuffle domain batches at the start of each epoch
                np.random.shuffle(train_domain_batches)
                
                # Track epoch statistics
                epoch_train_loss = 0.0
                epoch_domains_processed = 0
                epoch_batches_processed = 0
                
                # Training phase
                model.train()
                
                # Process each domain batch
                batch_progress = EnhancedProgressBar(
                    total=len(train_domain_batches),
                    prefix=f"Epoch {epoch+1}/{num_epochs} Batches",
                    suffix="Complete",
                    stage_info="DOMAIN_BATCH"
                )
                
                # Keep track of domains processed in this epoch
                domains_processed_this_epoch = set()
                
                for batch_idx, domain_batch_indices in enumerate(train_domain_batches):
                    batch_start_time = time.time()
                    
                    # MEMORY OPTIMIZATION: Check memory before loading new batch
                    memory_stats = check_memory_usage()
                    if memory_stats['system_percent'] > MEMORY_CRITICAL_THRESHOLD * 100:
                        logger.warning(f"Critical memory usage ({memory_stats['system_percent']:.1f}%) before batch {batch_idx+1}")
                        logger.warning("Performing emergency memory reduction")
                        freed_memory = emergency_memory_reduction()
                        
                        # If not enough memory was freed, skip this batch
                        memory_stats = check_memory_usage()
                        if memory_stats['system_percent'] > MEMORY_EMERGENCY_THRESHOLD * 100:
                            logger.error(f"Memory usage still critical ({memory_stats['system_percent']:.1f}%) after emergency reduction")
                            logger.error(f"Skipping batch {batch_idx+1} to prevent system crash")
                            batch_progress.update(batch_idx + 1)
                            continue
                    
                    # Load domain batch
                    batch_voxel_data = load_domain_batch(domain_batch_indices, all_domains, config)
                    
                    # Count domains successfully loaded
                    domains_in_batch = len(batch_voxel_data)
                    
                    # Update domain processing tracking
                    for domain_id in batch_voxel_data.keys():
                        domains_processed_this_epoch.add(domain_id)
                        domains_processed_this_run.add(domain_id)
                    
                    if domains_in_batch == 0:
                        logger.warning(f"No valid domains loaded in batch {batch_idx+1}. Skipping.")
                        batch_progress.update(batch_idx + 1)
                        continue
                    
                    logger.info(f"Processing {domains_in_batch} domains in batch {batch_idx+1}/{len(train_domain_batches)}")
                    
                    # MEMORY OPTIMIZATION: Check memory after loading batch
                    memory_stats = check_memory_usage()
                    if memory_stats['system_percent'] > MEMORY_CRITICAL_THRESHOLD * 100:
                        logger.warning(f"Critical memory usage ({memory_stats['system_percent']:.1f}%) after loading batch {batch_idx+1}")
                        logger.warning("Performing emergency memory reduction")
                        freed_memory = emergency_memory_reduction()
                        
                        # If still critical after reduction, we need to skip this batch
                        memory_stats = check_memory_usage()
                        if memory_stats['system_percent'] > MEMORY_EMERGENCY_THRESHOLD * 100:
                            logger.error(f"Memory usage still critical ({memory_stats['system_percent']:.1f}%) after emergency reduction")
                            logger.error(f"Skipping batch {batch_idx+1} to prevent system crash")
                            
                            # Free the batch data
                            del batch_voxel_data
                            clear_memory(force_gc=True, clear_cuda=True, aggressive=True)
                            batch_progress.update(batch_idx + 1)
                            continue
                    
                    # Create dataloaders for this batch
                    try:
                        # Create domain mapping for this batch
                        voxel_domains = list(batch_voxel_data.keys())
                        rmsf_domains = rmsf_data['domain_id'].unique().tolist()
                        domain_mapping = create_domain_mapping(voxel_domains, rmsf_domains)

                        # MEMORY OPTIMIZATION: Calculate optimal batch size for GPU more conservatively
                        data_batch_size = config["training"]["batch_size"]  # e.g., 512 from config
                        if device.type == 'cuda':
                            # Calculate dynamically based on available GPU memory
                            gpu_id = 0
                            total_memory = torch.cuda.get_device_properties(gpu_id).total_memory / (1024**3)
                            allocated = torch.cuda.memory_allocated(gpu_id) / (1024**3)
                            free_memory = total_memory - allocated

                            # MAJOR CHANGE: More conservative memory allocation
                            element_size = 4  # float32 = 4 bytes
                            input_bytes = np.prod(input_shape) * element_size
                            # Increased overhead factor from 2.0 to 3.0 for more safety
                            max_elements = (free_memory * 0.7 * (1024**3)) / (input_bytes * 3.0)
                            # Reduce max batch size for safety
                            max_batch = min(512, int(max_elements))
                            
                            # Use the smaller of configured batch size or calculated max
                            data_batch_size = min(config["training"]["batch_size"], max_batch)
                            logger.info(f"Using GPU-optimized batch size: {data_batch_size}")
                            
                        # Create dataset for this batch
                        batch_dataset = RMSFDataset(
                            batch_voxel_data,
                            rmsf_data,
                            domain_mapping,
                            memory_efficient=config["training"].get("memory_efficient", True),  # Use from config
                            global_rmsf_lookup=global_rmsf_lookup  # Use the pre-computed lookup
                        )

                        # MEMORY OPTIMIZATION: Determine optimal worker count more conservatively
                        memory_stats = check_memory_usage()
                        cpu_count = os.cpu_count() or 8
                        
                        if config["training"].get("safe_mode", False):
                            # Safe mode forces single-threaded operation
                            num_workers = 0
                            logger.info("Safe mode enabled. Using 0 workers (single-threaded mode).")
                        elif memory_stats['system_percent'] > 80:
                            # Very high memory pressure - use minimal workers
                            num_workers = 0
                            logger.warning(f"High memory pressure ({memory_stats['system_percent']:.1f}%). Using 0 workers.")
                        elif memory_stats['system_percent'] > 70:
                            # High memory pressure - use minimal workers
                            num_workers = 1
                            logger.warning(f"High memory pressure ({memory_stats['system_percent']:.1f}%). Using 1 worker.")
                        elif memory_stats['system_percent'] > 60:
                            # Moderate memory pressure
                            num_workers = min(2, cpu_count // 4)
                            logger.info(f"Moderate memory pressure ({memory_stats['system_percent']:.1f}%). Using {num_workers} workers.")
                        else:
                            # Normal memory pressure
                            num_workers = min(4, cpu_count // 2)
                            logger.info(f"Normal memory usage ({memory_stats['system_percent']:.1f}%). Using {num_workers} workers.")

                        # Create data loader
                        train_loader = DataLoader(
                            batch_dataset,
                            batch_size=data_batch_size,
                            shuffle=True,
                            num_workers=num_workers,
                            pin_memory=(device.type == 'cuda'),
                            persistent_workers=(num_workers > 0),
                            prefetch_factor=2 if num_workers > 0 else None  # CHANGE: Reduced from 4 to 2
                        )

                        logger.info(f"Created dataloader with batch size {data_batch_size}, {num_workers} workers")
                        logger.info(f"Dataloader contains {len(train_loader)} batches from {len(batch_dataset)} samples")

                        # Train on this domain batch
                        batch_train_loss = train_epoch(
                            model=model,
                            train_loader=train_loader,
                            criterion=criterion,
                            optimizer=optimizer,
                            device=device,
                            epoch=epoch,
                            show_progress=show_progress and len(train_loader) > 10,
                            memory_efficient=config["training"].get("memory_efficient", True),  # Use from config
                            scaler=scaler,
                            gradient_clip_norm=gradient_clip_norm
                        )

                        # Add to epoch statistics
                        epoch_train_loss += batch_train_loss * len(train_loader)
                        epoch_batches_processed += len(train_loader)
                        epoch_domains_processed += domains_in_batch

                        logger.info(f"Batch {batch_idx+1} completed: {domains_in_batch} domains, loss: {batch_train_loss:.6f}")

                    except Exception as e:
                        logger.error(f"Error processing domain batch {batch_idx+1}: {str(e)}", exc_info=True)

                        # Update domain registry with error information
                        for domain_id in [all_domains[i] for i in domain_batch_indices]:
                            if domain_id in domain_registry:
                                domain_registry[domain_id]["error_count"] = domain_registry[domain_id].get("error_count", 0) + 1
                                domain_registry[domain_id]["last_error"] = str(e)
                        
                        # MEMORY OPTIMIZATION: In case of error, perform aggressive cleanup
                        clear_memory(force_gc=True, clear_cuda=True, aggressive=True)
                    
                    # Clean up batch data to free memory
                    del batch_voxel_data
                    if 'train_loader' in locals():
                        del train_loader
                    if 'batch_dataset' in locals():
                        del batch_dataset
                    if 'domain_mapping' in locals():
                        del domain_mapping
                        
                    clear_memory(force_gc=True, clear_cuda=(device.type == 'cuda'))
                    
                    # Update batch progress
                    batch_duration = time.time() - batch_start_time
                    logger.info(f"Batch {batch_idx+1} processing time: {batch_duration:.2f}s")
                    batch_progress.update(batch_idx + 1)
                    
                    # MEMORY OPTIMIZATION: Check memory periodically during training
                    if (batch_idx + 1) % 5 == 0 or batch_idx == len(train_domain_batches) - 1:
                        memory_stats = check_memory_usage()
                        logger.info(f"Memory after batch {batch_idx+1}: {memory_stats['system_percent']:.1f}% used")
                        
                        # If memory is getting high, perform cleanup
                        if memory_stats['system_percent'] > MEMORY_CRITICAL_THRESHOLD * 100:
                            logger.warning(f"Critical memory usage ({memory_stats['system_percent']:.1f}%) after batch {batch_idx+1}")
                            logger.warning("Performing emergency memory reduction")
                            emergency_memory_reduction()
                
                # End batch progress
                batch_progress.finish()
                
                # Calculate average training loss for the epoch
                avg_train_loss = epoch_train_loss / max(1, epoch_batches_processed)
                train_losses.append(avg_train_loss)
                
                # Validation phase
                model.eval()
                epoch_val_loss = 0.0
                val_steps = 0
                
                # Process validation domain batches
                val_progress = EnhancedProgressBar(
                    total=len(val_domain_batches),
                    prefix="Validation Batches",
                    suffix="Complete",
                    stage_info="VALIDATION"
                )
                
                # MEMORY OPTIMIZATION: Clear memory before validation
                clear_memory(force_gc=True, clear_cuda=True)
                
                for val_batch_idx, val_domain_batch_indices in enumerate(val_domain_batches):
                    # MEMORY OPTIMIZATION: Check memory before validation batch
                    memory_stats = check_memory_usage()
                    if memory_stats['system_percent'] > MEMORY_CRITICAL_THRESHOLD * 100:
                        logger.warning(f"Critical memory usage ({memory_stats['system_percent']:.1f}%) before validation batch {val_batch_idx+1}")
                        logger.warning("Performing emergency memory reduction")
                        emergency_memory_reduction()
                        
                        # If still critical, skip this validation batch
                        memory_stats = check_memory_usage()
                        if memory_stats['system_percent'] > MEMORY_EMERGENCY_THRESHOLD * 100:
                            logger.error(f"Memory usage still critical ({memory_stats['system_percent']:.1f}%) after emergency reduction")
                            logger.error(f"Skipping validation batch {val_batch_idx+1} to prevent system crash")
                            val_progress.update(val_batch_idx + 1)
                            continue
                    
                    # Load validation domain batch
                    val_voxel_data = load_domain_batch(val_domain_batch_indices, all_domains, config)
                    
                    # Count domains successfully loaded
                    val_domains_in_batch = len(val_voxel_data)
                    
                    if val_domains_in_batch == 0:
                        logger.warning(f"No valid domains loaded in validation batch {val_batch_idx+1}. Skipping.")
                        val_progress.update(val_batch_idx + 1)
                        continue
                    
                    # Create dataloaders for validation
                    try:
                        # Create domain mapping for this validation batch
                        val_voxel_domains = list(val_voxel_data.keys())
                        val_domain_mapping = create_domain_mapping(val_voxel_domains, rmsf_domains)
                        
                        # MEMORY OPTIMIZATION: Use smaller batch size for validation
                        val_batch_size = min(128, config["training"]["batch_size"])
                        
                        # Create dataset and loader with memory-efficient mode
                        val_dataset = RMSFDataset(
                            val_voxel_data, 
                            rmsf_data, 
                            val_domain_mapping, 
                            memory_efficient=config["training"].get("memory_efficient", True),  # Use from config
                            global_rmsf_lookup=global_rmsf_lookup
                        )
                        
                        val_loader = DataLoader(
                            val_dataset,
                            batch_size=val_batch_size,
                            shuffle=False,
                            num_workers=0 if config["training"].get("safe_mode", False) else 0,  # Use 0 workers for validation to reduce memory pressure
                            pin_memory=(device.type == 'cuda')
                        )
                        
                        # Validate
                        with torch.no_grad():
                            batch_val_steps = 0
                            batch_val_loss = 0.0
                            
                            for val_inputs, val_targets in val_loader:
                                val_inputs = val_inputs.to(device, non_blocking=True)
                                val_targets = val_targets.to(device, non_blocking=True)
                                
                                # Use mixed precision for validation if available
                                if device.type == 'cuda' and scaler is not None:
                                    with torch.cuda.amp.autocast():
                                        val_outputs = model(val_inputs)
                                        val_loss = criterion(val_outputs, val_targets)
                                else:
                                    val_outputs = model(val_inputs)
                                    val_loss = criterion(val_outputs, val_targets)
                                
                                batch_val_loss += val_loss.item()
                                batch_val_steps += 1
                                
                                # Clean up
                                del val_inputs, val_outputs, val_targets
                                
                                # MEMORY OPTIMIZATION: Clear CUDA cache periodically during validation
                                if device.type == 'cuda' and batch_val_steps % 10 == 0:
                                    torch.cuda.empty_cache()
                        
                        # Add to epoch validation loss
                        if batch_val_steps > 0:
                            epoch_val_loss += batch_val_loss
                            val_steps += batch_val_steps
                        
                    except Exception as e:
                        logger.error(f"Error in validation batch {val_batch_idx+1}: {str(e)}")
                        
                        # MEMORY OPTIMIZATION: In case of error, perform aggressive cleanup
                        clear_memory(force_gc=True, clear_cuda=True, aggressive=True)
                    
                    # Clean up
                    del val_voxel_data
                    if 'val_loader' in locals():
                        del val_loader
                    if 'val_dataset' in locals():
                        del val_dataset
                    if 'val_domain_mapping' in locals():
                        del val_domain_mapping
                        
                    clear_memory(force_gc=True, clear_cuda=(device.type == 'cuda'))
                    
                    # Update progress
                    val_progress.update(val_batch_idx + 1)
                
                # End validation progress
                val_progress.finish()
                
                # Calculate average validation loss
                avg_val_loss = epoch_val_loss / max(1, val_steps)
                val_losses.append(avg_val_loss)
                
                # Update scheduler if used
                if scheduler is not None:
                    if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                        scheduler.step(avg_val_loss)
                    else:
                        scheduler.step()
                
                # Track best model
                is_best = avg_val_loss < best_val_loss
                if is_best:
                    best_val_loss = avg_val_loss
                    best_epoch = epoch + 1
                    
                    # Save best model checkpoint
                    best_model_path = os.path.join(model_dir, f"best_model_streaming.pt")
                    
                    # MEMORY OPTIMIZATION: Clear memory before saving model
                    clear_memory(force_gc=True, clear_cuda=True)
                    
                    # Save best model with minimal state to reduce file size
                    torch.save({
                        'model_state_dict': model.state_dict(),
                        'epoch': epoch + 1,
                        'val_loss': best_val_loss,
                        'config': config,
                        'input_shape': input_shape,
                        'processed_domains': list(domains_processed_this_run)  # Track processed domains
                    }, best_model_path)
                    
                    logger.info(f"Saved best model checkpoint (val_loss: {best_val_loss:.6f})")
                
                # MAJOR NEW FEATURE: Save regular checkpoints every 3 epochs
                if (epoch + 1) % 3 == 0 or epoch == num_epochs - 1:
                    # Create checkpoint filename
                    checkpoint_path = os.path.join(checkpoint_dir, f"checkpoint_epoch_{epoch+1}.pt")
                    
                    # MEMORY OPTIMIZATION: Clear memory before saving checkpoint
                    clear_memory(force_gc=True, clear_cuda=True)
                    
                    logger.info(f"Saving checkpoint for epoch {epoch+1}")
                    
                    # Save checkpoint with all necessary information
                    torch.save({
                        'model_state_dict': model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'scaler': scaler.state_dict() if scaler else None,
                        'epoch': epoch + 1,
                        'train_losses': train_losses,
                        'val_losses': val_losses,
                        'best_val_loss': best_val_loss,
                        'best_epoch': best_epoch,
                        'config': config,
                        'input_shape': input_shape,
                        'processed_domains': list(domains_processed_this_run)
                    }, checkpoint_path)
                    
                    logger.info(f"Checkpoint saved to {checkpoint_path}")
                    
                    # MEMORY OPTIMIZATION: Clean up old checkpoints to save disk space
                    # Keep only the 3 most recent checkpoints
                    try:
                        checkpoint_files = [f for f in os.listdir(checkpoint_dir) 
                                          if f.startswith("checkpoint_epoch_") and f.endswith(".pt")]
                        checkpoint_files.sort(key=lambda x: int(x.split("_")[2].split(".")[0]), reverse=True)
                        
                        # Keep the 3 most recent checkpoints
                        for old_checkpoint in checkpoint_files[3:]:
                            old_path = os.path.join(checkpoint_dir, old_checkpoint)
                            os.remove(old_path)
                            logger.info(f"Removed old checkpoint: {old_path}")
                    except Exception as e:
                        logger.warning(f"Error cleaning up old checkpoints: {str(e)}")
                
                # Calculate epoch time
                epoch_time = time.time() - epoch_start_time
                
                # Log progress with detailed metrics
                logger.info(
                    f"Epoch {epoch+1}/{num_epochs} completed in {epoch_time:.2f}s - "
                    f"Domains: {epoch_domains_processed} - "
                    f"Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}"
                    f"{' (Best)' if is_best else ''}"
                )
                
                # Check for training divergence
                if avg_train_loss > avg_val_loss * 5:  # Training loss much higher than validation
                    logger.warning(f"Potential training divergence detected: train_loss={avg_train_loss:.6f}, "
                                  f"val_loss={avg_val_loss:.6f}")
                    if gradient_clip_norm is None:
                        logger.warning("Consider enabling gradient clipping to address divergence")
                
                # Track domains processed in this epoch
                epoch_domain_counts.append(epoch_domains_processed)
                total_domains_processed += epoch_domains_processed
                
                # Update domain registry with successfully processed domains
                for domain_id in domains_processed_this_epoch:
                    if domain_id in domain_registry:
                        domain_registry[domain_id]["processed"] = True
                        domain_registry[domain_id]["processing_attempts"] = domain_registry[domain_id].get("processing_attempts", 0) + 1
                        domain_registry[domain_id]["last_processed"] = time.strftime("%Y%m%d_%H%M%S")
                
                # Save updated domain registry
                save_json(domain_registry, domain_registry_path)
                logger.info(f"Updated domain registry with {len(domains_processed_this_epoch)} newly processed domains")
                
                # MEMORY OPTIMIZATION: Check memory at end of epoch
                memory_stats = check_memory_usage()
                logger.info(f"Memory at end of epoch {epoch+1}: {memory_stats['system_percent']:.1f}% used")
                
                # MEMORY OPTIMIZATION: Clear memory at end of epoch
                clear_memory(force_gc=True, clear_cuda=True)
                
                # MEMORY OPTIMIZATION: Dynamically adjust domains_per_batch based on memory usage
                memory_stats = check_memory_usage()
                
                # If memory usage is too high, reduce batch size
                if memory_stats['system_percent'] > 75:
                    # Reduce domains per batch by 30%
                    old_domains_per_batch = domains_per_batch
                    domains_per_batch = max(10, int(domains_per_batch * 0.7))
                    
                    # Recalculate batches
                    train_domain_batches = create_domain_batches(train_domain_indices, domains_per_batch)
                    val_domain_batches = create_domain_batches(val_domain_indices, domains_per_batch)
                    
                    logger.warning(f"Reduced domains per batch from {old_domains_per_batch} to {domains_per_batch} due to high memory usage")
                    logger.info(f"New batch counts: {len(train_domain_batches)} training, {len(val_domain_batches)} validation")
                # If memory usage is very low and we've processed all domains, try to increase batch size slightly
                elif memory_stats['system_percent'] < 50 and epoch_domains_processed >= len(train_domain_indices):
                    # Increase domains per batch by 10% (more conservative than before)
                    old_domains_per_batch = domains_per_batch
                    domains_per_batch = min(len(train_domain_indices), int(domains_per_batch * 1.1))
                    
                    # Only adjust if there's a meaningful change
                    if domains_per_batch > old_domains_per_batch:
                        # Recalculate batches with new size
                        train_domain_batches = create_domain_batches(train_domain_indices, domains_per_batch)
                        val_domain_batches = create_domain_batches(val_domain_indices, domains_per_batch)
                        
                        logger.info(f"Increased domains per batch from {old_domains_per_batch} to {domains_per_batch} due to low memory usage")
                        logger.info(f"New batch counts: {len(train_domain_batches)} training, {len(val_domain_batches)} validation")
            
            # Training summary
            training_time = time.time() - start_time
            logger.info(f"Training completed in {training_time:.2f} seconds")
            logger.info(f"Best validation loss: {best_val_loss:.6f} (epoch {best_epoch})")
            logger.info(f"Total domains processed across all epochs: {total_domains_processed}")
            logger.info(f"Unique domains processed in this run: {len(domains_processed_this_run)}")
            
            # Calculate and report domain coverage
            total_domains = len(all_domains)
            coverage = (len(domains_processed_this_run) / total_domains) * 100
            logger.info(f"Domain coverage: {coverage:.1f}% ({len(domains_processed_this_run)}/{total_domains})")
            
            # Calculate and report total processed domains
            total_processed = len([d for d in domain_registry if domain_registry[d].get("processed", False)])
            total_coverage = (total_processed / total_domains) * 100
            logger.info(f"Total domain coverage (all runs): {total_coverage:.1f}% ({total_processed}/{total_domains})")
            
            # Final memory usage
            log_memory_usage(logger)
        
        # Save the final model
        with log_stage("MODEL_SAVING", "Saving trained model"):
            # MEMORY OPTIMIZATION: Clear memory before final save
            clear_memory(force_gc=True, clear_cuda=True)
            
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            model_path = os.path.join(model_dir, f"{config['model']['architecture']}_streaming_{timestamp}.pt")
            
            logger.info(f"Saving final model to {model_path}")
            
            # Save model with all relevant information
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'config': config,
                'input_shape': input_shape,
                'train_losses': train_losses,
                'val_losses': val_losses,
                'epoch_domain_counts': epoch_domain_counts,
                'epoch': num_epochs,
                'best_val_loss': best_val_loss,
                'best_epoch': best_epoch,
                'processed_domains': list(domains_processed_this_run)  # Save domains processed in this run
            }, model_path)
            
            logger.info(f"Final model saved to {model_path}")
            
            # Save training history
            history = {
                'train_loss': train_losses,
                'val_loss': val_losses,
                'best_epoch': best_epoch,
                'best_val_loss': best_val_loss,
                'epoch_domain_counts': epoch_domain_counts,
                'domains_processed': list(domains_processed_this_run),
                'total_domains': len(all_domains),
                'domain_coverage_percent': coverage
            }
            
            history_path = os.path.join(model_dir, f"training_history_streaming_{timestamp}.json")
            save_json(history, history_path)
            
            logger.info(f"Training history saved to {history_path}")
        
        return model_path, history
===== FILE: src/voxelflex/cli/commands/__init__.py =====
# In src/voxelflex/cli/commands/__init__.py
from voxelflex.cli.commands.train import train_model
from voxelflex.cli.commands.predict import predict_rmsf
from voxelflex.cli.commands.evaluate import evaluate_model
from voxelflex.cli.commands.visualize import create_visualizations
===== FILE: src/voxelflex/cli/cli.py =====
"""
Command Line Interface for Voxelflex.

This module provides the main CLI functionality for the Voxelflex package,
including argument parsing and command dispatching.
"""

import argparse
import logging
import os
import sys
from pathlib import Path
from typing import List, Optional

from voxelflex.config.config import load_config
from voxelflex.utils.logging_utils import pipeline_tracker, ProgressBar, get_logger, setup_logging, EnhancedProgressBar, log_memory_usage, log_operation_result, log_section_header, log_stage, log_step
from voxelflex.utils.system_utils import check_system_resources
from voxelflex.cli.commands.train import train_model
from voxelflex.cli.commands.predict import predict_rmsf
from voxelflex.cli.commands.evaluate import evaluate_model
from voxelflex.cli.commands.visualize import create_visualizations

logger = get_logger(__name__)

def parse_args(args: Optional[List[str]] = None) -> argparse.Namespace:
    """
    Parse command line arguments.
    
    Args:
        args: Command line arguments (if None, sys.argv[1:] is used)
        
    Returns:
        Parsed arguments
    """
    parser = argparse.ArgumentParser(
        prog="voxelflex",
        description="Voxelflex: A package for predicting per-residue RMSF values from voxelized protein data",
    )
    
    subparsers = parser.add_subparsers(dest="command", help="Command to run")
    
    # Run command (runs the entire pipeline)
    run_parser = subparsers.add_parser("run", help="Run the entire pipeline")
    run_parser.add_argument(
        "--config", 
        type=str, 
        required=True,
        help="Path to configuration file"
    )
    
    # Train command
    train_parser = subparsers.add_parser("train", help="Train a model")
    train_parser.add_argument(
        "--config", 
        type=str, 
        required=True,
        help="Path to configuration file with options for domain processing and memory management"
    )
    
    # Predict command
    predict_parser = subparsers.add_parser("predict", help="Make predictions with a trained model")
    predict_parser.add_argument(
        "--config", 
        type=str, 
        required=True,
        help="Path to configuration file with options for domain processing and memory management"
    )
    predict_parser.add_argument(
        "--model", 
        type=str, 
        required=True,
        help="Path to trained model file"
    )
    
    # Evaluate command
    evaluate_parser = subparsers.add_parser("evaluate", help="Evaluate model performance")
    evaluate_parser.add_argument(
        "--config", 
        type=str, 
        required=True,
        help="Path to configuration file with options for domain processing and memory management"
    )
    evaluate_parser.add_argument(
        "--model", 
        type=str, 
        required=True,
        help="Path to trained model file"
    )
    
    # Visualize command
    visualize_parser = subparsers.add_parser("visualize", help="Create visualizations")
    visualize_parser.add_argument(
        "--config", 
        type=str, 
        required=True,
        help="Path to configuration file"
    )
    visualize_parser.add_argument(
        "--predictions", 
        type=str, 
        required=True,
        help="Path to predictions file"
    )
    
    parsed_args = parser.parse_args(args)
    
    if parsed_args.command is None:
        parser.print_help()
        sys.exit(1)
    
    return parsed_args

def run_pipeline(config_path: str) -> None:
    """
    Run the entire pipeline: train, predict, evaluate, and visualize.
    
    Args:
        config_path: Path to configuration file
    """
    # Start pipeline tracking
    pipeline_tracker.start_stage("INITIALIZATION", "Loading configuration and setting up environment")
    
    # Load configuration
    config = load_config(config_path)
    
    # Set up logging
    log_file = os.path.join(
        config["output"]["base_dir"], 
        "logs", 
        config["output"]["log_file"]
    )
    setup_logging(
        log_file=log_file, 
        console_level=config["logging"]["console_level"],
        file_level=config["logging"]["file_level"]
    )
    
    logger = get_logger(__name__)
    
    # Log section header
    log_section_header(logger, "VOXELFLEX PIPELINE EXECUTION")
    
    # Check system resources
    system_info = check_system_resources(
        detect_cores=config["system_utilization"]["detect_cores"],
        adjust_for_gpu=config["system_utilization"]["adjust_for_gpu"]
    )
    logger.info(f"System resources: {system_info}")
    
    # Create output directories
    logger.info("Creating output directories")
    os.makedirs(os.path.join(config["output"]["base_dir"], "logs"), exist_ok=True)
    os.makedirs(os.path.join(config["output"]["base_dir"], "models"), exist_ok=True)
    os.makedirs(os.path.join(config["output"]["base_dir"], "metrics"), exist_ok=True)
    os.makedirs(os.path.join(config["output"]["base_dir"], "visualizations"), exist_ok=True)
    
    # End initialization stage
    pipeline_tracker.end_stage("INITIALIZATION")
    
    # Log initial memory usage
    log_memory_usage(logger)
    
    try:
        # Train the model
        logger.info("Starting model training phase")
        model_path, train_history = train_model(config)
        
        # Make predictions
        logger.info("Starting prediction phase")
        pipeline_tracker.start_stage("PREDICTION", "Making predictions with trained model")
        predictions_path = predict_rmsf(config, model_path)
        pipeline_tracker.end_stage("PREDICTION")
        
        # Evaluate the model
        logger.info("Starting evaluation phase")
        pipeline_tracker.start_stage("EVALUATION", "Evaluating model performance")
        metrics_path = evaluate_model(config, model_path, predictions_path)
        pipeline_tracker.end_stage("EVALUATION")
        
        # Create visualizations
        logger.info("Starting visualization phase")
        pipeline_tracker.start_stage("VISUALIZATION", "Creating performance visualizations")
        visualization_paths = create_visualizations(config, train_history, predictions_path)
        pipeline_tracker.end_stage("VISUALIZATION")
        
        # Cleanup and log summary
        pipeline_tracker.start_stage("CLEANUP", "Finalizing pipeline and logging results")
        
        # Log final memory usage
        log_memory_usage(logger)
        
        # Log summary of results
        logger.info("Pipeline completed successfully")
        logger.info(f"Model saved to: {model_path}")
        logger.info(f"Predictions saved to: {predictions_path}")
        logger.info(f"Metrics saved to: {metrics_path}")
        logger.info(f"Visualizations saved to: {os.path.join(config['output']['base_dir'], 'visualizations')}")
        
        pipeline_tracker.end_stage("CLEANUP")
        
    except Exception as e:
        logger.error(f"Pipeline execution failed: {str(e)}", exc_info=True)
        if pipeline_tracker.current_stage:
            pipeline_tracker.end_stage()
        raise

# def run_pipeline(config_path: str) -> None:
#     """
#     Run the entire pipeline: train, predict, evaluate, and visualize.
    
#     Args:
#         config_path: Path to configuration file
#     """
#     # Load configuration
#     config = load_config(config_path)
    
#     # Set up logging
#     log_file = os.path.join(
#         config["output"]["base_dir"], 
#         "logs", 
#         config["output"]["log_file"]
#     )
#     setup_logging(
#         log_file=log_file, 
#         console_level=config["logging"]["console_level"],
#         file_level=config["logging"]["file_level"]
#     )
    
#     # Check system resources
#     system_info = check_system_resources(
#         detect_cores=config["system_utilization"]["detect_cores"],
#         adjust_for_gpu=config["system_utilization"]["adjust_for_gpu"]
#     )
#     logger.info(f"System resources: {system_info}")
    
#     # Create output directories
#     os.makedirs(os.path.join(config["output"]["base_dir"], "logs"), exist_ok=True)
#     os.makedirs(os.path.join(config["output"]["base_dir"], "models"), exist_ok=True)
#     os.makedirs(os.path.join(config["output"]["base_dir"], "metrics"), exist_ok=True)
#     os.makedirs(os.path.join(config["output"]["base_dir"], "visualizations"), exist_ok=True)
    
#     # Train the model
#     logger.info("Starting model training")
#     model_path, train_history = train_model(config)
    
#     # Make predictions
#     logger.info("Making predictions")
#     predictions_path = predict_rmsf(config, model_path)
    
#     # Evaluate the model
#     logger.info("Evaluating model performance")
#     metrics_path = evaluate_model(config, model_path, predictions_path)
    
#     # Create visualizations
#     logger.info("Creating visualizations")
#     create_visualizations(config, train_history, predictions_path)
    
#     logger.info("Pipeline completed successfully")
#     logger.info(f"Model saved to: {model_path}")
#     logger.info(f"Predictions saved to: {predictions_path}")
#     logger.info(f"Metrics saved to: {metrics_path}")
#     logger.info(f"Visualizations saved to: {os.path.join(config['output']['base_dir'], 'visualizations')}")


def main(args: Optional[List[str]] = None) -> None:
    """
    Main entry point for the CLI.
    
    Args:
        args: Command line arguments (if None, sys.argv[1:] is used)
    """
    parsed_args = parse_args(args)
    
    if parsed_args.command == "run":
        run_pipeline(parsed_args.config)
    elif parsed_args.command == "train":
        config = load_config(parsed_args.config)
        setup_logging(
            log_file=os.path.join(config["output"]["base_dir"], "logs", config["output"]["log_file"]),
            console_level=config["logging"]["console_level"],
            file_level=config["logging"]["file_level"]
        )
        train_model(config)
    elif parsed_args.command == "predict":
        config = load_config(parsed_args.config)
        setup_logging(
            log_file=os.path.join(config["output"]["base_dir"], "logs", config["output"]["log_file"]),
            console_level=config["logging"]["console_level"],
            file_level=config["logging"]["file_level"]
        )
        predict_rmsf(config, parsed_args.model)
    elif parsed_args.command == "evaluate":
        config = load_config(parsed_args.config)
        setup_logging(
            log_file=os.path.join(config["output"]["base_dir"], "logs", config["output"]["log_file"]),
            console_level=config["logging"]["console_level"],
            file_level=config["logging"]["file_level"]
        )
        evaluate_model(config, parsed_args.model)
    elif parsed_args.command == "visualize":
        config = load_config(parsed_args.config)
        setup_logging(
            log_file=os.path.join(config["output"]["base_dir"], "logs", config["output"]["log_file"]),
            console_level=config["logging"]["console_level"],
            file_level=config["logging"]["file_level"]
        )
        create_visualizations(config, None, parsed_args.predictions)


if __name__ == "__main__":
    main()
===== FILE: src/voxelflex/cli/__init__.py =====
# In src/voxelflex/cli/__init__.py
from voxelflex.cli.commands import train, predict, evaluate, visualize
===== FILE: src/voxelflex/data/validators.py =====

"""
Data validation module for Voxelflex.

This module provides functions to validate voxel and RMSF data
to ensure consistency and proper format before processing.
"""

import logging
from typing import Dict, List, Set, Any

import numpy as np
import pandas as pd

from voxelflex.utils.logging_utils import get_logger

logger = get_logger(__name__)

def validate_voxel_data(voxel_data: Dict[str, Dict[str, np.ndarray]]) -> Dict[str, Dict[str, np.ndarray]]:
    """
    Validate voxel data to ensure consistent shapes and formats.
    
    Args:
        voxel_data: Dictionary mapping domain IDs to dictionaries of residue voxel data
        
    Returns:
        Validated voxel data
    """
    logger.info("Validating voxel data")
    
    if not voxel_data:
        logger.error("Empty voxel data. Check your voxel file structure and domain_ids configuration.")
        logger.error("If using specific domain_ids, ensure they match the base names in the voxel file.")
        raise ValueError("Empty voxel data. Check logs for troubleshooting details.")
    
    valid_data = {}
    expected_ndim = None
    expected_channels = None
    
    # First pass: determine expected dimensions
    for domain_id, domain_data in voxel_data.items():
        if not domain_data:
            logger.warning(f"Empty domain data for {domain_id}")
            continue
            
        # Get the first residue's voxel data to determine expected shape
        first_resid = next(iter(domain_data))
        first_voxel = domain_data[first_resid]
        
        if expected_ndim is None:
            expected_ndim = first_voxel.ndim
            if expected_ndim != 4:  # [channels, x, y, z]
                logger.warning(f"Unexpected voxel dimensions: {expected_ndim}, expected 4")
            
        if expected_channels is None and expected_ndim >= 1:
            expected_channels = first_voxel.shape[0]
            logger.info(f"Detected {expected_channels} channels in voxel data")
            
            # Check if we have the right number of channels
            if expected_channels not in [4, 5]:
                logger.warning(f"Unexpected number of channels: {expected_channels}, expected 4 or 5")
    
    # Second pass: validate and filter data
    total_residues = 0
    valid_residues = 0
    
    for domain_id, domain_data in voxel_data.items():
        valid_domain_data = {}
        
        for resid, voxel in domain_data.items():
            total_residues += 1
            
            # Check dimensions
            if voxel.ndim != expected_ndim:
                logger.debug(f"Skipping {domain_id}:{resid} - Inconsistent dimensions: {voxel.ndim} vs {expected_ndim}")
                continue
                
            # Check number of channels
            if voxel.shape[0] != expected_channels:
                logger.debug(f"Skipping {domain_id}:{resid} - Inconsistent channels: {voxel.shape[0]} vs {expected_channels}")
                continue
            
            # Check for NaN or Inf values
            if np.isnan(voxel).any() or np.isinf(voxel).any():
                logger.debug(f"Skipping {domain_id}:{resid} - Contains NaN or Inf values")
                continue
            
            valid_domain_data[resid] = voxel
            valid_residues += 1
        
        if valid_domain_data:
            valid_data[domain_id] = valid_domain_data
    
    logger.info(f"Validated {valid_residues}/{total_residues} residues "
                f"across {len(valid_data)}/{len(voxel_data)} domains")
    
    if not valid_data:
        # Provide detailed troubleshooting information
        logger.error("No valid voxel data after validation")
        logger.error("Potential issues:")
        logger.error("1. The structure of your voxel file may not match what the code expects")
        logger.error("2. The voxel data may have inconsistent shapes or contain NaN/Inf values")
        logger.error("3. You may need to adjust the validation criteria in the code")
        logger.error("Try running with verbose logging and check the file structure directly")
        raise ValueError("No valid voxel data after validation. Check logs for details.")
    
    return valid_data

def validate_rmsf_data(rmsf_data: pd.DataFrame) -> pd.DataFrame:
    """
    Validate RMSF data to ensure it has the required columns and format.
    
    Args:
        rmsf_data: DataFrame containing RMSF data
        
    Returns:
        Validated RMSF data
    """
    logger.info("Validating RMSF data")
    
    # Check if the dataframe is empty
    if rmsf_data.empty:
        raise ValueError("Empty RMSF data")
    
    # Check for required columns
    required_columns = ['domain_id', 'resid', 'resname', 'average_rmsf']
    missing_columns = [col for col in required_columns if col not in rmsf_data.columns]
    
    if missing_columns:
        raise ValueError(f"RMSF data missing required columns: {missing_columns}")
    
    # Check for NaN values
    nan_counts = rmsf_data[required_columns].isna().sum()
    if nan_counts.sum() > 0:
        logger.warning(f"RMSF data contains NaN values: {nan_counts}")
        
        # Drop rows with NaN values in required columns
        rmsf_data = rmsf_data.dropna(subset=required_columns)
        logger.info(f"Dropped rows with NaN values, {len(rmsf_data)} rows remain")
    
    # Check for negative RMSF values
    negative_rmsf = (rmsf_data['average_rmsf'] < 0).sum()
    if negative_rmsf > 0:
        logger.warning(f"RMSF data contains {negative_rmsf} negative values")
        
        # Filter out negative values
        rmsf_data = rmsf_data[rmsf_data['average_rmsf'] >= 0]
        logger.info(f"Filtered out negative RMSF values, {len(rmsf_data)} rows remain")
    
    # Check for duplicate (domain_id, resid) pairs
    duplicates = rmsf_data.duplicated(subset=['domain_id', 'resid']).sum()
    if duplicates > 0:
        logger.warning(f"RMSF data contains {duplicates} duplicate (domain_id, resid) pairs")
        
        # Keep only the first occurrence of each pair
        rmsf_data = rmsf_data.drop_duplicates(subset=['domain_id', 'resid'])
        logger.info(f"Removed duplicates, {len(rmsf_data)} rows remain")
    
    if rmsf_data.empty:
        raise ValueError("No valid RMSF data after validation")
    
    logger.info(f"RMSF data validation complete: {len(rmsf_data)} valid entries")
    
    # Print summary statistics
    logger.info(f"RMSF value range: [{rmsf_data['average_rmsf'].min():.4f}, {rmsf_data['average_rmsf'].max():.4f}]")
    logger.info(f"RMSF value mean: {rmsf_data['average_rmsf'].mean():.4f}")
    logger.info(f"Number of unique domains: {rmsf_data['domain_id'].nunique()}")
    logger.info(f"Number of unique residue types: {rmsf_data['resname'].nunique()}")
    
    return rmsf_data


def validate_domain_residue_mapping(
    voxel_data: Dict[str, Dict[str, np.ndarray]],
    rmsf_data: pd.DataFrame,
    domain_mapping: Dict[str, str]
) -> None:
    """
    Validate mapping between voxel and RMSF data at domain and residue level.
    
    Args:
        voxel_data: Dictionary mapping domain IDs to voxel data
        rmsf_data: DataFrame containing RMSF data
        domain_mapping: Mapping from voxel domain IDs to RMSF domain IDs
    """
    logger.info("Validating domain and residue mapping")
    
    # Count the number of domains in each dataset
    num_voxel_domains = len(voxel_data)
    num_rmsf_domains = rmsf_data['domain_id'].nunique()
    num_mapped_domains = len(domain_mapping)
    
    logger.info(f"Voxel domains: {num_voxel_domains}, RMSF domains: {num_rmsf_domains}, "
                f"Mapped domains: {num_mapped_domains}")
    
    # Analyze domain patterns
    voxel_domain_patterns = set()
    for domain in list(voxel_data.keys())[:min(100, len(voxel_data))]:
        if '_' in domain:
            pattern = domain.split('_', 1)[1]  # Everything after first '_'
            voxel_domain_patterns.add(pattern)
    
    rmsf_domain_patterns = set()
    for domain in rmsf_data['domain_id'].unique()[:min(100, len(rmsf_data['domain_id'].unique()))]:
        if '_' in domain:
            pattern = domain.split('_', 1)[1]  # Everything after first '_'
            rmsf_domain_patterns.add(pattern)
    
    logger.info(f"Voxel domain patterns: {voxel_domain_patterns}")
    logger.info(f"RMSF domain patterns: {rmsf_domain_patterns}")
    
    # Check mapping coverage
    unmapped_domains = [d for d in voxel_data.keys() if d not in domain_mapping]
    if unmapped_domains:
        logger.warning(f"{len(unmapped_domains)}/{num_voxel_domains} voxel domains could not be mapped to RMSF domains")
        logger.debug(f"Unmapped domains: {unmapped_domains[:5]}{'...' if len(unmapped_domains) > 5 else ''}")
        
        # Check if unmapped domains could be due to suffix issues
        suffix_issues = 0
        for domain in unmapped_domains[:min(50, len(unmapped_domains))]:
            base_name = domain.split('_')[0]
            for rmsf_domain in rmsf_data['domain_id'].unique():
                if rmsf_domain == base_name or rmsf_domain.startswith(base_name):
                    suffix_issues += 1
                    break
        
        if suffix_issues > 0:
            logger.warning(f"At least {suffix_issues} unmapped domains may be due to suffix differences between datasets")
    
    # Check residue mapping
    total_voxel_residues = sum(len(domain_data) for domain_data in voxel_data.values())
    mapped_residues = 0
    
    # Create a set of (domain_id, resid) pairs from RMSF data for faster lookup
    rmsf_domain_resid_set = set(
        (domain, resid) for domain, resid in 
        zip(rmsf_data['domain_id'], rmsf_data['resid'])
    )
    
    # Also create a set with base domain names for more flexible mapping
    rmsf_base_domain_resid_set = set()
    for domain, resid in zip(rmsf_data['domain_id'], rmsf_data['resid']):
        base_domain = domain.split('_')[0] if '_' in domain else domain
        rmsf_base_domain_resid_set.add((base_domain, resid))
    
    # Check each voxel residue
    residue_mapping_issues = 0
    sample_issues = []
    
    for voxel_domain, domain_data in voxel_data.items():
        if voxel_domain not in domain_mapping:
            continue
            
        rmsf_domain = domain_mapping[voxel_domain]
        
        for resid in domain_data:
            try:
                resid_int = int(resid)
                if (rmsf_domain, resid_int) in rmsf_domain_resid_set:
                    mapped_residues += 1
                else:
                    # Try base domain name as fallback
                    base_domain = voxel_domain.split('_')[0] if '_' in voxel_domain else voxel_domain
                    if (base_domain, resid_int) in rmsf_base_domain_resid_set:
                        mapped_residues += 1
                    else:
                        residue_mapping_issues += 1
                        if len(sample_issues) < 5:
                            sample_issues.append((voxel_domain, resid_int, rmsf_domain))
            except ValueError:
                logger.debug(f"Could not convert residue ID to integer: {resid}")
    
    logger.info(f"Successfully mapped {mapped_residues}/{total_voxel_residues} voxel residues to RMSF data "
                f"({mapped_residues/total_voxel_residues*100:.1f}%)")
    
    if residue_mapping_issues > 0:
        logger.warning(f"Found {residue_mapping_issues} residues that couldn't be mapped from voxel to RMSF data")
        if sample_issues:
            logger.debug(f"Sample mapping issues: {sample_issues}")
    
    if mapped_residues == 0:
        raise ValueError("No residues could be mapped between voxel and RMSF data")
===== FILE: src/voxelflex/data/data_loader.py =====
"""
Data loading module for Voxelflex.

This module handles loading and processing of voxelized protein data (.hdf5)
and RMSF data (.csv).
"""

import os
import logging
import h5py  # Make sure this import is here
import psutil  # For memory monitoring
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union, Any
import time

import h5py
import numpy as np
import pandas as pd
import torch
import multiprocessing
from torch.utils.data import Dataset, DataLoader

from voxelflex.data.validators import (
    validate_voxel_data,
    validate_rmsf_data,
    validate_domain_residue_mapping
)
from voxelflex.utils.logging_utils import (
    get_logger, 
    setup_logging, 
    EnhancedProgressBar, 
    log_memory_usage, 
    log_operation_result, 
    log_section_header, 
    log_stage, 
    log_step
)
from voxelflex.utils.file_utils import resolve_path
from voxelflex.utils.system_utils import (
    get_device, 
    check_system_resources, 
    clear_memory, 
    check_memory_usage,
    set_num_threads, 
    is_memory_critical, 
    estimate_batch_size, 
    adjust_workers_for_memory
)

logger = get_logger(__name__)

class RMSFDataset(Dataset):
    """PyTorch Dataset for voxel and RMSF data with dramatically improved performance."""
    
    def __init__(
        self,
        voxel_data: Dict[str, Dict[str, np.ndarray]],
        rmsf_data: pd.DataFrame,
        domain_mapping: Dict[str, str],
        transform=None,
        memory_efficient: bool = False,  # Default to False for better performance
        global_rmsf_lookup: Dict[Tuple[str, int], float] = None
    ):
        """
        Initialize RMSF dataset with highly optimized performance.
        
        Args:
            voxel_data: Dictionary mapping domain_ids to voxel data
            rmsf_data: DataFrame containing RMSF values
            domain_mapping: Mapping from hdf5 domain to RMSF domain
            transform: Optional transforms to apply
            memory_efficient: If True, use memory-efficient mode (default: False)
            global_rmsf_lookup: Pre-computed global RMSF lookup dictionary
        """
        self.voxel_data = voxel_data
        self.domain_mapping = domain_mapping
        self.transform = transform
        self.memory_efficient = memory_efficient
        
        # Keep original DataFrame for __getitem__ fallbacks
        self.rmsf_data = rmsf_data
        
        # Track timing for performance analysis
        start_time = time.time()
        
        # Use pre-computed lookup if provided
        if global_rmsf_lookup is not None:
            logger.info("Using pre-computed global RMSF lookup")
            self.rmsf_lookup = global_rmsf_lookup
            lookup_time = 0.0
        else:
            # Create RMSF lookup dictionary
            logger.info("Creating optimized RMSF lookup dictionary")
            
            # Extract columns as numpy arrays for faster processing
            domains = rmsf_data['domain_id'].values
            resids = rmsf_data['resid'].values
            rmsfs = rmsf_data['average_rmsf'].values
            
            # Create lookup in a single, efficient pass
            self.rmsf_lookup = {}
            for i in range(len(domains)):
                try:
                    resid_int = int(resids[i])
                    self.rmsf_lookup[(domains[i], resid_int)] = rmsfs[i]
                except (ValueError, TypeError):
                    continue
            
            lookup_time = time.time() - start_time
            logger.info(f"Created RMSF lookup with {len(self.rmsf_lookup)} entries in {lookup_time:.2f} seconds")
            
            # Create additional lookup dictionaries for faster access
            base_domain_time = time.time()
            
            # Create base domain lookup
            self.base_domain_lookup = {}
            for domain in set(domains):
                base_domain = domain.split('_')[0] if '_' in domain else domain
                self.base_domain_lookup[domain] = base_domain
            
            # Create optimized base domain lookup for faster residue matching
            self.base_rmsf_lookup = {}
            for (domain, resid), rmsf in self.rmsf_lookup.items():
                base_domain = domain.split('_')[0] if '_' in domain else domain
                if base_domain not in self.base_rmsf_lookup:
                    self.base_rmsf_lookup[base_domain] = {}
                self.base_rmsf_lookup[base_domain][resid] = rmsf
                
            logger.debug(f"Created base domain lookups in {time.time() - base_domain_time:.2f} seconds")
        
        # Create samples list with optimized algorithm
        samples_start_time = time.time()
        logger.info("Creating dataset samples list with optimized algorithm")
        
        # Count total residues for pre-allocation (avoid resizing)
        total_residues = sum(len(domain_data) for domain_data in voxel_data.values())
        
        # Pre-allocate samples list with enough capacity
        # Reserve approximately 80% of total residues (high estimated match rate)
        self.samples = [None] * (total_residues * 8 // 10)
        self.sample_count = 0
        
        # Track statistics
        total_domains = len(voxel_data)
        matched_residues = 0
        direct_matches = 0
        base_matches = 0
        
        # Process all domains and residues
        for domain_id, domain_data in voxel_data.items():
            mapped_domain = domain_mapping.get(domain_id, domain_id)
            domain_matches = 0
            
            # Process all residues in the domain
            for resid in domain_data:
                try:
                    resid_int = int(resid)
                    lookup_key = (mapped_domain, resid_int)
                    added = False
                    
                    # First try direct lookup
                    if lookup_key in self.rmsf_lookup:
                        self._add_sample(domain_id, resid)
                        domain_matches += 1
                        matched_residues += 1
                        direct_matches += 1
                        added = True
                    
                    # If not found directly, try with base domain name
                    if not added:
                        base_domain = domain_id.split('_')[0] if '_' in domain_id else domain_id
                        alt_key = (base_domain, resid_int)
                        
                        if alt_key in self.rmsf_lookup:
                            self._add_sample(domain_id, resid)
                            domain_matches += 1
                            matched_residues += 1
                            base_matches += 1
                            added = True
                except Exception as e:
                    # Skip invalid residues silently
                    pass
        
        # Resize samples list to actual count
        self.samples = self.samples[:self.sample_count]
        
        samples_time = time.time() - samples_start_time
        total_time = time.time() - start_time
        
        logger.info(f"Created dataset with {len(self.samples)} samples from {matched_residues} "
                    f"residues across {total_domains} domains in {total_time:.2f} seconds")
        logger.info(f"Direct matches: {direct_matches}, Base name matches: {base_matches}")
    
    def _add_sample(self, domain_id, resid):
        """Helper method to add a sample to the samples list."""
        if self.sample_count < len(self.samples):
            self.samples[self.sample_count] = (domain_id, resid)
        else:
            self.samples.append((domain_id, resid))
        self.sample_count += 1
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def __getitem__(self, idx) -> Tuple[torch.Tensor, torch.Tensor]:
        """Get a data sample with improved error handling and lookup performance."""
        domain_id, resid = self.samples[idx]
        
        try:
            # Access voxel data
            voxel = self.voxel_data[domain_id][resid]
            
            # Get the corresponding RMSF value using optimized lookup
            rmsf_domain = self.domain_mapping.get(domain_id, domain_id)
            lookup_key = (rmsf_domain, int(resid))
            
            if lookup_key in self.rmsf_lookup:
                rmsf_value = self.rmsf_lookup[lookup_key]
            else:
                # Try alternative lookup strategies
                alt_lookup_successful = False
                
                # Strategy 1: Try with base domain name
                base_domain = domain_id.split('_')[0]
                alt_key = (base_domain, int(resid))
                
                if alt_key in self.rmsf_lookup:
                    rmsf_value = self.rmsf_lookup[alt_key]
                    alt_lookup_successful = True
                    # Update the lookup for future use
                    self.rmsf_lookup[lookup_key] = rmsf_value
                
                # If alternative lookup failed
                if not alt_lookup_successful:
                    # Since we verified during initialization that this should have a match,
                    # this is likely an error condition
                    logger.warning(f"RMSF value not found for {domain_id}:{resid} (mapped to {rmsf_domain})")
                    
                    # Return a dummy tensor with dataset mean
                    rmsf_value = self.rmsf_data['average_rmsf'].median()
            
            # Convert to tensors
            voxel_tensor = torch.tensor(voxel, dtype=torch.float32)
            rmsf_tensor = torch.tensor(rmsf_value, dtype=torch.float32)
            
            if self.transform:
                voxel_tensor = self.transform(voxel_tensor)
                    
            return voxel_tensor, rmsf_tensor
                
        except Exception as e:
            logger.error(f"Error retrieving item {idx} (domain={domain_id}, resid={resid}): {str(e)}")
            
            # Create dummy data with same shape as expected to avoid crashing
            if hasattr(self, '_dummy_shape'):
                dummy_shape = self._dummy_shape
            else:
                # Try to find the shape from any valid sample
                for test_idx in range(min(100, len(self.samples))):
                    if test_idx == idx:
                        continue
                    try:
                        test_domain, test_resid = self.samples[test_idx]
                        dummy_shape = self.voxel_data[test_domain][test_resid].shape
                        self._dummy_shape = dummy_shape
                        break
                    except:
                        continue
                else:
                    # If we couldn't find any valid sample, use a default shape
                    dummy_shape = (5, 24, 24, 24)  # Common shape for voxel data
                    self._dummy_shape = dummy_shape
            
            # Create dummy tensors
            dummy_voxel = torch.zeros(dummy_shape, dtype=torch.float32)
            dummy_rmsf = torch.tensor(0.0, dtype=torch.float32)
            
            return dummy_voxel, dummy_rmsf
    
def load_voxel_data(
        voxel_file: str,
        domain_ids: Optional[List[str]] = None,
        max_domains: Optional[int] = None,
        memory_ceiling_percent: float = 80.0,  # Reduced from original 85.0
        out_of_core_mode: bool = True, 
    ) -> Dict[str, Dict[str, np.ndarray]]:
        """
        Load voxel data from HDF5 file with improved memory management.
        
        Args:
            voxel_file: Path to HDF5 file
            domain_ids: Optional list of domain IDs to load. If None, load all domains
                        (subject to memory constraints)
            max_domains: Optional limit on number of domains to load
            memory_ceiling_percent: Memory usage ceiling (percent of system RAM)
                                    above which no new domains will be loaded
            out_of_core_mode: If True, use out-of-core processing with memory mapping
            
        Returns:
            Dictionary mapping domain IDs to dictionaries of residue voxel data
        """
        voxel_file = resolve_path(voxel_file)
        logger.info(f"Loading voxel data from {voxel_file}")
        
        if not os.path.exists(voxel_file):
            raise FileNotFoundError(f"Voxel file not found: {voxel_file}")
        
        # Get initial memory stats
        memory_stats = check_memory_usage()
        logger.info(f"Initial memory: System: {memory_stats['system_percent']}% used, "
                f"Process: {memory_stats['process_rss_gb']:.2f} GB")
        
        # Aggressive memory clearing before starting to create space
        clear_memory(force_gc=True, clear_cuda=True)
        
        # Dictionary to store loaded domain data
        voxel_data = {}
        
        # Create temp directory for memory-mapped files if using out-of-core mode
        temp_dir = None
        if out_of_core_mode:
            import tempfile
            import atexit
            import shutil
            
            temp_dir = tempfile.mkdtemp(prefix="voxelflex_")
            logger.info(f"Created temporary directory for out-of-core processing: {temp_dir}")
            
            # Register cleanup function to ensure temp files are removed
            def cleanup_temp_dir():
                if os.path.exists(temp_dir):
                    logger.info(f"Removing temporary directory: {temp_dir}")
                    try:
                        shutil.rmtree(temp_dir)
                    except Exception as e:
                        logger.warning(f"Failed to remove temp directory: {str(e)}")
            
            atexit.register(cleanup_temp_dir)
        
        # Set a more conservative memory ceiling for loading new domains
        # This leaves more headroom for processing after loading
        actual_memory_ceiling = min(memory_ceiling_percent, 75.0)
        logger.info(f"Using memory ceiling of {actual_memory_ceiling}% for domain loading")
        
        with h5py.File(voxel_file, 'r') as f:
            # Get list of all domains in the file
            available_domains = list(f.keys())
            logger.info(f"Found {len(available_domains)} domains in voxel file")
            
            # Filter domains if domain_ids is provided and not empty
            if domain_ids and len(domain_ids) > 0:
                logger.info(f"Filtering domains based on provided domain_ids (n={len(domain_ids)})")
                domains_to_process = []
                for domain in available_domains:
                    # Extract base domain (remove _pdb, _pdb_clean, etc.)
                    base_domain = domain.split('_')[0]
                    if base_domain in domain_ids or domain in domain_ids:
                        domains_to_process.append(domain)
                
                if not domains_to_process:
                    logger.warning(f"None of the specified domain_ids were found in the voxel file")
                    # Show some examples to help with debugging
                    sample_domains = [d.split('_')[0] for d in available_domains[:10]]
                    logger.debug(f"First few available domain IDs (base names): {sample_domains}...")
                    logger.debug(f"Specified domain_ids: {domain_ids}")
                    
                    # Try more flexible matching as a fallback
                    logger.info("Trying more flexible domain matching...")
                    for domain in available_domains:
                        base_domain = domain.split('_')[0]
                        # Try to find partial matches
                        for domain_id in domain_ids:
                            if domain_id in base_domain or base_domain in domain_id:
                                logger.info(f"Found flexible match: {domain} for requested {domain_id}")
                                domains_to_process.append(domain)
                                break
            else:
                domains_to_process = available_domains
            
            # Apply max_domains limit if specified
            if max_domains is not None and max_domains > 0 and len(domains_to_process) > max_domains:
                logger.info(f"Limiting to {max_domains} domains (out of {len(domains_to_process)} available)")
                domains_to_process = domains_to_process[:max_domains]
            
            # Analyze domains to estimate memory requirements and sort by size
            domain_size_estimates = []
            
            for domain_idx, domain_id in enumerate(domains_to_process[:min(50, len(domains_to_process))]):
                try:
                    domain_group = f[domain_id]
                    
                    if len(domain_group.keys()) == 0:
                        logger.warning(f"Domain {domain_id} has no children")
                        continue
                        
                    first_child_key = list(domain_group.keys())[0]
                    residue_group = domain_group[first_child_key]
                    
                    # Count residues to estimate domain size
                    residue_keys = [k for k in residue_group.keys() if isinstance(k, str) and k.isdigit()]
                    
                    # If we have residues, estimate domain size
                    if residue_keys:
                        sample_residue = residue_keys[0]
                        residue_data = residue_group[sample_residue]
                        
                        if isinstance(residue_data, h5py.Dataset):
                            # Estimate size of single residue
                            shape = residue_data.shape
                            element_size = residue_data.dtype.itemsize
                            residue_size_bytes = np.prod(shape) * element_size
                            
                            # Estimate size of domain based on residue count
                            domain_size_bytes = residue_size_bytes * len(residue_keys)
                            domain_size_gb = domain_size_bytes / (1024**3)
                            
                            domain_size_estimates.append((domain_id, domain_size_gb, len(residue_keys)))
                            
                            if domain_idx < 5 or domain_idx % 20 == 0:
                                logger.debug(f"Domain {domain_id}: ~{domain_size_gb:.4f} GB, {len(residue_keys)} residues")
                except Exception as e:
                    logger.warning(f"Error estimating size for domain {domain_id}: {str(e)}")
            
            # Sort domains by size (smaller domains first to prioritize)
            if domain_size_estimates:
                # Sort by estimated size
                domain_size_estimates.sort(key=lambda x: x[1])
                
                # Reorder domains_to_process based on size
                sorted_domain_ids = [d[0] for d in domain_size_estimates]
                remaining_domain_ids = [d for d in domains_to_process if d not in sorted_domain_ids]
                
                domains_to_process = sorted_domain_ids + remaining_domain_ids
                logger.info(f"Prioritized domains by size. Smallest: {domain_size_estimates[0][0]} ({domain_size_estimates[0][1]:.4f} GB)")
                logger.info(f"Largest analyzed: {domain_size_estimates[-1][0]} ({domain_size_estimates[-1][1]:.4f} GB)")
            
            # Calculate a more conservative domain limit based on memory
            if domain_size_estimates:
                avg_domain_size_gb = sum(d[1] for d in domain_size_estimates) / len(domain_size_estimates)
                memory = psutil.virtual_memory()
                available_gb = memory.available / (1024**3)
                
                # More conservative memory usage (60% of available)
                safe_memory_usage_gb = available_gb * 0.6
                
                # Account for memory overhead and leave room for processing
                estimated_max_domains = int(safe_memory_usage_gb / (avg_domain_size_gb * 1.5))
                
                logger.info(f"Average domain size: {avg_domain_size_gb:.4f} GB")
                logger.info(f"Available memory: {available_gb:.2f} GB, safe usage: {safe_memory_usage_gb:.2f} GB")
                logger.info(f"Can safely process approximately {estimated_max_domains} domains")
                
                # Apply adaptive domain limit if needed
                if max_domains is None or estimated_max_domains < max_domains:
                    domains_to_process = domains_to_process[:estimated_max_domains]
                    logger.warning(f"Auto-limiting to {len(domains_to_process)} domains based on memory constraints")
            
            # Process domains with careful memory monitoring
            logger.info(f"Processing {len(domains_to_process)} domains")
            domains_processed = 0
            
            # Create progress bar
            progress = EnhancedProgressBar(
                len(domains_to_process), 
                prefix="Loading domains", 
                suffix="Complete",
                stage_info="DATA_LOADING"
            )
            
            # Iterate through domains
            for domain_idx, domain_id in enumerate(domains_to_process):
                # Check memory before loading this domain
                memory_stats = check_memory_usage()
                current_memory_percent = memory_stats['system_percent']
                
                # Use more conservative memory ceiling
                if current_memory_percent >= actual_memory_ceiling:
                    logger.warning(f"Memory ceiling ({actual_memory_ceiling}%) reached at "
                                f"{current_memory_percent}% after processing {domains_processed} domains")
                    logger.info(f"Stopping domain loading to preserve memory integrity")
                    break
                
                # Process one complete domain
                try:
                    domain_group = f[domain_id]
                    
                    if len(domain_group.keys()) == 0:
                        logger.warning(f"Domain {domain_id} has no children")
                        progress.update(domain_idx + 1)
                        continue
                        
                    # Get the first direct child
                    first_child_key = list(domain_group.keys())[0]
                    residue_group = domain_group[first_child_key]
                    
                    # Get all residue IDs (numeric keys)
                    residue_keys = [k for k in residue_group.keys() if isinstance(k, str) and k.isdigit()]
                    
                    if not residue_keys:
                        logger.warning(f"No valid residues found for domain {domain_id}")
                        progress.update(domain_idx + 1)
                        continue
                    
                    # Process all residues in the domain
                    domain_data = {}
                    
                    # Decide whether to use memory mapping
                    use_memmap = out_of_core_mode and len(residue_keys) > 100  # Use memmap for larger domains
                    
                    for resid in residue_keys:
                        try:
                            residue_data = residue_group[resid]
                            
                            if isinstance(residue_data, h5py.Dataset):
                                # Get shape and determine if transpose is needed
                                shape = residue_data.shape
                                voxel_data_raw = residue_data[:]
                                
                                # For datasets with shape (x, y, z, channels), transpose to (channels, x, y, z)
                                if len(shape) == 4 and shape[3] in [4, 5]:
                                    voxel = np.transpose(voxel_data_raw, (3, 0, 1, 2))
                                else:
                                    voxel = voxel_data_raw
                                
                                # Convert to float32 if needed
                                if voxel.dtype == bool:
                                    voxel = voxel.astype(np.float32)
                                elif voxel.dtype != np.float32:
                                    voxel = voxel.astype(np.float32)
                                
                                # Store using memory mapping for larger domains
                                if use_memmap:
                                    # Create memmap file
                                    memmap_file = os.path.join(temp_dir, f"{domain_id}_{resid}.npy")
                                    memmap_array = np.memmap(memmap_file, dtype=np.float32, 
                                                        mode='w+', shape=voxel.shape)
                                    # Copy data to memmap
                                    memmap_array[:] = voxel[:]
                                    memmap_array.flush()
                                    
                                    # Store memmap in domain data
                                    domain_data[resid] = memmap_array
                                else:
                                    # Store smaller voxels directly
                                    domain_data[resid] = voxel
                                
                                # Force explicit deletion of raw data
                                del voxel_data_raw
                                del voxel
                        except Exception as e:
                            logger.debug(f"Error processing residue {resid} for domain {domain_id}: {str(e)}")
                    
                    # Store the domain data if it has content
                    if domain_data:
                        voxel_data[domain_id] = domain_data
                        domains_processed += 1
                        
                        # Log details for large domains
                        if len(domain_data) > 200:
                            logger.info(f"Loaded large domain {domain_id} with {len(domain_data)} residues")
                    else:
                        logger.warning(f"No valid voxel data found for domain {domain_id}")
                    
                except Exception as e:
                    logger.error(f"Error processing domain {domain_id}: {str(e)}")
                
                # Update progress bar
                progress.update(domain_idx + 1)
                
                # Force periodic memory clearing
                if domain_idx % 2 == 0:  # More frequent clearing
                    clear_memory(force_gc=True, clear_cuda=True)
            
            # End progress bar
            progress.finish()
            
            # Report final processing statistics
            total_domains = len(domains_to_process)
            memory_stats = check_memory_usage()
            current_memory_percent = memory_stats['system_percent']
            
            logger.info(f"Domain loading complete: {domains_processed}/{total_domains} domains processed")
            logger.info(f"Current memory usage: {current_memory_percent:.1f}% "
                    f"({memory_stats['process_rss_gb']:.2f} GB)")
            
            if domains_processed < total_domains:
                logger.warning(f"{total_domains - domains_processed} domains were not processed "
                            f"due to memory constraints")
        
        # Validate the loaded voxel data
        if not voxel_data:
            logger.error("No valid voxel data was loaded")
            raise ValueError("No valid voxel data was loaded. Check the logs for details.")
        
        logger.info(f"Successfully loaded {len(voxel_data)} domains with a total of "
                f"{sum(len(d) for d in voxel_data.values())} residues")
        
        return voxel_data   
        
# def load_voxel_data(
#     voxel_file: str,
#     domain_ids: Optional[List[str]] = None,
#     max_domains: Optional[int] = None,
#     memory_ceiling_percent: float = 85.0,  # Reduced from 90.0
#     out_of_core_mode: bool = True
# ) -> Dict[str, Dict[str, np.ndarray]]:
#     """
#     Load voxel data from HDF5 file with intelligent memory management.
    
#     This function uses a domain-preserving, memory-aware strategy to load as many
#     complete domains as possible without exceeding the memory ceiling.
    
#     Args:
#         voxel_file: Path to HDF5 file
#         domain_ids: Optional list of domain IDs to load. If None, load all domains
#                     (subject to memory constraints)
#         max_domains: Optional limit on number of domains to load
#         memory_ceiling_percent: Memory usage ceiling (percent of system RAM)
#                                 above which no new domains will be loaded
#         out_of_core_mode: If True, use out-of-core processing techniques
#                          to minimize memory footprint
        
#     Returns:
#         Dictionary mapping domain IDs to dictionaries of residue voxel data
#     """
#     with log_stage("DATA_LOADING", f"Loading voxel data from {voxel_file}"):
#         voxel_file = resolve_path(voxel_file)
#         logger.info(f"Loading voxel data from {voxel_file}")
        
#         if not os.path.exists(voxel_file):
#             raise FileNotFoundError(f"Voxel file not found: {voxel_file}")
        
#         # Get initial memory stats
#         memory_stats = check_memory_usage()
#         logger.info(f"Initial memory: System: {memory_stats['system_percent']}% used, "
#                    f"Process: {memory_stats['process_rss_gb']:.2f} GB")
        
#         # Clear memory before starting to create space
#         clear_memory(force_gc=True, clear_cuda=True)
        
#         # Dictionary to store loaded domain data
#         voxel_data = {}
        
#         # Create temp directory for memory-mapped files if using out-of-core mode
#         if out_of_core_mode:
#             import tempfile
#             import atexit
#             import shutil
            
#             temp_dir = tempfile.mkdtemp(prefix="voxelflex_")
#             logger.info(f"Created temporary directory for out-of-core processing: {temp_dir}")
            
#             # Register cleanup function
#             def cleanup_temp_dir():
#                 if os.path.exists(temp_dir):
#                     logger.info(f"Removing temporary directory: {temp_dir}")
#                     try:
#                         shutil.rmtree(temp_dir)
#                     except Exception as e:
#                         logger.warning(f"Failed to remove temp directory: {str(e)}")
            
#             atexit.register(cleanup_temp_dir)
        
#         with h5py.File(voxel_file, 'r') as f:
#             # Get list of all domains in the file
#             available_domains = list(f.keys())
#             logger.info(f"Found {len(available_domains)} domains in voxel file")
            
#             # Filter domains if domain_ids is provided and not empty
#             if domain_ids and len(domain_ids) > 0:
#                 domains_to_process = []
#                 for domain in available_domains:
#                     # Extract base domain (remove _pdb, _pdb_clean, etc.)
#                     base_domain = domain.split('_')[0]
#                     if base_domain in domain_ids:
#                         domains_to_process.append(domain)
                
#                 if not domains_to_process:
#                     logger.warning(f"None of the specified domain_ids were found in the voxel file")
#                     # Show some examples to help with debugging
#                     sample_domains = [d.split('_')[0] for d in available_domains[:10]]
#                     logger.debug(f"First few available domain IDs (base names): {sample_domains}...")
#                     logger.debug(f"Specified domain_ids: {domain_ids}")
                    
#                     # Try more flexible matching as a fallback
#                     logger.info("Trying more flexible domain matching...")
#                     for domain in available_domains:
#                         base_domain = domain.split('_')[0]
#                         # Try to find partial matches
#                         for domain_id in domain_ids:
#                             if domain_id in base_domain or base_domain in domain_id:
#                                 logger.info(f"Found flexible match: {domain} for requested {domain_id}")
#                                 domains_to_process.append(domain)
#                                 break
#             else:
#                 domains_to_process = available_domains
            
#             # Apply max_domains limit if specified
#             if max_domains is not None and max_domains > 0 and len(domains_to_process) > max_domains:
#                 logger.info(f"Limiting to {max_domains} domains (out of {len(domains_to_process)} available)")
#                 domains_to_process = domains_to_process[:max_domains]
            
#             logger.info(f"Preparing to process {len(domains_to_process)} domains")
            
#             # Check if we have any domains to process
#             if not domains_to_process:
#                 logger.warning("No domains to process. Please check your domain_ids configuration.")
#                 return {}  # Return empty dictionary
            
#             # First, analyze domains to estimate memory requirements and sort by size
#             domain_size_estimates = []
            
#             for domain_idx, domain_id in enumerate(domains_to_process[:min(100, len(domains_to_process))]):
#                 try:
#                     domain_group = f[domain_id]
                    
#                     if len(domain_group.keys()) == 0:
#                         logger.warning(f"Domain {domain_id} has no children")
#                         continue
                        
#                     first_child_key = list(domain_group.keys())[0]
#                     residue_group = domain_group[first_child_key]
                    
#                     # Count residues to estimate domain size
#                     residue_keys = [k for k in residue_group.keys() if isinstance(k, str) and k.isdigit()]
                    
#                     # If we have residues, estimate domain size
#                     if residue_keys:
#                         sample_residue = residue_keys[0]
#                         residue_data = residue_group[sample_residue]
                        
#                         if isinstance(residue_data, h5py.Dataset):
#                             # Estimate size of single residue
#                             shape = residue_data.shape
#                             element_size = residue_data.dtype.itemsize
#                             residue_size_bytes = np.prod(shape) * element_size
                            
#                             # Estimate size of domain based on residue count
#                             domain_size_bytes = residue_size_bytes * len(residue_keys)
#                             domain_size_gb = domain_size_bytes / (1024**3)
                            
#                             domain_size_estimates.append((domain_id, domain_size_gb, len(residue_keys)))
                            
#                             if domain_idx < 5 or domain_idx % 20 == 0:
#                                 logger.debug(f"Domain {domain_id}: ~{domain_size_gb:.4f} GB, {len(residue_keys)} residues")
#                 except Exception as e:
#                     logger.warning(f"Error estimating size for domain {domain_id}: {str(e)}")
            
#             # Sort domains by size (smaller domains first)
#             if domain_size_estimates:
#                 # Sort by estimated size
#                 domain_size_estimates.sort(key=lambda x: x[1])
                
#                 # Reorder domains_to_process based on size
#                 sorted_domain_ids = [d[0] for d in domain_size_estimates]
#                 remaining_domain_ids = [d for d in domains_to_process if d not in sorted_domain_ids]
                
#                 domains_to_process = sorted_domain_ids + remaining_domain_ids
#                 logger.info(f"Prioritized domains by size. Smallest: {domain_size_estimates[0][0]} ({domain_size_estimates[0][1]:.4f} GB)")
#                 logger.info(f"Largest analyzed: {domain_size_estimates[-1][0]} ({domain_size_estimates[-1][1]:.4f} GB)")
            
#             # Calculate total estimated memory needed and adjust max domains
#             if domain_size_estimates:
#                 avg_domain_size_gb = sum(d[1] for d in domain_size_estimates) / len(domain_size_estimates)
#                 memory = psutil.virtual_memory()
#                 available_gb = memory.available / (1024**3)
#                 safe_memory_usage_gb = available_gb * 0.7  # Use up to 70% of available memory
                
#                 estimated_max_domains = int(safe_memory_usage_gb / avg_domain_size_gb)
                
#                 logger.info(f"Average domain size: {avg_domain_size_gb:.4f} GB")
#                 logger.info(f"Available memory: {available_gb:.2f} GB, safe usage: {safe_memory_usage_gb:.2f} GB")
#                 logger.info(f"Can safely process approximately {estimated_max_domains} domains")
                
#                 # Apply adaptive domain limit if needed
#                 if max_domains is None and estimated_max_domains < len(domains_to_process):
#                     max_domains = estimated_max_domains
#                     domains_to_process = domains_to_process[:max_domains]
#                     logger.warning(f"Limiting to {max_domains} domains based on memory constraints")
            
#             # Process domains with careful memory monitoring
#             logger.info(f"Processing {len(domains_to_process)} domains with memory ceiling of {memory_ceiling_percent}%")
#             domains_processed = 0
            
#             # Create progress bar only if we have domains to process
#             if len(domains_to_process) > 0:
#                 # Create progress bar
#                 progress = EnhancedProgressBar(
#                     len(domains_to_process), 
#                     prefix="Loading domains", 
#                     suffix="Complete"
#                 )
#             else:
#                 # No domains to process, log a warning
#                 logger.warning("No domains to process, skipping domain loading")
#                 return {}  # Return empty dictionary
            
#             # Iterate through domains
#             for domain_idx, domain_id in enumerate(domains_to_process):
#                 # Check memory before loading this domain
#                 memory_stats = check_memory_usage()
#                 current_memory_percent = memory_stats['system_percent']
                
#                 # If we've reached the memory ceiling, stop processing new domains
#                 if current_memory_percent >= memory_ceiling_percent:
#                     logger.warning(f"Memory ceiling ({memory_ceiling_percent}%) reached at "
#                                   f"{current_memory_percent}% after processing {domains_processed} domains")
#                     logger.info(f"Stopping domain loading to preserve memory integrity")
#                     break
                
#                 # Process one complete domain
#                 try:
#                     domain_group = f[domain_id]
                    
#                     if len(domain_group.keys()) == 0:
#                         logger.warning(f"Domain {domain_id} has no children")
#                         progress.update(domain_idx + 1)
#                         continue
                        
#                     # Get the first direct child
#                     first_child_key = list(domain_group.keys())[0]
#                     residue_group = domain_group[first_child_key]
                    
#                     # Get all residue IDs (numeric keys)
#                     residue_keys = [k for k in residue_group.keys() if isinstance(k, str) and k.isdigit()]
                    
#                     if not residue_keys:
#                         logger.warning(f"No valid residues found for domain {domain_id}")
#                         progress.update(domain_idx + 1)
#                         continue
                    
#                     # Prepare domain data dictionary or memmap-based storage
#                     if out_of_core_mode:
#                         # Memory mapped approach for out-of-core processing
#                         domain_data = {}
                        
#                         # Check if domain is expected to be large based on residue count
#                         use_memmap = len(residue_keys) > 500  # Use memmap for domains with many residues
                        
#                         # Process all residues in the domain
#                         for resid in residue_keys:
#                             try:
#                                 residue_data = residue_group[resid]
                                
#                                 if isinstance(residue_data, h5py.Dataset):
#                                     # Get shape and determine if transpose is needed
#                                     shape = residue_data.shape
#                                     voxel_data_raw = residue_data[:]
                                    
#                                     # For datasets with shape (x, y, z, channels), transpose to (channels, x, y, z)
#                                     if len(shape) == 4 and shape[3] in [4, 5]:
#                                         voxel = np.transpose(voxel_data_raw, (3, 0, 1, 2))
#                                     else:
#                                         voxel = voxel_data_raw
                                    
#                                     # Convert to float32 if needed
#                                     if voxel.dtype == bool:
#                                         voxel = voxel.astype(np.float32)
#                                     elif voxel.dtype != np.float32:
#                                         voxel = voxel.astype(np.float32)
                                    
#                                     # Store using memmap for larger domains
#                                     if use_memmap:
#                                         # Create memmap file
#                                         memmap_file = os.path.join(temp_dir, f"{domain_id}_{resid}.npy")
#                                         memmap_array = np.memmap(memmap_file, dtype=np.float32, 
#                                                                mode='w+', shape=voxel.shape)
#                                         # Copy data to memmap
#                                         memmap_array[:] = voxel[:]
#                                         memmap_array.flush()
                                        
#                                         # Store memmap in domain data
#                                         domain_data[resid] = memmap_array
#                                     else:
#                                         # Store smaller voxels directly
#                                         domain_data[resid] = voxel
                                    
#                                     # Force explicit deletion of raw data
#                                     del voxel_data_raw
                                    
#                             except Exception as e:
#                                 logger.warning(f"Error processing residue {resid} for domain {domain_id}: {str(e)}")
#                     else:
#                         # Standard in-memory approach
#                         domain_data = {}
                        
#                         # Process all residues in the domain
#                         for resid in residue_keys:
#                             try:
#                                 residue_data = residue_group[resid]
                                
#                                 if isinstance(residue_data, h5py.Dataset):
#                                     shape = residue_data.shape
#                                     voxel_data_raw = residue_data[:]
                                    
#                                     if len(shape) == 4 and shape[3] in [4, 5]:
#                                         voxel = np.transpose(voxel_data_raw, (3, 0, 1, 2))
#                                     else:
#                                         voxel = voxel_data_raw
                                    
#                                     if voxel.dtype == bool:
#                                         voxel = voxel.astype(np.float32)
#                                     elif voxel.dtype != np.float32:
#                                         voxel = voxel.astype(np.float32)
                                    
#                                     domain_data[resid] = voxel
                                    
#                                     # Force explicit deletion of raw data
#                                     del voxel_data_raw
                                    
#                             except Exception as e:
#                                 logger.warning(f"Error processing residue {resid} for domain {domain_id}: {str(e)}")
                    
#                     # Store the domain data if it has content
#                     if domain_data:
#                         voxel_data[domain_id] = domain_data
#                         domains_processed += 1
#                         logger.info(f"Loaded {len(domain_data)} residues for domain {domain_id}")
#                     else:
#                         logger.warning(f"No valid voxel data found for domain {domain_id}")
                    
#                 except Exception as e:
#                     logger.error(f"Error processing domain {domain_id}: {str(e)}")
                
#                 # Update progress bar
#                 progress.update(domain_idx + 1)
                
#                 # Force garbage collection after each domain
#                 clear_memory(force_gc=True, clear_cuda=True)
                
#                 # Check memory again after domain processing and GC
#                 memory_stats = check_memory_usage()
#                 logger.debug(f"Memory after domain {domain_id}: {memory_stats['system_percent']}% "
#                             f"({memory_stats['process_rss_gb']:.2f} GB)")
            
#             # End progress bar
#             if 'progress' in locals():
#                 progress.finish()
            
#             # Report final processing statistics
#             total_domains = len(domains_to_process)
#             memory_stats = check_memory_usage()
#             current_memory_percent = memory_stats['system_percent']
            
#             logger.info(f"Domain loading complete: {domains_processed}/{total_domains} domains processed")
#             logger.info(f"Current memory usage: {current_memory_percent:.1f}% "
#                        f"({memory_stats['process_rss_gb']:.2f} GB)")
            
#             if domains_processed < total_domains:
#                 logger.warning(f"{total_domains - domains_processed} domains were not processed "
#                               f"due to memory constraints")
#                 logger.warning(f"The model will be trained on {domains_processed} domains only")
        
#         if not voxel_data:
#             logger.error("No valid voxel data was loaded")
#             raise ValueError("No valid voxel data was loaded. Check the logs for details.")
        
#         # Validate the loaded voxel data
#         logger.info("Validating voxel data...")
#         voxel_data = validate_voxel_data(voxel_data)
        
#         return voxel_data

def load_rmsf_data(
    rmsf_dir: str,
    replica: str = "replica_average",
    temperature: Union[int, str] = 320
) -> pd.DataFrame:
    """
    Load RMSF data from CSV file.
    
    Args:
        rmsf_dir: Base directory for RMSF data
        replica: Replica folder name (default: "replica_average")
        temperature: Temperature value (default: 320)
        
    Returns:
        DataFrame containing RMSF data
    """
    rmsf_dir = resolve_path(rmsf_dir)
    logger.info(f"Loading RMSF data from {rmsf_dir}, replica={replica}, temperature={temperature}")
    
    # Construct the path to the RMSF CSV file
    if isinstance(temperature, int):
        temperature_str = str(temperature)
    else:
        temperature_str = temperature
    
    rmsf_file = os.path.join(
        rmsf_dir, 
        replica, 
        temperature_str,
        f"rmsf_{replica}_temperature{temperature_str}.csv"
    )
    
    if not os.path.exists(rmsf_file):
        raise FileNotFoundError(f"RMSF file not found: {rmsf_file}")
    
    # Load the CSV file
    rmsf_data = pd.read_csv(rmsf_file)
    
    # Validate the RMSF data
    rmsf_data = validate_rmsf_data(rmsf_data)
    
    logger.info(f"Loaded RMSF data with {len(rmsf_data)} entries")
    return rmsf_data


def create_domain_mapping(
    voxel_domains: List[str],
    rmsf_domains: List[str]
) -> Dict[str, str]:
    """
    Create mapping between voxel domain IDs and RMSF domain IDs with improved performance.
    
    Args:
        voxel_domains: List of domain IDs from voxel data
        rmsf_domains: List of domain IDs from RMSF data
        
    Returns:
        Dictionary mapping voxel domain IDs to RMSF domain IDs
    """
    logger.info("Creating optimized domain mapping")
    
    # OPTIMIZATION: Convert to sets for O(1) lookups
    voxel_domains_set = set(voxel_domains)
    rmsf_domains_set = set(rmsf_domains)
    
    # Extract base names for all domains upfront
    voxel_base_names = {d: d.split('_')[0] for d in voxel_domains}
    rmsf_base_names = {d: d.split('_')[0] for d in rmsf_domains}
    
    # Create reverse lookup (base name to full domain names)
    rmsf_base_to_full = {}
    for full_domain, base_name in rmsf_base_names.items():
        if base_name not in rmsf_base_to_full:
            rmsf_base_to_full[base_name] = []
        rmsf_base_to_full[base_name].append(full_domain)
    
    # Track suffix statistics
    suffix_counts = {}
    
    # Create mapping dictionary with optimal algorithm
    mapping = {}
    direct_matches = 0
    base_matches = 0
    fuzzy_matches = 0
    
    # First, try direct matches (fastest)
    for voxel_domain in voxel_domains:
        if voxel_domain in rmsf_domains_set:
            mapping[voxel_domain] = voxel_domain
            direct_matches += 1
        else:
            # Track suffix for diagnostics
            if "_" in voxel_domain:
                suffix = voxel_domain.split("_", 1)[1]
                suffix_counts[suffix] = suffix_counts.get(suffix, 0) + 1
    
    # Next, try base name matches for unmatched domains
    for voxel_domain in voxel_domains:
        if voxel_domain not in mapping:
            base_domain = voxel_base_names[voxel_domain]
            
            # Check if base name is a direct match with any RMSF domain
            if base_domain in rmsf_domains_set:
                mapping[voxel_domain] = base_domain
                base_matches += 1
            # Check if base name matches any RMSF domain's base name
            elif base_domain in rmsf_base_to_full:
                # Use the first RMSF domain with this base name
                mapping[voxel_domain] = rmsf_base_to_full[base_domain][0]
                base_matches += 1
    
    # Finally, try fuzzy matching for any remaining unmatched domains
    for voxel_domain in voxel_domains:
        if voxel_domain not in mapping:
            base_domain = voxel_base_names[voxel_domain]
            
            # Try to find any partial match
            for rmsf_domain in rmsf_domains:
                if rmsf_domain.startswith(base_domain) or base_domain.startswith(rmsf_domain):
                    mapping[voxel_domain] = rmsf_domain
                    fuzzy_matches += 1
                    break
    
    # Report mapping statistics
    total_mapped = len(mapping)
    mapping_percentage = (total_mapped / len(voxel_domains)) * 100 if voxel_domains else 0
    
    logger.info(f"Created mapping for {total_mapped} domains out of {len(voxel_domains)} "
                f"({mapping_percentage:.1f}%)")
    logger.info(f"Direct matches: {direct_matches}, Base matches: {base_matches}, Fuzzy matches: {fuzzy_matches}")
    
    # Log suffix statistics
    if suffix_counts:
        # Get top 5 most common suffixes
        top_suffixes = sorted(suffix_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        suffix_info = ", ".join([f"{suffix}: {count}" for suffix, count in top_suffixes])
        logger.info(f"Domain suffix statistics (top 5): {suffix_info}")
        
        # Get total count by suffix type
        total_with_suffix = sum(suffix_counts.values())
        suffix_percentage = 100.0 * total_with_suffix / len(voxel_domains)
        logger.info(f"Domains with suffixes: {total_with_suffix} ({suffix_percentage:.1f}%)")
    
    # If no mappings were created, provide more detailed information
    if not mapping:
        logger.error("No domain mappings could be created!")
        logger.error("This could be due to naming inconsistencies between voxel and RMSF data")
        logger.error(f"Sample voxel domains: {voxel_domains[:5]}")
        logger.error(f"Sample RMSF domains: {rmsf_domains[:5]}")
        
        # Try more permissive matching as a fallback
        logger.info("Attempting more permissive matching as fallback...")
        for voxel_domain in voxel_domains:
            clean_voxel = voxel_domain.split('_')[0]
            # Try to find any RMSF domain that starts with the same characters
            for rmsf_domain in rmsf_domains:
                if rmsf_domain.startswith(clean_voxel) or clean_voxel.startswith(rmsf_domain):
                    mapping[voxel_domain] = rmsf_domain
                    logger.debug(f"Fallback mapping: {voxel_domain} -> {rmsf_domain}")
                    break
        
        if mapping:
            logger.info(f"Created {len(mapping)} fallback mappings")
    
    return mapping

def prepare_dataloaders(
    voxel_data: Dict[str, Dict[str, np.ndarray]],
    rmsf_data: pd.DataFrame,
    batch_size: int = 32,
    train_split: float = 0.7,
    val_split: float = 0.15,
    test_split: float = 0.15,
    num_workers: int = 4,
    seed: int = 42,
    safe_mode: bool = False,
    memory_efficient: bool = True
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """
    Prepare PyTorch DataLoaders with aggressive memory management.
    
    Args:
        voxel_data: Dictionary mapping domain IDs to voxel data
        rmsf_data: DataFrame containing RMSF values
        batch_size: Batch size for DataLoaders
        train_split: Proportion of data for training
        val_split: Proportion of data for validation
        test_split: Proportion of data for testing
        num_workers: Number of worker processes for DataLoaders
        seed: Random seed for reproducibility
        safe_mode: If True, use single-threaded mode (no workers)
        memory_efficient: If True, use memory-efficient dataset mode
        
    Returns:
        Tuple of (train_loader, val_loader, test_loader)
    """
    logger.info("Preparing DataLoaders")
    
    # Check memory before dataset creation
    memory_stats = check_memory_usage()
    logger.info(f"Memory before dataloader creation: {memory_stats['system_percent']}% used")
    
    # Force safe mode in extremely high memory situations
    if memory_stats['system_percent'] > 90:
        logger.warning(f"Critical memory state detected: {memory_stats['system_percent']}%. Forcing safe mode.")
        safe_mode = True
        
    # Adjust workers based on memory conditions
    if not safe_mode:
        # Use more aggressive worker reduction with thresholds
        if memory_stats['system_percent'] > 85:
            num_workers = 0  # Force single-threaded mode in high memory usage
            logger.warning(f"High memory usage ({memory_stats['system_percent']}%). Forcing single-threaded mode.")
        elif memory_stats['system_percent'] > 75:
            num_workers = 1  # Use just one worker
            logger.warning(f"Elevated memory usage ({memory_stats['system_percent']}%). Using 1 worker only.")
        else:
            adjusted_workers = min(2, multiprocessing.cpu_count() // 4)  # Much more conservative
            if adjusted_workers != num_workers:
                logger.warning(f"Reducing workers from {num_workers} to {adjusted_workers} to conserve memory")
                num_workers = adjusted_workers
    
    # Force single-threaded mode if safe_mode is enabled
    if safe_mode:
        old_workers = num_workers
        num_workers = 0
        logger.info(f"Safe mode enabled: Setting workers from {old_workers} to {num_workers}")
    
    # Clear memory before dataset creation
    clear_memory(force_gc=True, clear_cuda=True)
    
    # Create domain mapping
    voxel_domains = list(voxel_data.keys())
    rmsf_domains = rmsf_data['domain_id'].unique().tolist()
    domain_mapping = create_domain_mapping(voxel_domains, rmsf_domains)
    
    # Validate the mapping
    validate_domain_residue_mapping(voxel_data, rmsf_data, domain_mapping)
    
    # Adjust batch size aggressively based on memory
    input_shape = None
    for domain_id, domain_data in voxel_data.items():
        for resid, voxel in domain_data.items():
            input_shape = voxel.shape
            break
        if input_shape is not None:
            break
    
    if input_shape is not None:
        # Calculate element_size
        element_size = 4  # float32 = 4 bytes
        single_input_bytes = np.prod(input_shape) * element_size
        
        # Calculate target memory usage (much more conservative)
        memory_stats = check_memory_usage()
        available_memory_bytes = memory_stats['system_available_gb'] * (1024**3)
        
        # Target a smaller percentage of available memory (20-40% depending on memory pressure)
        memory_target_percentage = 0.2 if memory_stats['system_percent'] > 85 else 0.4
        target_memory_bytes = available_memory_bytes * memory_target_percentage
        
        # Account for PyTorch overhead - assume 3x memory usage
        pytorch_overhead = 3.0
        # Increase overhead estimation in high memory conditions
        if memory_stats['system_percent'] > 80:
            pytorch_overhead = 4.0
        
        # Calculate safe batch size
        safe_batch_size = max(1, int(target_memory_bytes / (single_input_bytes * pytorch_overhead)))
        
        # Cap batch size to a reasonable maximum to avoid memory spikes
        max_safe_batch = 16 if memory_stats['system_percent'] < 80 else 8
        safe_batch_size = min(safe_batch_size, max_safe_batch)
        
        # If memory is critical, use an extremely small batch size
        if memory_stats['system_percent'] > 90:
            safe_batch_size = 1
        
        # Apply the calculated safe batch size
        if safe_batch_size < batch_size:
            logger.warning(f"Reducing batch size from {batch_size} to {safe_batch_size} based on memory constraints")
            batch_size = safe_batch_size
    
    # Create dataset with memory-efficient mode
    try:
        logger.info("Creating RMSFDataset - this may take several minutes for large datasets")
        
        # Force memory clearing before dataset creation
        clear_memory(force_gc=True, clear_cuda=True)
        
        with log_stage("DATASET_CREATION", "Creating PyTorch dataset"):
            dataset = RMSFDataset(
                voxel_data, 
                rmsf_data, 
                domain_mapping, 
                memory_efficient=True  # Always use memory-efficient mode
            )
    except Exception as e:
        logger.error(f"Error creating dataset: {str(e)}", exc_info=True)
        raise
    
    # Explicit memory clearing after dataset creation
    clear_memory(force_gc=True, clear_cuda=True)
    
    # Split the dataset with careful memory management
    try:
        dataset_size = len(dataset)
        indices = list(range(dataset_size))
        
        # Set a fixed seed for reproducibility
        np.random.seed(seed)
        np.random.shuffle(indices)
        
        train_end = int(train_split * dataset_size)
        val_end = train_end + int(val_split * dataset_size)
        
        train_indices = indices[:train_end]
        val_indices = indices[train_end:val_end]
        test_indices = indices[val_end:]
        
        logger.info(f"Split dataset into {len(train_indices)} training, "
                    f"{len(val_indices)} validation, and {len(test_indices)} test samples")
        
        # Force GC after creating large index lists
        del indices
        clear_memory(force_gc=True, clear_cuda=False)
    except Exception as e:
        logger.error(f"Error splitting dataset: {str(e)}", exc_info=True)
        raise
    
    # Configure DataLoader settings for extreme memory efficiency
    pin_memory = False  # Disable pin_memory in all cases to reduce memory usage
    persistent_workers = False  # Disable persistent workers to reduce memory usage
    prefetch_factor = 2  # Use minimum prefetch factor
    
    # Create DataLoaders with simplified configuration for memory efficiency
    try:
        logger.info(f"Creating DataLoaders with {num_workers} workers, minimal memory settings")
        
        # Start with most conservative settings for all loaders
        dataloader_kwargs = {
            'batch_size': batch_size,
            'num_workers': num_workers,
            'pin_memory': False,
            'persistent_workers': False,
            'prefetch_factor': 2 if num_workers > 0 else None
        }
        
        # Create train loader with fallback
        try:
            train_loader = DataLoader(
                dataset, 
                sampler=torch.utils.data.SubsetRandomSampler(train_indices),
                **dataloader_kwargs
            )
        except Exception as e:
            logger.error(f"Error creating train loader: {str(e)}. Falling back to minimal configuration.")
            train_loader = DataLoader(
                dataset, 
                batch_size=1,  # Minimal batch size for extreme cases
                sampler=torch.utils.data.SubsetRandomSampler(train_indices),
                num_workers=0
            )
        
        # Force memory clearing between loader creation
        clear_memory(force_gc=True, clear_cuda=True)
        
        # Create validation loader with fallback
        try:
            val_loader = DataLoader(
                dataset,
                sampler=torch.utils.data.SubsetRandomSampler(val_indices),
                **dataloader_kwargs
            )
        except Exception as e:
            logger.error(f"Error creating validation loader: {str(e)}. Falling back to minimal configuration.")
            val_loader = DataLoader(
                dataset,
                batch_size=1,
                sampler=torch.utils.data.SubsetRandomSampler(val_indices),
                num_workers=0
            )
        
        # Force memory clearing between loader creation
        clear_memory(force_gc=True, clear_cuda=True)
        
        # Create test loader with fallback
        try:
            test_loader = DataLoader(
                dataset,
                sampler=torch.utils.data.SubsetRandomSampler(test_indices),
                **dataloader_kwargs
            )
        except Exception as e:
            logger.error(f"Error creating test loader: {str(e)}. Falling back to minimal configuration.")
            test_loader = DataLoader(
                dataset,
                batch_size=1,
                sampler=torch.utils.data.SubsetRandomSampler(test_indices),
                num_workers=0
            )
        
        # Verify loaders work by testing a single batch from test loader
        try:
            logger.info("Testing DataLoader initialization by accessing first batch...")
            # Get first batch with timeout protection
            import time
            start_time = time.time()
            timeout = 120  # 2 minutes timeout
            
            for i, (inputs, targets) in enumerate(test_loader):
                logger.info(f"Successfully loaded first batch with {len(inputs)} items")
                break
                
                if time.time() - start_time > timeout:
                    logger.warning("Timeout waiting for first batch. Loader may be stuck.")
                    # Force break and try recovery
                    break
            
            logger.info("DataLoaders created and validated successfully")
        except Exception as e:
            logger.error(f"Error accessing first batch: {str(e)}")
            
            # Final fallback to absolute minimal configuration
            logger.warning("Falling back to absolute minimal DataLoader settings")
            test_loader = DataLoader(
                dataset, 
                batch_size=1,
                sampler=torch.utils.data.SubsetRandomSampler(test_indices[:100]),  # Sample only 100 items
                num_workers=0,
                pin_memory=False
            )
            
            # Try again with even smaller subset if needed
            try:
                next(iter(test_loader))
                logger.info("Successfully tested loader with minimal settings")
            except:
                logger.critical("Failed to create working dataloader even with minimal settings!")
        
        # Final memory clearing
        clear_memory(force_gc=True, clear_cuda=True)
        
        return train_loader, val_loader, test_loader
    except Exception as e:
        logger.error(f"Error creating DataLoaders: {str(e)}", exc_info=True)
        raise
    
def create_optimized_rmsf_lookup(rmsf_data: pd.DataFrame) -> Dict[Tuple[str, int], float]:
    """
    Create an optimized RMSF lookup dictionary that can be reused across dataset instances.
    
    Args:
        rmsf_data: DataFrame containing RMSF values
        
    Returns:
        Dictionary mapping (domain_id, resid) to RMSF values
    """
    logger.info("Creating global optimized RMSF lookup")
    start_time = time.time()
    
    # Extract columns as numpy arrays for fastest processing
    domains = rmsf_data['domain_id'].values
    resids = rmsf_data['resid'].values
    rmsfs = rmsf_data['average_rmsf'].values
    
    # Pre-allocate dictionary with size hint
    rmsf_lookup = {}
    
    # Process in a single pass for better performance
    for i in range(len(domains)):
        try:
            resid_int = int(resids[i])
            rmsf_lookup[(domains[i], resid_int)] = rmsfs[i]
        except (ValueError, TypeError):
            continue
    
    # Also create base domain lookups
    base_lookup = {}
    for domain in set(domains):
        base_domain = domain.split('_')[0] if '_' in domain else domain
        if base_domain not in base_lookup:
            base_lookup[base_domain] = {}
    
    # Fill in base domain lookup
    for (domain, resid), rmsf in rmsf_lookup.items():
        base_domain = domain.split('_')[0] if '_' in domain else domain
        base_lookup[base_domain][resid] = rmsf
    
    # Add base domain lookups to main lookup
    for base_domain, residues in base_lookup.items():
        for resid, rmsf in residues.items():
            if (base_domain, resid) not in rmsf_lookup:
                rmsf_lookup[(base_domain, resid)] = rmsf
    
    lookup_time = time.time() - start_time
    logger.info(f"Created global RMSF lookup with {len(rmsf_lookup)} entries in {lookup_time:.2f} seconds")
    
    return rmsf_lookup

def load_domain_batch(domain_indices, domain_list, config):
    """
    Load a batch of domains with optimized memory usage.
    
    Args:
        domain_indices: List of domain indices to load
        domain_list: List of all domain IDs
        config: Configuration dictionary
        
    Returns:
        Dictionary of loaded domain data
    """
    domain_batch = [domain_list[i] for i in domain_indices]
    logger.info(f"Loading domain batch with {len(domain_batch)} domains")
    
    # Load domains with a more efficient approach
    voxel_data = {}
    
    # Use larger read buffers for better I/O performance
    read_buffer_size = 1024 * 1024 * 8  # 8MB buffer size
    
    with h5py.File(config["input"]["voxel_file"], 'r', rdcc_nbytes=read_buffer_size) as f:
        for domain_id in domain_batch:
            try:
                domain_group = f[domain_id]
                first_child_key = list(domain_group.keys())[0]
                residue_group = domain_group[first_child_key]
                residue_keys = [k for k in residue_group.keys() if isinstance(k, str) and k.isdigit()]
                
                if not residue_keys:
                    logger.warning(f"No valid residues found for domain {domain_id}")
                    continue
                
                # Process all residues in the domain
                domain_data = {}
                
                # Pre-allocate dictionary with estimated size
                # This avoids dictionary resizing during insertion
                domain_data = {}
                
                # Process residues in larger chunks for better I/O
                chunk_size = 50
                for i in range(0, len(residue_keys), chunk_size):
                    chunk = residue_keys[i:i+chunk_size]
                    for resid in chunk:
                        try:
                            residue_data = residue_group[resid]
                            
                            if isinstance(residue_data, h5py.Dataset):
                                # Get shape and determine if transpose is needed
                                shape = residue_data.shape
                                voxel_data_raw = residue_data[:]
                                
                                # For datasets with shape (x, y, z, channels), transpose to (channels, x, y, z)
                                if len(shape) == 4 and shape[3] in [4, 5]:
                                    voxel = np.transpose(voxel_data_raw, (3, 0, 1, 2))
                                else:
                                    voxel = voxel_data_raw
                                
                                # Convert to float32 if needed
                                if voxel.dtype == bool:
                                    voxel = voxel.astype(np.float32)
                                elif voxel.dtype != np.float32:
                                    voxel = voxel.astype(np.float32)
                                
                                domain_data[resid] = voxel
                                
                                # Force explicit deletion of raw data
                                del voxel_data_raw
                                
                        except Exception as e:
                            logger.debug(f"Error processing residue {resid} for domain {domain_id}: {str(e)}")
                
                # Store the domain data if it has content
                if domain_data:
                    voxel_data[domain_id] = domain_data
                else:
                    logger.warning(f"No valid voxel data found for domain {domain_id}")
                
            except Exception as e:
                logger.error(f"Error processing domain {domain_id}: {str(e)}")
    
    return voxel_data
===== FILE: src/voxelflex/data/__init__.py =====
# In src/voxelflex/data/__init__.py
from voxelflex.data.data_loader import load_voxel_data, load_rmsf_data, prepare_dataloaders, RMSFDataset
from voxelflex.data.validators import validate_voxel_data, validate_rmsf_data, validate_domain_residue_mapping
===== FILE: src/voxelflex/models/cnn_models.py =====
"""
CNN models for Voxelflex.

This module contains PyTorch 3D CNN architectures for RMSF prediction.
"""

from typing import List, Tuple, Dict, Any, Optional, Union

import torch
import torch.nn as nn
import torch.nn.functional as F

from voxelflex.utils.logging_utils import get_logger

logger = get_logger(__name__)

class ResidualBlock3D(nn.Module):
    """3D Residual block with dilated convolutions."""
    
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        dilation: int = 1,
        dropout_rate: float = 0.3
    ):
        """
        Initialize a 3D residual block.
        
        Args:
            in_channels: Number of input channels
            out_channels: Number of output channels
            dilation: Dilation rate for convolution
            dropout_rate: Dropout rate
        """
        super().__init__()
        
        self.conv1 = nn.Conv3d(
            in_channels, out_channels, kernel_size=3, 
            padding=dilation, dilation=dilation, bias=False
        )
        self.bn1 = nn.BatchNorm3d(out_channels)
        self.conv2 = nn.Conv3d(
            out_channels, out_channels, kernel_size=3, 
            padding=dilation, dilation=dilation, bias=False
        )
        self.bn2 = nn.BatchNorm3d(out_channels)
        self.dropout = nn.Dropout3d(dropout_rate)
        
        # Skip connection
        self.skip = nn.Sequential()
        if in_channels != out_channels:
            self.skip = nn.Sequential(
                nn.Conv3d(in_channels, out_channels, kernel_size=1, bias=False),
                nn.BatchNorm3d(out_channels)
            )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward pass through the residual block."""
        residual = self.skip(x)
        
        out = self.conv1(x)
        out = self.bn1(out)
        out = F.relu(out)
        
        out = self.conv2(out)
        out = self.bn2(out)
        
        out = out + residual
        out = F.relu(out)
        out = self.dropout(out)
        
        return out


class VoxelFlexCNN(nn.Module):
    """
    Basic 3D CNN architecture for RMSF prediction.
    
    This model uses a series of 3D convolutional layers followed by fully connected
    layers to predict RMSF values from voxelized protein data.
    """
    
    def __init__(
        self,
        input_channels: int = 5,
        base_filters: int = 32,
        channel_growth_rate: float = 1.5,
        dropout_rate: float = 0.3
    ):
        """
        Initialize VoxelFlexCNN.
        
        Args:
            input_channels: Number of input channels (typically 4 or 5)
            base_filters: Number of filters in the first convolutional layer
            channel_growth_rate: Growth rate for channels in successive layers
            dropout_rate: Dropout rate
        """
        super().__init__()
        
        # Calculate channel sizes for each layer
        c1 = base_filters
        c2 = int(c1 * channel_growth_rate)
        c3 = int(c2 * channel_growth_rate)
        c4 = int(c3 * channel_growth_rate)
        
        # Convolutional layers
        self.conv1 = nn.Conv3d(input_channels, c1, kernel_size=3, padding=1)
        self.conv2 = nn.Conv3d(c1, c2, kernel_size=3, padding=1)
        self.conv3 = nn.Conv3d(c2, c3, kernel_size=3, padding=1)
        self.conv4 = nn.Conv3d(c3, c4, kernel_size=3, padding=1)
        
        # Batch normalization layers
        self.bn1 = nn.BatchNorm3d(c1)
        self.bn2 = nn.BatchNorm3d(c2)
        self.bn3 = nn.BatchNorm3d(c3)
        self.bn4 = nn.BatchNorm3d(c4)
        
        # Dropout
        self.dropout = nn.Dropout3d(dropout_rate)
        
        # Global average pooling
        self.global_avg_pool = nn.AdaptiveAvgPool3d(1)
        
        # Fully connected layers
        self.fc1 = nn.Linear(c4, 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        
        # Initialize weights
        self._initialize_weights()
    
    def _initialize_weights(self):
        """Initialize model weights."""
        for m in self.modules():
            if isinstance(m, nn.Conv3d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm3d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward pass through the network."""
        # Convolutional layers
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.max_pool3d(x, 2)
        
        x = F.relu(self.bn2(self.conv2(x)))
        x = F.max_pool3d(x, 2)
        
        x = F.relu(self.bn3(self.conv3(x)))
        x = self.dropout(x)
        
        x = F.relu(self.bn4(self.conv4(x)))
        
        # Global average pooling
        x = self.global_avg_pool(x)
        x = x.view(x.size(0), -1)
        
        # Fully connected layers
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        
        return x.squeeze(1)


class DilatedResNet3D(nn.Module):
    """
    Dilated ResNet 3D architecture for RMSF prediction.
    
    This model uses residual blocks with dilated convolutions for better
    capturing multi-scale features in voxelized protein data.
    """
    
    def __init__(
        self,
        input_channels: int = 5,
        base_filters: int = 32,
        channel_growth_rate: float = 1.5,
        num_residual_blocks: int = 4,
        dropout_rate: float = 0.3
    ):
        """
        Initialize DilatedResNet3D.
        
        Args:
            input_channels: Number of input channels (typically 4 or 5)
            base_filters: Number of filters in the first convolutional layer
            channel_growth_rate: Growth rate for channels in successive layers
            num_residual_blocks: Number of residual blocks
            dropout_rate: Dropout rate
        """
        super().__init__()
        
        # Initial convolution
        self.conv1 = nn.Conv3d(input_channels, base_filters, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm3d(base_filters)
        
        # Calculate channel sizes for each layer
        channels = [base_filters]
        for i in range(num_residual_blocks):
            channels.append(int(channels[-1] * channel_growth_rate))
        
        # Residual blocks with increasing dilation
        self.res_blocks = nn.ModuleList()
        for i in range(num_residual_blocks):
            dilation = 2 ** (i % 3)  # Dilations: 1, 2, 4, 1, 2, 4, ...
            block = ResidualBlock3D(
                channels[i], channels[i+1], dilation=dilation, dropout_rate=dropout_rate
            )
            self.res_blocks.append(block)
        
        # Global average pooling
        self.global_avg_pool = nn.AdaptiveAvgPool3d(1)
        
        # Fully connected layers
        self.fc1 = nn.Linear(channels[-1], 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        
        # Initialize weights
        self._initialize_weights()
    
    def _initialize_weights(self):
        """Initialize model weights."""
        for m in self.modules():
            if isinstance(m, nn.Conv3d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm3d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward pass through the network."""
        # Initial convolution
        x = self.conv1(x)
        x = self.bn1(x)
        x = F.relu(x)
        x = F.max_pool3d(x, kernel_size=3, stride=2, padding=1)
        
        # Residual blocks
        for block in self.res_blocks:
            x = block(x)
        
        # Global average pooling
        x = self.global_avg_pool(x)
        x = x.view(x.size(0), -1)
        
        # Fully connected layers
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        
        return x.squeeze(1)


class MultipathRMSFNet(nn.Module):
    """
    Multi-path 3D CNN architecture for RMSF prediction.
    
    This model uses multiple parallel paths with different kernel sizes
    to capture features at different scales.
    """
    
    def __init__(
        self,
        input_channels: int = 5,
        base_filters: int = 32,
        channel_growth_rate: float = 1.5,
        num_residual_blocks: int = 3,
        dropout_rate: float = 0.3
    ):
        """
        Initialize MultipathRMSFNet.
        
        Args:
            input_channels: Number of input channels (typically 4 or 5)
            base_filters: Number of filters in the first convolutional layer
            channel_growth_rate: Growth rate for channels in successive layers
            num_residual_blocks: Number of residual blocks in each path
            dropout_rate: Dropout rate
        """
        super().__init__()
        
        # Calculate channel sizes
        c1 = base_filters
        c2 = int(c1 * channel_growth_rate)
        c3 = int(c2 * channel_growth_rate)
        
        # Initial convolution
        self.conv1 = nn.Conv3d(input_channels, c1, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm3d(c1)
        
        # Multi-path branches with different kernel sizes
        self.path1 = self._create_path(c1, c2, kernel_size=3, blocks=num_residual_blocks, dropout_rate=dropout_rate)
        self.path2 = self._create_path(c1, c2, kernel_size=5, blocks=num_residual_blocks, dropout_rate=dropout_rate)
        self.path3 = self._create_path(c1, c2, kernel_size=7, blocks=num_residual_blocks, dropout_rate=dropout_rate)
        
        # Fusion layer
        self.fusion = nn.Conv3d(c2 * 3, c3, kernel_size=1, bias=False)
        self.fusion_bn = nn.BatchNorm3d(c3)
        
        # Global average pooling
        self.global_avg_pool = nn.AdaptiveAvgPool3d(1)
        
        # Fully connected layers
        self.fc1 = nn.Linear(c3, 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        
        # Dropout
        self.dropout = nn.Dropout(dropout_rate)
        
        # Initialize weights
        self._initialize_weights()
    
    def _create_path(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: int,
        blocks: int,
        dropout_rate: float
    ) -> nn.Sequential:
        """
        Create a path with multiple convolutional blocks.
        
        Args:
            in_channels: Number of input channels
            out_channels: Number of output channels
            kernel_size: Kernel size for convolutions
            blocks: Number of blocks
            dropout_rate: Dropout rate
            
        Returns:
            Sequential container of blocks
        """
        layers = []
        
        # First block
        padding = kernel_size // 2
        layers.append(nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=False))
        layers.append(nn.BatchNorm3d(out_channels))
        layers.append(nn.ReLU(inplace=True))
        layers.append(nn.MaxPool3d(kernel_size=2, stride=2))
        
        # Additional blocks
        for _ in range(blocks - 1):
            layers.append(nn.Conv3d(out_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=False))
            layers.append(nn.BatchNorm3d(out_channels))
            layers.append(nn.ReLU(inplace=True))
            layers.append(nn.Dropout3d(dropout_rate))
        
        return nn.Sequential(*layers)
    
    def _initialize_weights(self):
        """Initialize model weights."""
        for m in self.modules():
            if isinstance(m, nn.Conv3d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm3d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward pass through the network."""
        # Initial convolution
        x = self.conv1(x)
        x = self.bn1(x)
        x = F.relu(x)
        x = F.max_pool3d(x, kernel_size=3, stride=2, padding=1)
        
        # Multi-path processing
        out1 = self.path1(x)
        out2 = self.path2(x)
        out3 = self.path3(x)
        
        # Concatenate outputs
        out = torch.cat([out1, out2, out3], dim=1)
        
        # Fusion
        out = self.fusion(out)
        out = self.fusion_bn(out)
        out = F.relu(out)
        
        # Global average pooling
        out = self.global_avg_pool(out)
        out = out.view(out.size(0), -1)
        
        # Fully connected layers
        out = F.relu(self.fc1(out))
        out = self.dropout(out)
        out = F.relu(self.fc2(out))
        out = self.fc3(out)
        
        return out.squeeze(1)


def get_model(
    architecture: str,
    input_channels: int = 5,
    base_filters: int = 32,
    channel_growth_rate: float = 1.5,
    num_residual_blocks: int = 4,
    dropout_rate: float = 0.3
) -> nn.Module:
    """
    Get a model based on the specified architecture.
    
    Args:
        architecture: Model architecture name
        input_channels: Number of input channels
        base_filters: Base number of filters
        channel_growth_rate: Channel growth rate
        num_residual_blocks: Number of residual blocks
        dropout_rate: Dropout rate
        
    Returns:
        PyTorch model
    """
    if architecture == "voxelflex_cnn":
        return VoxelFlexCNN(
            input_channels=input_channels,
            base_filters=base_filters,
            channel_growth_rate=channel_growth_rate,
            dropout_rate=dropout_rate
        )
    elif architecture == "dilated_resnet3d":
        return DilatedResNet3D(
            input_channels=input_channels,
            base_filters=base_filters,
            channel_growth_rate=channel_growth_rate,
            num_residual_blocks=num_residual_blocks,
            dropout_rate=dropout_rate
        )
    elif architecture == "multipath_rmsf_net":
        return MultipathRMSFNet(
            input_channels=input_channels,
            base_filters=base_filters,
            channel_growth_rate=channel_growth_rate,
            num_residual_blocks=num_residual_blocks,
            dropout_rate=dropout_rate
        )
    else:
        raise ValueError(f"Unknown architecture: {architecture}")
===== FILE: src/voxelflex/models/__init__.py =====
# In src/voxelflex/models/__init__.py
from voxelflex.models.cnn_models import get_model, VoxelFlexCNN, DilatedResNet3D, MultipathRMSFNet
===== FILE: src/voxelflex/utils/system_utils.py =====
"""
Enhanced system utility functions with memory management for Voxelflex.

This module provides improved memory monitoring and resource allocation.
"""

import os
import platform
import multiprocessing
import gc
import psutil
from typing import Dict, Any, Tuple, Optional

import torch
import numpy as np

from voxelflex.utils.logging_utils import get_logger

logger = get_logger(__name__)

# Memory thresholds (percentage of system memory)
MEMORY_WARNING_THRESHOLD = 0.70  
MEMORY_CRITICAL_THRESHOLD = 0.80 
MEMORY_EMERGENCY_THRESHOLD = 0.90  


def get_device(adjust_for_gpu: bool = True) -> torch.device:
    if adjust_for_gpu and torch.cuda.is_available():
        try:
            # Explicitly set device
            torch.cuda.set_device(0)
            
            # Verify GPU setup
            test_tensor = torch.tensor([1.0], device='cuda')
            
            # Detailed logging
            logger.info(f"GPU Selected: {torch.cuda.get_device_name(0)}")
            logger.info(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB")
            
            return torch.device('cuda')
        except Exception as e:
            logger.error(f"GPU Setup Failed: {e}")
    
    return torch.device('cpu')

def check_system_resources(detect_cores: bool = True, 
                           adjust_for_gpu: bool = True) -> Dict[str, Any]:
    """
    Check available system resources with enhanced memory reporting.
    
    Args:
        detect_cores: Whether to detect available CPU cores
        adjust_for_gpu: Whether to check for GPU availability
        
    Returns:
        Dictionary containing system resource information
    """
    system_info = {
        "platform": platform.platform(),
        "python_version": platform.python_version(),
        "torch_version": torch.__version__,
    }
    
    # Check memory resources - ADD THIS SECTION
    memory = psutil.virtual_memory()
    system_info["memory_total_gb"] = memory.total / (1024**3)
    system_info["memory_available_gb"] = memory.available / (1024**3)
    system_info["memory_percent_used"] = memory.percent
    
    # Add memory thresholds
    system_info["memory_warning_threshold"] = MEMORY_WARNING_THRESHOLD * 100
    system_info["memory_critical_threshold"] = MEMORY_CRITICAL_THRESHOLD * 100
    system_info["memory_emergency_threshold"] = MEMORY_EMERGENCY_THRESHOLD * 100
    
    # Check CPU resources
    if detect_cores:
        cpu_count = multiprocessing.cpu_count()
        system_info["cpu_count"] = cpu_count
        
        # # Reduce worker recommendation to be more conservative
        # system_info["recommended_workers"] = max(1, min(4, cpu_count // 2))
        # More aggressive worker allocation
        system_info["recommended_workers"] = min(32, cpu_count - 4)  # Leave 2 cores free, max 32
    
    # Check GPU resources
    if adjust_for_gpu:
        system_info["cuda_available"] = torch.cuda.is_available()
        if torch.cuda.is_available():
            system_info["cuda_device_count"] = torch.cuda.device_count()
            system_info["cuda_device_name"] = torch.cuda.get_device_name(0)
            system_info["cuda_version"] = torch.version.cuda
            
            # Add GPU memory info
            try:
                gpu_id = 0
                gpu_properties = torch.cuda.get_device_properties(gpu_id)
                total_memory_gb = gpu_properties.total_memory / (1024**3)  # Convert to GB
                allocated_memory_gb = torch.cuda.memory_allocated(gpu_id) / (1024**3)
                reserved_memory_gb = torch.cuda.memory_reserved(gpu_id) / (1024**3)
                
                system_info["gpu_total_memory_gb"] = total_memory_gb
                system_info["gpu_allocated_memory_gb"] = allocated_memory_gb
                system_info["gpu_reserved_memory_gb"] = reserved_memory_gb
                system_info["gpu_available_memory_gb"] = total_memory_gb - allocated_memory_gb
            except Exception as e:
                logger.warning(f"Error getting GPU memory info: {str(e)}")
    
    # Log enhanced system information
    logger.info(f"Platform: {system_info['platform']}")
    logger.info(f"Python version: {system_info['python_version']}")
    logger.info(f"PyTorch version: {system_info['torch_version']}")
    
    # Log memory information
    logger.info(f"System memory: {system_info['memory_total_gb']:.2f} GB total, "
                f"{system_info['memory_available_gb']:.2f} GB available "
                f"({system_info['memory_percent_used']}% used)")
    
    if detect_cores:
        logger.info(f"CPU cores: {system_info['cpu_count']}")
        logger.info(f"Recommended worker processes: {system_info['recommended_workers']}")
    
    if adjust_for_gpu and system_info.get("cuda_available", False):
        logger.info(f"CUDA available: {system_info['cuda_available']}")
        logger.info(f"CUDA device count: {system_info['cuda_device_count']}")
        logger.info(f"CUDA device name: {system_info['cuda_device_name']}")
        logger.info(f"CUDA version: {system_info['cuda_version']}")
        
        if "gpu_total_memory_gb" in system_info:
            logger.info(f"GPU memory: {system_info['gpu_total_memory_gb']:.2f} GB total, "
                        f"{system_info['gpu_available_memory_gb']:.2f} GB available")
    
    return system_info


def set_num_threads(num_threads: int = None) -> int:
    """
    Set number of threads for PyTorch.
    
    Args:
        num_threads: Number of threads to use (if None, use half of available cores)
        
    Returns:
        Number of threads set
    """
    if num_threads is None:
        cpu_count = multiprocessing.cpu_count()
        # Use half of available cores for better resource sharing
        num_threads = max(1, cpu_count // 2)
    
    torch.set_num_threads(num_threads)
    logger.info(f"Set PyTorch number of threads to {num_threads}")
    
    return num_threads


def check_memory_usage() -> Dict[str, float]:
    """
    Check current memory usage and return detailed statistics.
    
    Returns:
        Dictionary with memory usage statistics
    """
    # Get process memory info
    process = psutil.Process(os.getpid())
    process_memory = process.memory_info()
    
    # Get system memory info
    system_memory = psutil.virtual_memory()
    
    # Calculate memory statistics
    process_rss_gb = process_memory.rss / (1024**3)
    process_vms_gb = process_memory.vms / (1024**3)
    system_total_gb = system_memory.total / (1024**3)
    system_available_gb = system_memory.available / (1024**3)
    system_used_gb = system_total_gb - system_available_gb
    system_percent = system_memory.percent
    
    # Check GPU memory if available
    gpu_stats = {}
    if torch.cuda.is_available():
        try:
            for i in range(torch.cuda.device_count()):
                allocated = torch.cuda.memory_allocated(i) / (1024**3)
                reserved = torch.cuda.memory_reserved(i) / (1024**3)
                gpu_stats[f"gpu{i}_allocated_gb"] = allocated
                gpu_stats[f"gpu{i}_reserved_gb"] = reserved
        except Exception as e:
            logger.debug(f"Error getting GPU memory stats: {str(e)}")
    
    # Combine all stats
    memory_stats = {
        "process_rss_gb": process_rss_gb,
        "process_vms_gb": process_vms_gb,
        "system_total_gb": system_total_gb,
        "system_available_gb": system_available_gb,
        "system_used_gb": system_used_gb,
        "system_percent": system_percent,
        **gpu_stats
    }
    
    return memory_stats


def clear_memory(force_gc: bool = True, clear_cuda: bool = True, aggressive: bool = False) -> Dict[str, float]:
    """
    Attempt to clear memory by forcing aggressive garbage collection and clearing CUDA cache.
    
    Args:
        force_gc: Whether to force garbage collection
        clear_cuda: Whether to clear CUDA cache
        aggressive: Whether to use aggressive memory clearing (for emergency situations)
        
    Returns:
        Dictionary with memory usage statistics after clearing
    """
    # Get memory usage before clearing
    before_stats = check_memory_usage()
    
    # Force garbage collection if requested - run multiple times for better collection
    if force_gc:
        # Run multiple collections to better handle reference cycles and fragmentation
        for _ in range(5 if aggressive else 3):  # More cycles in aggressive mode
            gc.collect()
        
        # Attempt to manually clean reference cycles between objects
        gc.collect(generation=2)  # Focus on oldest generation
    
    # Clear CUDA cache if available and requested
    if clear_cuda and torch.cuda.is_available():
        torch.cuda.empty_cache()
        # Force synchronization to ensure CUDA operations complete
        if torch.cuda.is_initialized():
            try:
                torch.cuda.synchronize()
                
                # Reset the CUDA device on critical memory or in aggressive mode
                if is_memory_critical() or aggressive:
                    current_device = torch.cuda.current_device()
                    torch.cuda.empty_cache()
                    # More aggressive clearing for critical situations
                    if hasattr(torch.cuda, 'memory_stats'):
                        torch.cuda.memory_stats(current_device)  # Force memory stats refresh
                    if hasattr(torch.cuda, 'reset_peak_memory_stats'):
                        torch.cuda.reset_peak_memory_stats(current_device)
                    if hasattr(torch.cuda.memory, '_dump_snapshot'):
                        torch.cuda.memory._dump_snapshot()
            except Exception as e:
                logger.warning(f"Error during CUDA synchronization: {str(e)}")
    
    # In aggressive mode, attempt to release memory back to the OS
    if aggressive:
        try:
            import ctypes
            try:
                # Try Linux version first
                libc = ctypes.CDLL('libc.so.6')
                if hasattr(libc, 'malloc_trim'):
                    libc.malloc_trim(0)
            except:
                # Try Windows version
                try:
                    kernel32 = ctypes.windll.kernel32
                    if hasattr(kernel32, 'SetProcessWorkingSetSize'):
                        kernel32.SetProcessWorkingSetSize(
                            ctypes.windll.kernel32.GetCurrentProcess(),
                            ctypes.c_size_t(-1),
                            ctypes.c_size_t(-1)
                        )
                except:
                    pass
        except Exception as e:
            logger.debug(f"Could not call OS memory release: {str(e)}")
    
    # Get memory usage after clearing
    after_stats = check_memory_usage()
    
    # Calculate memory freed
    process_rss_freed = before_stats["process_rss_gb"] - after_stats["process_rss_gb"]
    system_freed = before_stats["system_used_gb"] - after_stats["system_used_gb"]
    
    # Log more detailed information about memory clearing
    logger.info(f"Memory cleared: Process RSS: {process_rss_freed:.2f} GB, System: {system_freed:.2f} GB")
    
    return after_stats

def is_memory_critical() -> bool:
    """
    Check if system memory usage is at a critical level.
    
    Returns:
        True if memory usage is critical, False otherwise
    """
    system_memory = psutil.virtual_memory()
    memory_percent = system_memory.percent / 100.0
    
    return memory_percent >= MEMORY_CRITICAL_THRESHOLD

def estimate_batch_size(
    input_shape: Tuple[int, ...], 
    target_memory_gb: float = None,
    min_batch_size: int = 32, 
    max_batch_size: int = 1024
) -> int:
    """
    Estimate a safe batch size based on input shape and available memory.
    
    Args:
        input_shape: Shape of a single input tensor
        target_memory_gb: Target memory usage in GB (if None, will be estimated)
        min_batch_size: Minimum allowable batch size
        max_batch_size: Maximum allowable batch size
        
    Returns:
        Estimated safe batch size
    """
    # Calculate size of a single input in bytes
    element_size = 4  # float32 = 4 bytes
    single_input_size = np.prod(input_shape) * element_size
    
    # Improved memory estimation for PyTorch overhead
    # PyTorch typically needs extra memory for gradients, optimizer states, etc.
    memory_overhead_factor = 3.0  # More aggressive - allows larger batch sizes
    
    # Use GPU memory if available for batch size estimation
    if torch.cuda.is_available():
        try:
            gpu_id = 0
            gpu_properties = torch.cuda.get_device_properties(gpu_id)
            total_memory_gb = gpu_properties.total_memory / (1024**3)
            allocated_memory_gb = torch.cuda.memory_allocated(gpu_id) / (1024**3)
            reserved_memory_gb = torch.cuda.memory_reserved(gpu_id) / (1024**3)
            
            # Calculate available memory more accurately
            effective_available_gb = total_memory_gb - max(allocated_memory_gb, reserved_memory_gb)
            
            # Use a higher percentage of available GPU memory
            target_gpu_memory_gb = effective_available_gb * 0.85  # Use up to 85% of available memory
            
            # Calculate maximum batch size based on GPU memory
            max_elements = (target_gpu_memory_gb * (1024**3)) / (single_input_size * memory_overhead_factor)
            gpu_batch_size = max(min_batch_size, min(int(max_elements), max_batch_size))
            
            logger.info(f"GPU memory: {total_memory_gb:.2f} GB total, {effective_available_gb:.2f} GB available")
            logger.info(f"Estimated GPU-based batch size: {gpu_batch_size}")
            
            return gpu_batch_size
        
        except Exception as e:
            logger.warning(f"GPU memory estimation failed: {str(e)}")
    
    # Fallback to system memory estimation
    memory = psutil.virtual_memory()
    available_gb = memory.available / (1024**3)
    
    # Use more aggressive memory estimation for CPU
    system_memory_factor = 0.7  # Use up to 70% of available system memory
    target_system_memory_gb = available_gb * system_memory_factor
    
    # Calculate maximum batch size based on system memory
    max_elements = (target_system_memory_gb * (1024**3)) / (single_input_size * memory_overhead_factor)
    system_batch_size = max(min_batch_size, min(int(max_elements), max_batch_size))
    
    logger.info(f"System memory: {memory.total/(1024**3):.2f} GB total, {available_gb:.2f} GB available")
    logger.info(f"Estimated system memory-based batch size: {system_batch_size}")
    
    return system_batch_size

def adjust_workers_for_memory(default_workers: int = 4) -> int:
    """
    Adjust the number of worker processes based on available system memory.
    
    Args:
        default_workers: Default number of workers
        
    Returns:
        Adjusted number of workers
    """
    memory = psutil.virtual_memory()
    memory_percent = memory.percent / 100.0
    
    if memory_percent >= MEMORY_EMERGENCY_THRESHOLD:
        # Critical memory situation, use single-threaded operation
        logger.warning(f"Emergency memory situation ({memory_percent*100:.1f}%), using 0 workers")
        return 0
    elif memory_percent >= MEMORY_CRITICAL_THRESHOLD:
        # Critical memory situation, use single-threaded operation
        logger.warning(f"Critical memory situation ({memory_percent*100:.1f}%), using 1 worker")
        return 1
    elif memory_percent >= MEMORY_WARNING_THRESHOLD:
        # Warning memory situation, reduce workers
        adjusted_workers = max(1, default_workers // 2)
        logger.warning(f"Memory usage high ({memory_percent*100:.1f}%), reducing workers to {adjusted_workers}")
        return adjusted_workers
    else:
        # Normal memory situation, use default workers
        return default_workers
    
    

def log_gpu_details():
    """
    Comprehensive GPU logging and diagnostics.
    """
    if torch.cuda.is_available():
        gpu_id = 0
        device = torch.device('cuda', gpu_id)
        
        # Device Properties
        props = torch.cuda.get_device_properties(gpu_id)
        logger.info(f"GPU Details:")
        logger.info(f"  Name: {props.name}")
        logger.info(f"  Total Memory: {props.total_memory / (1024**3):.2f} GB")
        logger.info(f"  CUDA Capability: {props.major}.{props.minor}")
        logger.info(f"  Multi-Processor Count: {props.multi_processor_count}")
        
        # Current Memory Stats
        allocated = torch.cuda.memory_allocated(gpu_id) / (1024**3)
        reserved = torch.cuda.memory_reserved(gpu_id) / (1024**3)
        max_allocated = torch.cuda.max_memory_allocated(gpu_id) / (1024**3)
        
        logger.info(f"Memory Stats:")
        logger.info(f"  Currently Allocated: {allocated:.2f} GB")
        logger.info(f"  Reserved Memory: {reserved:.2f} GB")
        logger.info(f"  Peak Allocated: {max_allocated:.2f} GB")
        
        # Utilization and Performance
        logger.info(f"  Current GPU Utilization: {torch.cuda.utilization(gpu_id)}%")
        
        
        

def emergency_memory_reduction():
    """
    Emergency procedure to reduce memory usage when critical thresholds are reached.
    This is a last resort before potential system crash.
    
    Returns:
        Amount of memory freed in GB
    """
    logger.warning("EMERGENCY MEMORY REDUCTION INITIATED")
    
    before_stats = check_memory_usage()
    
    # 1. Aggressive garbage collection
    clear_memory(force_gc=True, clear_cuda=True, aggressive=True)
    
    # 2. Trigger Python's internal memory compaction
    import gc
    gc.collect(generation=2)
    
    # 3. Attempt to release memory back to the OS
    try:
        import ctypes
        try:
            # Try Linux version first
            libc = ctypes.CDLL('libc.so.6')
            if hasattr(libc, 'malloc_trim'):
                libc.malloc_trim(0)
        except:
            # Try Windows version
            try:
                kernel32 = ctypes.windll.kernel32
                kernel32.SetProcessWorkingSetSize(
                    ctypes.windll.kernel32.GetCurrentProcess(),
                    ctypes.c_size_t(-1),
                    ctypes.c_size_t(-1)
                )
            except:
                pass
    except Exception as e:
        logger.debug(f"Could not call OS memory release: {str(e)}")
    
    # 4. Force CUDA memory cleanup if available
    if torch.cuda.is_available():
        try:
            for i in range(torch.cuda.device_count()):
                torch.cuda.empty_cache()
                if hasattr(torch.cuda, 'memory_stats'):
                    torch.cuda.memory_stats(i)
                if hasattr(torch.cuda, 'reset_peak_memory_stats'):
                    torch.cuda.reset_peak_memory_stats(i)
        except Exception as e:
            logger.warning(f"Error clearing CUDA memory: {str(e)}")
    
    # 5. Get memory usage after emergency procedures
    after_stats = check_memory_usage()
    
    # Calculate memory freed
    process_rss_freed = before_stats["process_rss_gb"] - after_stats["process_rss_gb"]
    system_freed = before_stats["system_used_gb"] - after_stats["system_used_gb"]
    
    logger.warning(f"Emergency memory reduction freed: Process RSS: {process_rss_freed:.2f} GB, System: {system_freed:.2f} GB")
    logger.warning(f"Current memory usage: {after_stats['system_percent']:.1f}% ({after_stats['process_rss_gb']:.2f} GB)")
    
    return system_freed
===== FILE: src/voxelflex/utils/logging_utils.py =====

"""
Enhanced logging utilities for Voxelflex.

This module provides advanced logging functionality including:
- Structured pipeline progress tracking
- Memory usage monitoring
- Stage-based progress reporting
- Enhanced progress bar with ETA, memory stats, and stage info
"""

import os
import sys
import time
import logging
import psutil
import shutil
from typing import Optional, Dict, Any, List
from contextlib import contextmanager

# ANSI escape codes for colors
COLOR_RESET = "\033[0m"
COLOR_RED = "\033[31m"
COLOR_GREEN = "\033[32m"
COLOR_YELLOW = "\033[33m"
COLOR_BLUE = "\033[34m"
COLOR_MAGENTA = "\033[35m"
COLOR_CYAN = "\033[36m"

# ASCII art for logger
ASCII_HEADER = r"""
 __      __                  _  __ _           
 \ \    / /                 | |/ _| |          
  \ \  / /__  __  _____  ___| | |_| | _____  __
   \ \/ / _ \\ \/ / _ \/ __| |  _| |/ _ \ \/ /
    \  / (_) |>  <  __/ (__| | | | |  __/>  < 
     \/ \___//_/\_\___|\___|_|_| |_|\___/_/\_\                                     
"""

# Pipeline stages for tracking progress
# In src/voxelflex/utils/logging_utils.py

# Update the PIPELINE_STAGES list to include MODEL_SAVING
PIPELINE_STAGES = [
    "INITIALIZATION",
    "DATA_LOADING",
    "DATA_VALIDATION",
    "DATASET_CREATION",
    "MODEL_CREATION",
    "TRAINING",
    "MODEL_SAVING",  # Add this missing stage
    "PREDICTION",
    "EVALUATION",
    "VISUALIZATION",
    "CLEANUP"
]

class PipelineTracker:
    """Tracks the progress of the Voxelflex pipeline through its stages."""
    
    def __init__(self):
        """Initialize the pipeline tracker."""
        self.current_stage = None
        self.stage_start_time = None
        self.stages_completed = []
        self.stage_durations = {}
        self.logger = logging.getLogger("voxelflex.pipeline")
    
    def start_stage(self, stage: str, details: str = "") -> None:
        """
        Mark the beginning of a pipeline stage.
        
        Args:
            stage: Name of the stage
            details: Additional details about the stage
        """
        if stage not in PIPELINE_STAGES:
            raise ValueError(f"Unknown pipeline stage: {stage}")
        
        self.current_stage = stage
        self.stage_start_time = time.time()
        
        # Log the stage start
        detail_text = f" - {details}" if details else ""
        self.logger.info(f"{COLOR_CYAN}Starting pipeline stage: {stage}{COLOR_RESET}{detail_text}")
        
        # Log memory usage
        self._log_memory_usage()
    
    def end_stage(self, stage: str = None) -> None:
        """
        Mark the completion of a pipeline stage.
        
        Args:
            stage: Name of the stage (if None, use current_stage)
        """
        if stage is None:
            stage = self.current_stage
        
        if stage != self.current_stage:
            self.logger.warning(f"Ending stage {stage}, but current stage is {self.current_stage}")
        
        if self.stage_start_time is None:
            self.logger.warning(f"Ending stage {stage}, but no start time was recorded")
            duration = 0
        else:
            duration = time.time() - self.stage_start_time
        
        self.stages_completed.append(stage)
        self.stage_durations[stage] = duration
        
        # Log the stage completion and duration
        self.logger.info(f"{COLOR_GREEN}Completed pipeline stage: {stage} in {self._format_time(duration)}{COLOR_RESET}")
        
        # Log memory usage
        self._log_memory_usage()
        
        self.current_stage = None
        self.stage_start_time = None
    
    def get_current_stage(self) -> str:
        """
        Get the current pipeline stage.
        
        Returns:
            Current stage name or "UNKNOWN" if no stage is active
        """
        return self.current_stage or "UNKNOWN"
    
    def get_pipeline_progress(self) -> float:
        """
        Get the overall pipeline progress as a percentage.
        
        Returns:
            Progress percentage (0-100)
        """
        if not self.stages_completed:
            return 0.0
        
        total_stages = len(PIPELINE_STAGES)
        completed_stages = len(self.stages_completed)
        
        # If a stage is in progress, add partial credit
        if self.current_stage:
            current_stage_idx = PIPELINE_STAGES.index(self.current_stage)
            prev_stages = current_stage_idx
            
            # Calculate progress within the current stage (assuming linear progress)
            # This is a rough approximation and could be improved with more data
            if self.stage_start_time:
                # Average time for completed stages (if any)
                if self.stage_durations:
                    avg_duration = sum(self.stage_durations.values()) / len(self.stage_durations)
                    # Estimate current stage progress (cap at 0.95 to avoid appearing complete)
                    elapsed = time.time() - self.stage_start_time
                    stage_progress = min(0.95, elapsed / (avg_duration * 1.5))  # Apply a 1.5x factor for safety
                else:
                    # No historical data, assume 50% complete
                    stage_progress = 0.5
            else:
                stage_progress = 0
            
            progress = (prev_stages + stage_progress) / total_stages
        else:
            progress = completed_stages / total_stages
        
        return progress * 100
    
    def _log_memory_usage(self) -> None:
        """Log current memory usage."""
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        
        self.logger.info(f"Memory usage: {memory_info.rss / (1024 * 1024):.1f} MB")
    
    def _format_time(self, seconds: float) -> str:
        """
        Format time in seconds to a readable string.
        
        Args:
            seconds: Time in seconds
            
        Returns:
            Formatted time string
        """
        if seconds < 60:
            return f"{seconds:.1f} seconds"
        elif seconds < 3600:
            minutes = int(seconds / 60)
            seconds = seconds % 60
            return f"{minutes} minutes {seconds:.1f} seconds"
        else:
            hours = int(seconds / 3600)
            seconds = seconds % 3600
            minutes = int(seconds / 60)
            seconds = seconds % 60
            return f"{hours} hours {minutes} minutes {seconds:.1f} seconds"

# Global pipeline tracker instance
pipeline_tracker = PipelineTracker()

def setup_logging(log_file: Optional[str] = None, console_level: str = "INFO", 
                  file_level: str = "DEBUG") -> None:
    """
    Set up enhanced logging for Voxelflex.
    
    Args:
        log_file: Path to log file (if None, logging to file is disabled)
        console_level: Logging level for console output
        file_level: Logging level for file output
    """
    # Convert string levels to logging levels
    console_level = getattr(logging, console_level.upper())
    file_level = getattr(logging, file_level.upper())
    
    # Create root logger
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)  # Set to lowest level to capture everything
    
    # Remove existing handlers
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # Create formatter with timestamp
    formatter = logging.Formatter(
        "%(asctime)s [%(levelname)8s] %(name)s: %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    
    # Create console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(console_level)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # Create file handler if log_file is provided
    if log_file:
        # Create directory if it doesn't exist
        log_dir = os.path.dirname(log_file)
        if log_dir:
            os.makedirs(log_dir, exist_ok=True)
        
        file_handler = logging.FileHandler(log_file)
        file_handler.setLevel(file_level)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    
    # Log ASCII art header
    logger.info(f"\n{ASCII_HEADER}")
    logger.info(f"{COLOR_GREEN}Voxelflex logger initialized{COLOR_RESET}")
    
    # Log system memory information
    vm = psutil.virtual_memory()
    logger.info(f"System memory: {vm.total / (1024**3):.1f} GB total, {vm.available / (1024**3):.1f} GB available")


def get_logger(name: str) -> logging.Logger:
    """
    Get a logger with the specified name.
    
    Args:
        name: Logger name
        
    Returns:
        Logger instance
    """
    return logging.getLogger(name)


@contextmanager
def log_stage(stage: str, details: str = ""):
    """
    Context manager for tracking a pipeline stage.
    
    Args:
        stage: Stage name
        details: Additional details about the stage
    """
    pipeline_tracker.start_stage(stage, details)
    try:
        yield
    finally:
        pipeline_tracker.end_stage(stage)


class EnhancedProgressBar:
    """
    Enhanced progress bar with memory usage tracking and time statistics.
    """
    
    def __init__(self, total: int, prefix: str = "", suffix: str = "", 
                 bar_length: int = 30, stage_info: str = None):
        """
        Initialize progress bar.
        
        Args:
            total: Total number of items
            prefix: Prefix string
            suffix: Suffix string
            bar_length: Length of the progress bar
            stage_info: Current pipeline stage information
        """
        self.total = total
        self.prefix = prefix
        self.suffix = suffix
        self.bar_length = bar_length
        self.current = 0
        self.start_time = time.time()
        self.last_printed_length = 0
        self.stage_info = stage_info or pipeline_tracker.get_current_stage()
        
        # Get terminal width
        self.terminal_width = shutil.get_terminal_size().columns
        
        # Initial memory snapshot
        self.process = psutil.Process(os.getpid())
        self.initial_memory = self.process.memory_info().rss
        
        # Print initial progress
        self._print_progress()
    
    def update(self, current: int) -> None:
        """
        Update progress bar.
        
        Args:
            current: Current progress value
        """
        self.current = current
        self._print_progress()
    
    def _print_progress(self) -> None:
        """Print the progress bar with enhanced information."""
        # Calculate progress
        if self.total <= 0:  # Check if total is zero or negative
            percent = 100.0  # Assume 100% complete if total is 0
            filled_length = self.bar_length  # Fill the entire bar
        else:
            percent = float(self.current) / float(self.total) * 100
            filled_length = int(round(self.bar_length * self.current / float(self.total)))
        
        bar = "█" * filled_length + "-" * (self.bar_length - filled_length)
        
        # Calculate elapsed time and ETA
        elapsed_time = time.time() - self.start_time
        
        # Handle items_per_second calculation when total is 0
        if self.total <= 0 or elapsed_time <= 0:
            items_per_second = 0
            eta = 0
        else:
            items_per_second = self.current / elapsed_time if elapsed_time > 0 else 0
            remaining_items = self.total - self.current
            eta = remaining_items / items_per_second if items_per_second > 0 else 0
        
        # Format time strings
        elapsed_str = self._format_time(elapsed_time)
        eta_str = self._format_time(eta)
        
        # Get memory usage
        current_memory = self.process.memory_info().rss
        memory_diff = current_memory - self.initial_memory
        memory_str = f"{current_memory / (1024 * 1024):.1f} MB"
        memory_diff_str = f"{memory_diff / (1024 * 1024):+.1f} MB" if memory_diff != 0 else ""
        
        # Build progress string
        progress_str = f"\r{self.prefix} [{bar}] {percent:.1f}% {self.current}/{self.total} "
        progress_str += f"[{elapsed_str}<{eta_str}, {items_per_second:.1f} it/s]"
        
        # Add memory usage if significant change
        if abs(memory_diff) > 1024 * 1024:  # Only show if change > 1MB
            progress_str += f" | Mem: {memory_str} ({memory_diff_str})"
        
        # Add stage info
        if self.stage_info:
            progress_str += f" | Stage: {self.stage_info}"
        
        progress_str += f" {self.suffix}"
        
        # Ensure the string fits the terminal width
        if len(progress_str) > self.terminal_width:
            progress_str = progress_str[:self.terminal_width - 3] + "..."
        
        # Clear previous output by printing spaces
        clear_str = " " * self.last_printed_length
        sys.stdout.write("\r" + clear_str)
        
        # Print progress
        sys.stdout.write(progress_str)
        sys.stdout.flush()
        
        self.last_printed_length = len(progress_str)
    
    def _format_time(self, seconds: float) -> str:
        """
        Format time in seconds to a readable string.
        
        Args:
            seconds: Time in seconds
            
        Returns:
            Formatted time string
        """
        if seconds < 60:
            return f"{seconds:.1f}s"
        elif seconds < 3600:
            minutes = int(seconds / 60)
            seconds = seconds % 60
            return f"{minutes}m {seconds:.1f}s"
        else:
            hours = int(seconds / 3600)
            seconds = seconds % 3600
            minutes = int(seconds / 60)
            seconds = seconds % 60
            return f"{hours}h {minutes}m {seconds:.1f}s"
    
    def finish(self) -> None:
        """Complete the progress bar and move to the next line."""
        self.update(self.total)
        sys.stdout.write("\n")
        sys.stdout.flush()


def log_memory_usage(logger=None) -> Dict[str, float]:
    """
    Log current memory usage statistics.
    
    Args:
        logger: Logger to use (if None, create a new one)
        
    Returns:
        Dictionary with memory usage statistics in MB
    """
    if logger is None:
        logger = get_logger("voxelflex.memory")
    
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    
    # Get system memory info
    system_memory = psutil.virtual_memory()
    
    # Calculate memory statistics
    process_rss_mb = memory_info.rss / (1024 * 1024)
    process_vms_mb = memory_info.vms / (1024 * 1024)
    system_used_mb = (system_memory.total - system_memory.available) / (1024 * 1024)
    system_total_mb = system_memory.total / (1024 * 1024)
    system_percent = system_memory.percent
    
    memory_stats = {
        "process_rss_mb": process_rss_mb,
        "process_vms_mb": process_vms_mb,
        "system_used_mb": system_used_mb,
        "system_total_mb": system_total_mb,
        "system_percent": system_percent
    }
    
    logger.info(
        f"Memory usage: Process RSS: {process_rss_mb:.1f} MB, "
        f"System: {system_used_mb:.1f}/{system_total_mb:.1f} MB ({system_percent:.1f}%)"
    )
    
    return memory_stats


def log_step(logger, step_name: str, step_index: int = None, total_steps: int = None) -> None:
    """
    Log a step in a process with optional progress information.
    
    Args:
        logger: Logger to use
        step_name: Name of the step
        step_index: Current step index (optional)
        total_steps: Total number of steps (optional)
    """
    progress_info = ""
    if step_index is not None and total_steps is not None:
        percent = (step_index / total_steps) * 100
        progress_info = f" ({step_index}/{total_steps}, {percent:.1f}%)"
    
    logger.info(f"Step: {step_name}{progress_info}")


def log_section_header(logger, section_name: str) -> None:
    """
    Log a section header to clearly delineate different parts of the process.
    
    Args:
        logger: Logger to use
        section_name: Name of the section
    """
    separator = "=" * min(70, len(section_name) + 10)
    logger.info(f"\n{separator}")
    logger.info(f"{COLOR_CYAN}{section_name}{COLOR_RESET}")
    logger.info(f"{separator}")


def log_operation_result(logger, operation_name: str, result_summary: str, 
                        success: bool = True, extras: Dict[str, Any] = None) -> None:
    """
    Log the result of an operation with additional details.
    
    Args:
        logger: Logger to use
        operation_name: Name of the operation
        result_summary: Summary of the result
        success: Whether the operation was successful
        extras: Additional information to log
    """
    color = COLOR_GREEN if success else COLOR_RED
    status = "SUCCESS" if success else "FAILURE"
    
    logger.info(f"{color}[{status}]{COLOR_RESET} {operation_name}: {result_summary}")
    
    if extras:
        for key, value in extras.items():
            logger.debug(f"  {key}: {value}")






class ProgressBar:
    """
    Fixed-bottom progress bar that can be updated from anywhere in the code.
    """
    
    def __init__(self, total: int, prefix: str = "", suffix: str = "", 
                 bar_length: int = 30):
        """
        Initialize progress bar.
        
        Args:
            total: Total number of items
            prefix: Prefix string
            suffix: Suffix string
            bar_length: Length of the progress bar
        """
        self.total = total
        self.prefix = prefix
        self.suffix = suffix
        self.bar_length = bar_length
        self.current = 0
        self.start_time = time.time()
        self.last_printed_length = 0
        
        # Get terminal width
        self.terminal_width = shutil.get_terminal_size().columns
    
    def update(self, current: int) -> None:
        """
        Update progress bar.
        
        Args:
            current: Current progress value
        """
        self.current = current
        self._print_progress()
    
    def _print_progress(self) -> None:
        """Print the progress bar."""
        # Calculate progress
        percent = float(self.current) / float(self.total) * 100
        filled_length = int(round(self.bar_length * self.current / float(self.total)))
        bar = "█" * filled_length + "-" * (self.bar_length - filled_length)
        
        # Calculate elapsed time and ETA
        elapsed_time = time.time() - self.start_time
        items_per_second = self.current / elapsed_time if elapsed_time > 0 else 0
        eta = (self.total - self.current) / items_per_second if items_per_second > 0 else 0
        
        # Format time strings
        elapsed_str = self._format_time(elapsed_time)
        eta_str = self._format_time(eta)
        
        # Build progress string
        progress_str = f"\r{self.prefix} [{bar}] {percent:.1f}% {self.current}/{self.total} "
        progress_str += f"[{elapsed_str}<{eta_str}, {items_per_second:.1f} it/s] {self.suffix}"
        
        # Ensure the string fits the terminal width
        if len(progress_str) > self.terminal_width:
            progress_str = progress_str[:self.terminal_width - 3] + "..."
        
        # Clear previous output by printing spaces
        clear_str = " " * self.last_printed_length
        sys.stdout.write("\r" + clear_str)
        
        # Print progress
        sys.stdout.write(progress_str)
        sys.stdout.flush()
        
        self.last_printed_length = len(progress_str)
    
    def _format_time(self, seconds: float) -> str:
        """
        Format time in seconds to a readable string.
        
        Args:
            seconds: Time in seconds
            
        Returns:
            Formatted time string
        """
        if seconds < 60:
            return f"{seconds:.1f}s"
        elif seconds < 3600:
            minutes = int(seconds / 60)
            seconds = seconds % 60
            return f"{minutes}m {seconds:.1f}s"
        else:
            hours = int(seconds / 3600)
            seconds = seconds % 3600
            minutes = int(seconds / 60)
            seconds = seconds % 60
            return f"{hours}h {minutes}m {seconds:.1f}s"
    
    def finish(self) -> None:
        """Complete the progress bar and move to the next line."""
        self.update(self.total)
        sys.stdout.write("\n")
        sys.stdout.flush()

===== FILE: src/voxelflex/utils/file_utils.py =====
"""
File utility functions for Voxelflex.

This module provides utility functions for file and directory operations.
"""

import os
import json
from pathlib import Path
from typing import Dict, Any, Union, Optional, List

def ensure_dir(directory: str) -> None:
    """
    Ensure that a directory exists, creating it if necessary.
    
    Args:
        directory: Directory path
    """
    os.makedirs(directory, exist_ok=True)


def resolve_path(path: str) -> str:
    """
    Resolve a file path, expanding user directory and making it absolute.
    
    Args:
        path: File path
        
    Returns:
        Resolved path
    """
    expanded_path = os.path.expanduser(path)
    return os.path.abspath(expanded_path)


def save_json(data: Dict[str, Any], file_path: str, indent: int = 4) -> None:
    """
    Save data to a JSON file.
    
    Args:
        data: Data to save
        file_path: Path to save the file
        indent: JSON indentation level
    """
    # Ensure the directory exists
    directory = os.path.dirname(file_path)
    ensure_dir(directory)
    
    # Save the JSON file
    with open(file_path, 'w') as f:
        # Handle numpy arrays and other non-serializable objects
        json.dump(data, f, indent=indent, default=lambda x: x.tolist() if hasattr(x, 'tolist') else str(x))


def load_json(file_path: str) -> Dict[str, Any]:
    """
    Load data from a JSON file.
    
    Args:
        file_path: Path to the JSON file
        
    Returns:
        Loaded data
    """
    with open(file_path, 'r') as f:
        return json.load(f)


def get_file_extension(file_path: str) -> str:
    """
    Get the file extension from a file path.
    
    Args:
        file_path: Path to the file
        
    Returns:
        File extension (lowercase, without the dot)
    """
    return os.path.splitext(file_path)[1].lower()[1:]


def inspect_hdf5_structure(file_path: str, domain_sample: int = 2, print_residues: bool = False):
    """
    Utility function to inspect and print the structure of an HDF5 file.
    
    This is useful for debugging data loading issues.
    
    Args:
        file_path: Path to the HDF5 file
        domain_sample: Number of domains to sample and print (default: 2)
        print_residues: Whether to print individual residue details (default: False)
    """
    import h5py
    import os
    
    file_path = os.path.expanduser(file_path)
    if not os.path.exists(file_path):
        print(f"File not found: {file_path}")
        return
    
    print(f"\nInspecting HDF5 file: {file_path}")
    print("=" * 80)
    
    with h5py.File(file_path, 'r') as f:
        # Print top-level keys (domains)
        domains = list(f.keys())
        print(f"File contains {len(domains)} top-level groups (domains)")
        print(f"First few domains: {domains[:min(5, len(domains))]}")
        
        # Sample a few domains to inspect more deeply
        sample_domains = domains[:min(domain_sample, len(domains))]
        print(f"\nSampling {len(sample_domains)} domains for detailed inspection:")
        
        for domain in sample_domains:
            print(f"\nDomain: {domain}")
            print("-" * 40)
            
            domain_group = f[domain]
            domain_keys = list(domain_group.keys())
            print(f"Domain has {len(domain_keys)} direct children")
            print(f"Children keys: {domain_keys}")
            
            # Find residue groups
            for key in domain_keys:
                item = domain_group[key]
                if isinstance(item, h5py.Group):
                    print(f"\n  Group: {key}")
                    sub_keys = list(item.keys())
                    print(f"  Contains {len(sub_keys)} items")
                    
                    # Check if these are likely residues (numeric keys)
                    numeric_keys = [k for k in sub_keys if isinstance(k, str) and k.isdigit()]
                    if numeric_keys:
                        print(f"  Contains {len(numeric_keys)} numeric keys (likely residues)")
                        
                        if print_residues:
                            # Sample a few residues
                            sample_residues = numeric_keys[:min(3, len(numeric_keys))]
                            for res_id in sample_residues:
                                print(f"\n    Residue: {res_id}")
                                residue = item[res_id]
                                
                                if isinstance(residue, h5py.Group):
                                    res_keys = list(residue.keys())
                                    print(f"    Contains keys: {res_keys}")
                                    
                                    # Check for voxel data
                                    for res_key in res_keys:
                                        res_item = residue[res_key]
                                        if isinstance(res_item, h5py.Dataset):
                                            print(f"      Dataset '{res_key}': shape={res_item.shape}, dtype={res_item.dtype}")
                                
                                elif isinstance(residue, h5py.Dataset):
                                    print(f"    Direct dataset: shape={residue.shape}, dtype={residue.dtype}")
                elif isinstance(item, h5py.Dataset):
                    print(f"\n  Dataset: {key}, shape={item.shape}, dtype={item.dtype}")
    
    print("\nFile inspection complete.")
    print("=" * 80)



def save_domain_registry(domains: List[str], file_path: str) -> None:
    """
    Save a list of processed domain IDs to a file.
    
    Args:
        domains: List of domain IDs that were processed
        file_path: Path to save the registry file
    """
    with open(file_path, 'w') as f:
        for domain in domains:
            f.write(f"{domain}\n")

def load_domain_registry(file_path: str) -> List[str]:
    """
    Load a list of processed domain IDs from a file.
    
    Args:
        file_path: Path to the registry file
        
    Returns:
        List of domain IDs
    """
    if not os.path.exists(file_path):
        return []
        
    with open(file_path, 'r') as f:
        return [line.strip() for line in f if line.strip()]

=======================================
Extracting First 10 Lines from Files in outputs/logs
=======================================

